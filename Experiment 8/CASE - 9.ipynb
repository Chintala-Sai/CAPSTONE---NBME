{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3189c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import spacy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6eec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:\\\\Users\\\\preet\\\\Desktop\\\\CAPstone\\\\train.csv\")\n",
    "features = pd.read_csv(\"C:\\\\Users\\\\preet\\\\Desktop\\\\CAPstone\\\\features.csv\")\n",
    "patient_notes = pd.read_csv(\"C:\\\\Users\\\\preet\\\\Desktop\\\\CAPstone\\\\patient_notes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499fc6a",
   "metadata": {},
   "source": [
    "### CASE - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e2b53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>900</td>\n",
       "      <td>9</td>\n",
       "      <td>No-relief-with-Motrin-OR-no-relief-with-tylenol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>901</td>\n",
       "      <td>9</td>\n",
       "      <td>20-year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>902</td>\n",
       "      <td>9</td>\n",
       "      <td>1-day-duration-OR-2-days-duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>903</td>\n",
       "      <td>9</td>\n",
       "      <td>Myalgias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>904</td>\n",
       "      <td>9</td>\n",
       "      <td>Global-headache-OR-diffuse-headache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>905</td>\n",
       "      <td>9</td>\n",
       "      <td>Neck-pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>906</td>\n",
       "      <td>9</td>\n",
       "      <td>Vomiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>907</td>\n",
       "      <td>9</td>\n",
       "      <td>No-rash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>908</td>\n",
       "      <td>9</td>\n",
       "      <td>Nausea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>909</td>\n",
       "      <td>9</td>\n",
       "      <td>viral-symptoms-OR-rhinorrhea-OR-scratchy-throat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>910</td>\n",
       "      <td>9</td>\n",
       "      <td>Shares-an-apartment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>911</td>\n",
       "      <td>9</td>\n",
       "      <td>Meningococcal-vaccine-status-unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>912</td>\n",
       "      <td>9</td>\n",
       "      <td>Family-history-of-migraines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>913</td>\n",
       "      <td>9</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>914</td>\n",
       "      <td>9</td>\n",
       "      <td>Photophobia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>915</td>\n",
       "      <td>9</td>\n",
       "      <td>No-known-illness-contacts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>916</td>\n",
       "      <td>9</td>\n",
       "      <td>Subjective-fever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_num  case_num                                     feature_text\n",
       "126          900         9  No-relief-with-Motrin-OR-no-relief-with-tylenol\n",
       "127          901         9                                          20-year\n",
       "128          902         9                1-day-duration-OR-2-days-duration\n",
       "129          903         9                                         Myalgias\n",
       "130          904         9              Global-headache-OR-diffuse-headache\n",
       "131          905         9                                        Neck-pain\n",
       "132          906         9                                         Vomiting\n",
       "133          907         9                                          No-rash\n",
       "134          908         9                                           Nausea\n",
       "135          909         9  viral-symptoms-OR-rhinorrhea-OR-scratchy-throat\n",
       "136          910         9                              Shares-an-apartment\n",
       "137          911         9             Meningococcal-vaccine-status-unknown\n",
       "138          912         9                      Family-history-of-migraines\n",
       "139          913         9                                           Female\n",
       "140          914         9                                      Photophobia\n",
       "141          915         9                        No-known-illness-contacts\n",
       "142          916         9                                 Subjective-fever"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_features = features[features[\"case_num\"] == 9]\n",
    "case_9_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64976a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36995</th>\n",
       "      <td>90000</td>\n",
       "      <td>9</td>\n",
       "      <td>HPI: Ms. Madden is a 20 year old previously he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36996</th>\n",
       "      <td>90001</td>\n",
       "      <td>9</td>\n",
       "      <td>Ms. Madden is a 40 yo f presenting with progre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36997</th>\n",
       "      <td>90002</td>\n",
       "      <td>9</td>\n",
       "      <td>20 yo F with 2 days of 8/10 dull, achy headach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36998</th>\n",
       "      <td>90003</td>\n",
       "      <td>9</td>\n",
       "      <td>20 yo f c/o headache started yesterday , sudde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36999</th>\n",
       "      <td>90004</td>\n",
       "      <td>9</td>\n",
       "      <td>Ms. Madden is a 20 yo female who presents with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42141</th>\n",
       "      <td>95330</td>\n",
       "      <td>9</td>\n",
       "      <td>Ms. Madden is a 20 yo female presenting w/ the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42142</th>\n",
       "      <td>95331</td>\n",
       "      <td>9</td>\n",
       "      <td>A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42143</th>\n",
       "      <td>95332</td>\n",
       "      <td>9</td>\n",
       "      <td>Ms. Madden is a 20yo female who presents with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42144</th>\n",
       "      <td>95333</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie madden is a 20 year old woman compla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42145</th>\n",
       "      <td>95334</td>\n",
       "      <td>9</td>\n",
       "      <td>patient is a 20 yo F who presents with a heada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5151 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pn_num  case_num                                         pn_history\n",
       "36995   90000         9  HPI: Ms. Madden is a 20 year old previously he...\n",
       "36996   90001         9  Ms. Madden is a 40 yo f presenting with progre...\n",
       "36997   90002         9  20 yo F with 2 days of 8/10 dull, achy headach...\n",
       "36998   90003         9  20 yo f c/o headache started yesterday , sudde...\n",
       "36999   90004         9  Ms. Madden is a 20 yo female who presents with...\n",
       "...       ...       ...                                                ...\n",
       "42141   95330         9  Ms. Madden is a 20 yo female presenting w/ the...\n",
       "42142   95331         9  A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...\n",
       "42143   95332         9  Ms. Madden is a 20yo female who presents with ...\n",
       "42144   95333         9  Stephanie madden is a 20 year old woman compla...\n",
       "42145   95334         9  patient is a 20 yo F who presents with a heada...\n",
       "\n",
       "[5151 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_pn = patient_notes[patient_notes[\"case_num\"] ==  9]\n",
    "case_9_pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e4e2df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>90127_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90127</td>\n",
       "      <td>900</td>\n",
       "      <td>['tylenol no relief', 'ibuprofen no relief']</td>\n",
       "      <td>['251 258;284 293', '264 273;284 293']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12601</th>\n",
       "      <td>90127_901</td>\n",
       "      <td>9</td>\n",
       "      <td>90127</td>\n",
       "      <td>901</td>\n",
       "      <td>['20 year old']</td>\n",
       "      <td>['34 45']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>90127_902</td>\n",
       "      <td>9</td>\n",
       "      <td>90127</td>\n",
       "      <td>902</td>\n",
       "      <td>['yesterday']</td>\n",
       "      <td>['102 111']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12606</th>\n",
       "      <td>90127_906</td>\n",
       "      <td>9</td>\n",
       "      <td>90127</td>\n",
       "      <td>906</td>\n",
       "      <td>['vomiting']</td>\n",
       "      <td>['347 355']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608</th>\n",
       "      <td>90127_908</td>\n",
       "      <td>9</td>\n",
       "      <td>90127</td>\n",
       "      <td>908</td>\n",
       "      <td>['nausea']</td>\n",
       "      <td>['321 327']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  case_num  pn_num  feature_num  \\\n",
       "12600  90127_900         9   90127          900   \n",
       "12601  90127_901         9   90127          901   \n",
       "12602  90127_902         9   90127          902   \n",
       "12606  90127_906         9   90127          906   \n",
       "12608  90127_908         9   90127          908   \n",
       "\n",
       "                                         annotation  \\\n",
       "12600  ['tylenol no relief', 'ibuprofen no relief']   \n",
       "12601                               ['20 year old']   \n",
       "12602                                 ['yesterday']   \n",
       "12606                                  ['vomiting']   \n",
       "12608                                    ['nausea']   \n",
       "\n",
       "                                     location  \n",
       "12600  ['251 258;284 293', '264 273;284 293']  \n",
       "12601                               ['34 45']  \n",
       "12602                             ['102 111']  \n",
       "12606                             ['347 355']  \n",
       "12608                             ['321 327']  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_train = train_data[train_data[\"case_num\"] == 9]\n",
    "case_9_train = case_9_train[case_9_train.annotation != '[]']\n",
    "case_9_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1671d63f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[8,6])\n",
    "case_9_train.groupby(\"feature_num\").size().plot.bar()\n",
    "plt.title(\"CASE - 9\")\n",
    "plt.ylabel(\"Number of observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33c96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81ea0622",
   "metadata": {},
   "source": [
    "### Over Sampling for CASE - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83a12b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_dict = {}\n",
    "for idx, row in case_9_pn.iterrows():\n",
    "    pn_dict[row['pn_num']] = row['pn_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad0a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_annotation = []\n",
    "for case_id in case_9_features['case_num'].unique():\n",
    "    \n",
    "    all_pn_id = set(case_9_pn[case_9_pn['case_num']==case_id]['pn_num'].tolist())\n",
    "    \n",
    "    for feature_id in case_9_features[case_9_features['case_num']==case_id]['feature_num'].unique():\n",
    "        # get all the pn_num that have already been annotated\n",
    "        annotated_pn = set(case_9_train[case_9_train['feature_num']==feature_id]['pn_num'].tolist())\n",
    "        # get all the pn_num that have NOT been annotated\n",
    "        pn_to_annotate = all_pn_id-annotated_pn\n",
    "        \n",
    "        # get all current annotations\n",
    "        # we will use them to find more annotations\n",
    "        annotations = case_9_train[case_9_train['feature_num']==feature_id]['annotation'].tolist()\n",
    "        annotation_texts = set()\n",
    "        for a in annotations:\n",
    "            anns = eval(a)\n",
    "            for at in anns:\n",
    "                annotation_texts.add(at)\n",
    "                \n",
    "        # annotate       \n",
    "        for pn_id in pn_to_annotate:\n",
    "            new_annotation_pn, new_location_pn = [], []\n",
    "            pn_text = pn_dict[pn_id]\n",
    "            for at in annotation_texts:\n",
    "                start = pn_text.find(at)\n",
    "                if start>=0:\n",
    "                    new_annotation_pn.append(at)\n",
    "                    new_location_pn.append(f'{start} {start+len(at)}')\n",
    "            if len(new_annotation_pn)>0:\n",
    "                new_annotation.append((\n",
    "                    f'{pn_id:04d}_{feature_id:03d}',\n",
    "                    case_id,\n",
    "                    pn_id,\n",
    "                    feature_id,\n",
    "                    new_annotation_pn,\n",
    "                    new_location_pn\n",
    "                ))\n",
    "     #   break\n",
    "    break\n",
    "    # break to get sample results quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf2d102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40873"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da0a996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90046_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90046</td>\n",
       "      <td>900</td>\n",
       "      <td>[tylenol have not helped]</td>\n",
       "      <td>[324 347]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90082_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90082</td>\n",
       "      <td>900</td>\n",
       "      <td>[ibuprofen have not helped]</td>\n",
       "      <td>[161 186]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90118_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90118</td>\n",
       "      <td>900</td>\n",
       "      <td>[ibuprofen have not helped]</td>\n",
       "      <td>[435 460]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90122_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90122</td>\n",
       "      <td>900</td>\n",
       "      <td>[tylenol with no relief]</td>\n",
       "      <td>[497 519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90124_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90124</td>\n",
       "      <td>900</td>\n",
       "      <td>[No relief with tylenol]</td>\n",
       "      <td>[360 382]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1      2    3                            4          5\n",
       "0  90046_900  9  90046  900    [tylenol have not helped]  [324 347]\n",
       "1  90082_900  9  90082  900  [ibuprofen have not helped]  [161 186]\n",
       "2  90118_900  9  90118  900  [ibuprofen have not helped]  [435 460]\n",
       "3  90122_900  9  90122  900     [tylenol with no relief]  [497 519]\n",
       "4  90124_900  9  90124  900     [No relief with tylenol]  [360 382]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(new_annotation)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fdfaba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90046_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90046</td>\n",
       "      <td>900</td>\n",
       "      <td>[tylenol have not helped]</td>\n",
       "      <td>[324 347]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90082_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90082</td>\n",
       "      <td>900</td>\n",
       "      <td>[ibuprofen have not helped]</td>\n",
       "      <td>[161 186]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90118_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90118</td>\n",
       "      <td>900</td>\n",
       "      <td>[ibuprofen have not helped]</td>\n",
       "      <td>[435 460]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90122_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90122</td>\n",
       "      <td>900</td>\n",
       "      <td>[tylenol with no relief]</td>\n",
       "      <td>[497 519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90124_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90124</td>\n",
       "      <td>900</td>\n",
       "      <td>[No relief with tylenol]</td>\n",
       "      <td>[360 382]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num                   annotation  \\\n",
       "0  90046_900         9   90046          900    [tylenol have not helped]   \n",
       "1  90082_900         9   90082          900  [ibuprofen have not helped]   \n",
       "2  90118_900         9   90118          900  [ibuprofen have not helped]   \n",
       "3  90122_900         9   90122          900     [tylenol with no relief]   \n",
       "4  90124_900         9   90124          900     [No relief with tylenol]   \n",
       "\n",
       "    location  \n",
       "0  [324 347]  \n",
       "1  [161 186]  \n",
       "2  [435 460]  \n",
       "3  [497 519]  \n",
       "4  [360 382]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['id','case_num','pn_num','feature_num','annotation','location']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f760c061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90046_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90046</td>\n",
       "      <td>900</td>\n",
       "      <td>'tylenol have not helped'</td>\n",
       "      <td>'324 347'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90082_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90082</td>\n",
       "      <td>900</td>\n",
       "      <td>'ibuprofen have not helped'</td>\n",
       "      <td>'161 186'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90118_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90118</td>\n",
       "      <td>900</td>\n",
       "      <td>'ibuprofen have not helped'</td>\n",
       "      <td>'435 460'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90122_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90122</td>\n",
       "      <td>900</td>\n",
       "      <td>'tylenol with no relief'</td>\n",
       "      <td>'497 519'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90124_900</td>\n",
       "      <td>9</td>\n",
       "      <td>90124</td>\n",
       "      <td>900</td>\n",
       "      <td>'No relief with tylenol'</td>\n",
       "      <td>'360 382'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num                   annotation  \\\n",
       "0  90046_900         9   90046          900    'tylenol have not helped'   \n",
       "1  90082_900         9   90082          900  'ibuprofen have not helped'   \n",
       "2  90118_900         9   90118          900  'ibuprofen have not helped'   \n",
       "3  90122_900         9   90122          900     'tylenol with no relief'   \n",
       "4  90124_900         9   90124          900     'No relief with tylenol'   \n",
       "\n",
       "    location  \n",
       "0  '324 347'  \n",
       "1  '161 186'  \n",
       "2  '435 460'  \n",
       "3  '497 519'  \n",
       "4  '360 382'  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"location\"] = df[\"location\"].apply(str)\n",
    "df[\"annotation\"] = df[\"annotation\"].apply(str)\n",
    "\n",
    "df[\"annotation\"] = df.annotation.str.replace('[','')\n",
    "df[\"annotation\"] = df.annotation.str.replace(']','')\n",
    "df[\"location\"] = df.location.str.replace('[','')\n",
    "df[\"location\"] = df.location.str.replace(']','')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7616d221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1548, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df[\"feature_num\"] == 905)|(df[\"feature_num\"] == 907)][['pn_num','annotation',\"location\",\"feature_num\"]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a18ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90000</td>\n",
       "      <td>'neck pain'</td>\n",
       "      <td>'580 589'</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90001</td>\n",
       "      <td>'neck stiffness'</td>\n",
       "      <td>'390 404'</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90007</td>\n",
       "      <td>'neck stiffness'</td>\n",
       "      <td>'188 202'</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90011</td>\n",
       "      <td>'neck pain'</td>\n",
       "      <td>'381 390'</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90022</td>\n",
       "      <td>'neck stiffness'</td>\n",
       "      <td>'473 487'</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>95143</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'307 318'</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>95162</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'313 324'</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>95226</td>\n",
       "      <td>'No rashes'</td>\n",
       "      <td>'442 451'</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>95275</td>\n",
       "      <td>'Denies rash'</td>\n",
       "      <td>'448 459'</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>95307</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'379 390'</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num        annotation   location  feature_num\n",
       "0      90000       'neck pain'  '580 589'          905\n",
       "1      90001  'neck stiffness'  '390 404'          905\n",
       "2      90007  'neck stiffness'  '188 202'          905\n",
       "3      90011       'neck pain'  '381 390'          905\n",
       "4      90022  'neck stiffness'  '473 487'          905\n",
       "...      ...               ...        ...          ...\n",
       "1604   95143     'denies rash'  '307 318'          907\n",
       "1605   95162     'denies rash'  '313 324'          907\n",
       "1606   95226       'No rashes'  '442 451'          907\n",
       "1607   95275     'Denies rash'  '448 459'          907\n",
       "1608   95307     'denies rash'  '379 390'          907\n",
       "\n",
       "[1609 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (df.set_index(['pn_num',\"feature_num\"]) \n",
    "   .apply(lambda col: col.str.split(',').explode())\n",
    "   .reset_index()\n",
    "   .reindex(df.columns, axis=1))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da0c730b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90000</td>\n",
       "      <td>'neck pain'</td>\n",
       "      <td>'580 589'</td>\n",
       "      <td>905</td>\n",
       "      <td>580</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90001</td>\n",
       "      <td>'neck stiffness'</td>\n",
       "      <td>'390 404'</td>\n",
       "      <td>905</td>\n",
       "      <td>390</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90007</td>\n",
       "      <td>'neck stiffness'</td>\n",
       "      <td>'188 202'</td>\n",
       "      <td>905</td>\n",
       "      <td>188</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90011</td>\n",
       "      <td>'neck pain'</td>\n",
       "      <td>'381 390'</td>\n",
       "      <td>905</td>\n",
       "      <td>381</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90022</td>\n",
       "      <td>'neck stiffness'</td>\n",
       "      <td>'473 487'</td>\n",
       "      <td>905</td>\n",
       "      <td>473</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>95143</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'307 318'</td>\n",
       "      <td>907</td>\n",
       "      <td>307</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>95162</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'313 324'</td>\n",
       "      <td>907</td>\n",
       "      <td>313</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>95226</td>\n",
       "      <td>'No rashes'</td>\n",
       "      <td>'442 451'</td>\n",
       "      <td>907</td>\n",
       "      <td>442</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>95275</td>\n",
       "      <td>'Denies rash'</td>\n",
       "      <td>'448 459'</td>\n",
       "      <td>907</td>\n",
       "      <td>448</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>95307</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'379 390'</td>\n",
       "      <td>907</td>\n",
       "      <td>379</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num        annotation   location  feature_num start_location  \\\n",
       "0      90000       'neck pain'  '580 589'          905            580   \n",
       "1      90001  'neck stiffness'  '390 404'          905            390   \n",
       "2      90007  'neck stiffness'  '188 202'          905            188   \n",
       "3      90011       'neck pain'  '381 390'          905            381   \n",
       "4      90022  'neck stiffness'  '473 487'          905            473   \n",
       "...      ...               ...        ...          ...            ...   \n",
       "1604   95143     'denies rash'  '307 318'          907            307   \n",
       "1605   95162     'denies rash'  '313 324'          907            313   \n",
       "1606   95226       'No rashes'  '442 451'          907            442   \n",
       "1607   95275     'Denies rash'  '448 459'          907            448   \n",
       "1608   95307     'denies rash'  '379 390'          907            379   \n",
       "\n",
       "     end_location  \n",
       "0             589  \n",
       "1             404  \n",
       "2             202  \n",
       "3             390  \n",
       "4             487  \n",
       "...           ...  \n",
       "1604          318  \n",
       "1605          324  \n",
       "1606          451  \n",
       "1607          459  \n",
       "1608          390  \n",
       "\n",
       "[1609 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"start_location\"] = df[\"location\"].apply(lambda x: x.split()[0][1:])\n",
    "df[\"end_location\"] = df[\"location\"].apply(lambda x: x.split()[-1][:-1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9568c497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_905 = df[df[\"feature_num\"] == 905].sample(n = 160, random_state = 100)\n",
    "df_905.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9439ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_907 = df[df[\"feature_num\"] == 907].sample(n = 150, random_state = 100)\n",
    "df_907.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a012d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bece38eb",
   "metadata": {},
   "source": [
    "### Case - 9 Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b027bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_train = case_9_train[['pn_num','annotation',\"location\",\"feature_num\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a7e636e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief', 'ibuprofen no relief'</td>\n",
       "      <td>'251 258;284 293', '264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12601</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12606</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608</th>\n",
       "      <td>90127</td>\n",
       "      <td>'nausea'</td>\n",
       "      <td>'321 327'</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14291</th>\n",
       "      <td>95333</td>\n",
       "      <td>'Nausea'</td>\n",
       "      <td>'354 360'</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14293</th>\n",
       "      <td>95333</td>\n",
       "      <td>'lives with roomate'</td>\n",
       "      <td>'576 594'</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14297</th>\n",
       "      <td>95333</td>\n",
       "      <td>'photobia'</td>\n",
       "      <td>'274 282'</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>95333</td>\n",
       "      <td>'no sick contacts'</td>\n",
       "      <td>'421 437'</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>95333</td>\n",
       "      <td>'Subjective fever'</td>\n",
       "      <td>'314 330'</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pn_num                                  annotation  \\\n",
       "12600   90127  'tylenol no relief', 'ibuprofen no relief'   \n",
       "12601   90127                               '20 year old'   \n",
       "12602   90127                                 'yesterday'   \n",
       "12606   90127                                  'vomiting'   \n",
       "12608   90127                                    'nausea'   \n",
       "...       ...                                         ...   \n",
       "14291   95333                                    'Nausea'   \n",
       "14293   95333                        'lives with roomate'   \n",
       "14297   95333                                  'photobia'   \n",
       "14298   95333                          'no sick contacts'   \n",
       "14299   95333                          'Subjective fever'   \n",
       "\n",
       "                                   location  feature_num  \n",
       "12600  '251 258;284 293', '264 273;284 293'          900  \n",
       "12601                               '34 45'          901  \n",
       "12602                             '102 111'          902  \n",
       "12606                             '347 355'          906  \n",
       "12608                             '321 327'          908  \n",
       "...                                     ...          ...  \n",
       "14291                             '354 360'          908  \n",
       "14293                             '576 594'          910  \n",
       "14297                             '274 282'          914  \n",
       "14298                             '421 437'          915  \n",
       "14299                             '314 330'          916  \n",
       "\n",
       "[992 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_train[\"annotation\"] = case_9_train.annotation.str.replace('[','')\n",
    "case_9_train[\"annotation\"] = case_9_train.annotation.str.replace(']','')\n",
    "case_9_train[\"location\"] = case_9_train.location.str.replace('[','')\n",
    "case_9_train[\"location\"] = case_9_train.location.str.replace(']','')\n",
    "\n",
    "case_9_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "203f795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_train.loc[case_9_train[\"annotation\"] == \"'ibuprofen not better', 'tylenol , not better'\",\"annotation\"] = \"'ibuprofen not better', 'tylenol   not better'\"\n",
    "case_9_train.loc[case_9_train[\"annotation\"] == \"'HA front, back, and on sides of head'\",\"annotation\"] = \"'HA front  back  and on sides of head'\"\n",
    "case_9_train.loc[case_9_train[\"annotation\"] == \"'headache , generalised'\",\"annotation\"] = \"'headache   generalised'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8efcb7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief'</td>\n",
       "      <td>'251 258;284 293'</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90127</td>\n",
       "      <td>'ibuprofen no relief'</td>\n",
       "      <td>'264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>95333</td>\n",
       "      <td>'Nausea'</td>\n",
       "      <td>'354 360'</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>95333</td>\n",
       "      <td>'lives with roomate'</td>\n",
       "      <td>'576 594'</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>95333</td>\n",
       "      <td>'photobia'</td>\n",
       "      <td>'274 282'</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>95333</td>\n",
       "      <td>'no sick contacts'</td>\n",
       "      <td>'421 437'</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>95333</td>\n",
       "      <td>'Subjective fever'</td>\n",
       "      <td>'314 330'</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num              annotation            location  feature_num\n",
       "0      90127     'tylenol no relief'   '251 258;284 293'          900\n",
       "1      90127   'ibuprofen no relief'   '264 273;284 293'          900\n",
       "2      90127           '20 year old'             '34 45'          901\n",
       "3      90127             'yesterday'           '102 111'          902\n",
       "4      90127              'vomiting'           '347 355'          906\n",
       "...      ...                     ...                 ...          ...\n",
       "1208   95333                'Nausea'           '354 360'          908\n",
       "1209   95333    'lives with roomate'           '576 594'          910\n",
       "1210   95333              'photobia'           '274 282'          914\n",
       "1211   95333      'no sick contacts'           '421 437'          915\n",
       "1212   95333      'Subjective fever'           '314 330'          916\n",
       "\n",
       "[1213 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_train = (case_9_train.set_index(['pn_num',\"feature_num\"]) \n",
    "   .apply(lambda col: col.str.split(',').explode())\n",
    "   .reset_index()\n",
    "   .reindex(case_9_train.columns, axis=1))\n",
    "case_9_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd99c1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief'</td>\n",
       "      <td>'251 258;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>251</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90127</td>\n",
       "      <td>'ibuprofen no relief'</td>\n",
       "      <td>'264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>264</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "      <td>102</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "      <td>347</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>95333</td>\n",
       "      <td>'Nausea'</td>\n",
       "      <td>'354 360'</td>\n",
       "      <td>908</td>\n",
       "      <td>354</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>95333</td>\n",
       "      <td>'lives with roomate'</td>\n",
       "      <td>'576 594'</td>\n",
       "      <td>910</td>\n",
       "      <td>576</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>95333</td>\n",
       "      <td>'photobia'</td>\n",
       "      <td>'274 282'</td>\n",
       "      <td>914</td>\n",
       "      <td>274</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>95333</td>\n",
       "      <td>'no sick contacts'</td>\n",
       "      <td>'421 437'</td>\n",
       "      <td>915</td>\n",
       "      <td>421</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>95333</td>\n",
       "      <td>'Subjective fever'</td>\n",
       "      <td>'314 330'</td>\n",
       "      <td>916</td>\n",
       "      <td>314</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num              annotation            location  feature_num  \\\n",
       "0      90127     'tylenol no relief'   '251 258;284 293'          900   \n",
       "1      90127   'ibuprofen no relief'   '264 273;284 293'          900   \n",
       "2      90127           '20 year old'             '34 45'          901   \n",
       "3      90127             'yesterday'           '102 111'          902   \n",
       "4      90127              'vomiting'           '347 355'          906   \n",
       "...      ...                     ...                 ...          ...   \n",
       "1208   95333                'Nausea'           '354 360'          908   \n",
       "1209   95333    'lives with roomate'           '576 594'          910   \n",
       "1210   95333              'photobia'           '274 282'          914   \n",
       "1211   95333      'no sick contacts'           '421 437'          915   \n",
       "1212   95333      'Subjective fever'           '314 330'          916   \n",
       "\n",
       "     start_location end_location  \n",
       "0               251          293  \n",
       "1               264          293  \n",
       "2                34           45  \n",
       "3               102          111  \n",
       "4               347          355  \n",
       "...             ...          ...  \n",
       "1208            354          360  \n",
       "1209            576          594  \n",
       "1210            274          282  \n",
       "1211            421          437  \n",
       "1212            314          330  \n",
       "\n",
       "[1213 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_train[\"start_location\"] = case_9_train[\"location\"].apply(lambda x: x.split()[0][1:])\n",
    "case_9_train[\"end_location\"] = case_9_train[\"location\"].apply(lambda x: x.split()[-1][:-1])\n",
    "case_9_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "537d85e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9 = pd.concat([case_9_train, df_905, df_907])\n",
    "case_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26575bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief'</td>\n",
       "      <td>'251 258;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>251</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90127</td>\n",
       "      <td>'ibuprofen no relief'</td>\n",
       "      <td>'264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>264</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "      <td>102</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "      <td>347</td>\n",
       "      <td>355</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>93959</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'384 395'</td>\n",
       "      <td>907</td>\n",
       "      <td>384</td>\n",
       "      <td>395</td>\n",
       "      <td>9</td>\n",
       "      <td>20 yo F c/o headache that started 2 days ago, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>92690</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'493 504'</td>\n",
       "      <td>907</td>\n",
       "      <td>493</td>\n",
       "      <td>504</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F complaining of H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>92872</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'483 490'</td>\n",
       "      <td>907</td>\n",
       "      <td>483</td>\n",
       "      <td>490</td>\n",
       "      <td>9</td>\n",
       "      <td>Patient is a 20 yo F presenting with c/o of he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>94339</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'688 695'</td>\n",
       "      <td>907</td>\n",
       "      <td>688</td>\n",
       "      <td>695</td>\n",
       "      <td>9</td>\n",
       "      <td>The patient is a 20 yo female presenting with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>94603</td>\n",
       "      <td>'Denies rash'</td>\n",
       "      <td>'355 366'</td>\n",
       "      <td>907</td>\n",
       "      <td>355</td>\n",
       "      <td>366</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F who presents wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1523 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num              annotation            location  feature_num  \\\n",
       "0      90127     'tylenol no relief'   '251 258;284 293'          900   \n",
       "1      90127   'ibuprofen no relief'   '264 273;284 293'          900   \n",
       "2      90127           '20 year old'             '34 45'          901   \n",
       "3      90127             'yesterday'           '102 111'          902   \n",
       "4      90127              'vomiting'           '347 355'          906   \n",
       "...      ...                     ...                 ...          ...   \n",
       "1518   93959           'denies rash'           '384 395'          907   \n",
       "1519   92690           'denies rash'           '493 504'          907   \n",
       "1520   92872               'no rash'           '483 490'          907   \n",
       "1521   94339               'no rash'           '688 695'          907   \n",
       "1522   94603           'Denies rash'           '355 366'          907   \n",
       "\n",
       "     start_location end_location  case_num  \\\n",
       "0               251          293         9   \n",
       "1               264          293         9   \n",
       "2                34           45         9   \n",
       "3               102          111         9   \n",
       "4               347          355         9   \n",
       "...             ...          ...       ...   \n",
       "1518            384          395         9   \n",
       "1519            493          504         9   \n",
       "1520            483          490         9   \n",
       "1521            688          695         9   \n",
       "1522            355          366         9   \n",
       "\n",
       "                                             pn_history  \n",
       "0     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...  \n",
       "1     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...  \n",
       "2     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...  \n",
       "3     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...  \n",
       "4     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...  \n",
       "...                                                 ...  \n",
       "1518  20 yo F c/o headache that started 2 days ago, ...  \n",
       "1519  Stephanie Madden is a 20 yo F complaining of H...  \n",
       "1520  Patient is a 20 yo F presenting with c/o of he...  \n",
       "1521  The patient is a 20 yo female presenting with ...  \n",
       "1522  Stephanie Madden is a 20 yo F who presents wit...  \n",
       "\n",
       "[1523 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9 = case_9.merge(patient_notes, on='pn_num', how='left')\n",
    "case_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22f0fbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief'</td>\n",
       "      <td>'251 258;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>251</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>tylenol, and ibuprofen and found no relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90127</td>\n",
       "      <td>'ibuprofen no relief'</td>\n",
       "      <td>'264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>264</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>ibuprofen and found no relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>20 year old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "      <td>102</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "      <td>347</td>\n",
       "      <td>355</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>vomiting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pn_num              annotation            location  feature_num  \\\n",
       "0   90127     'tylenol no relief'   '251 258;284 293'          900   \n",
       "1   90127   'ibuprofen no relief'   '264 273;284 293'          900   \n",
       "2   90127           '20 year old'             '34 45'          901   \n",
       "3   90127             'yesterday'           '102 111'          902   \n",
       "4   90127              'vomiting'           '347 355'          906   \n",
       "\n",
       "  start_location end_location  case_num  \\\n",
       "0            251          293         9   \n",
       "1            264          293         9   \n",
       "2             34           45         9   \n",
       "3            102          111         9   \n",
       "4            347          355         9   \n",
       "\n",
       "                                          pn_history  \\\n",
       "0  CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "1  CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "2  CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "3  CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "4  CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "\n",
       "                               New_annotation  \n",
       "0  tylenol, and ibuprofen and found no relief  \n",
       "1               ibuprofen and found no relief  \n",
       "2                                 20 year old  \n",
       "3                                   yesterday  \n",
       "4                                    vomiting  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9[\"New_annotation\"] = case_9.apply(lambda x: x.pn_history[int(x.start_location):int(x.end_location)],axis=1)\n",
    "case_9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "088e7d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief'</td>\n",
       "      <td>'251 258;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>251</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>tylenol  and ibuprofen and found no relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90127</td>\n",
       "      <td>'ibuprofen no relief'</td>\n",
       "      <td>'264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>264</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>ibuprofen and found no relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>20 year old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "      <td>102</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "      <td>347</td>\n",
       "      <td>355</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>vomiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>93959</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'384 395'</td>\n",
       "      <td>907</td>\n",
       "      <td>384</td>\n",
       "      <td>395</td>\n",
       "      <td>9</td>\n",
       "      <td>20 yo F c/o headache that started 2 days ago, ...</td>\n",
       "      <td>denies rash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>92690</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'493 504'</td>\n",
       "      <td>907</td>\n",
       "      <td>493</td>\n",
       "      <td>504</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F complaining of H...</td>\n",
       "      <td>denies rash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>92872</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'483 490'</td>\n",
       "      <td>907</td>\n",
       "      <td>483</td>\n",
       "      <td>490</td>\n",
       "      <td>9</td>\n",
       "      <td>Patient is a 20 yo F presenting with c/o of he...</td>\n",
       "      <td>no rash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>94339</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'688 695'</td>\n",
       "      <td>907</td>\n",
       "      <td>688</td>\n",
       "      <td>695</td>\n",
       "      <td>9</td>\n",
       "      <td>The patient is a 20 yo female presenting with ...</td>\n",
       "      <td>no rash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>94603</td>\n",
       "      <td>'Denies rash'</td>\n",
       "      <td>'355 366'</td>\n",
       "      <td>907</td>\n",
       "      <td>355</td>\n",
       "      <td>366</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F who presents wit...</td>\n",
       "      <td>Denies rash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1523 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num              annotation            location  feature_num  \\\n",
       "0      90127     'tylenol no relief'   '251 258;284 293'          900   \n",
       "1      90127   'ibuprofen no relief'   '264 273;284 293'          900   \n",
       "2      90127           '20 year old'             '34 45'          901   \n",
       "3      90127             'yesterday'           '102 111'          902   \n",
       "4      90127              'vomiting'           '347 355'          906   \n",
       "...      ...                     ...                 ...          ...   \n",
       "1518   93959           'denies rash'           '384 395'          907   \n",
       "1519   92690           'denies rash'           '493 504'          907   \n",
       "1520   92872               'no rash'           '483 490'          907   \n",
       "1521   94339               'no rash'           '688 695'          907   \n",
       "1522   94603           'Denies rash'           '355 366'          907   \n",
       "\n",
       "     start_location end_location  case_num  \\\n",
       "0               251          293         9   \n",
       "1               264          293         9   \n",
       "2                34           45         9   \n",
       "3               102          111         9   \n",
       "4               347          355         9   \n",
       "...             ...          ...       ...   \n",
       "1518            384          395         9   \n",
       "1519            493          504         9   \n",
       "1520            483          490         9   \n",
       "1521            688          695         9   \n",
       "1522            355          366         9   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "1     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "2     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "3     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "4     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "...                                                 ...   \n",
       "1518  20 yo F c/o headache that started 2 days ago, ...   \n",
       "1519  Stephanie Madden is a 20 yo F complaining of H...   \n",
       "1520  Patient is a 20 yo F presenting with c/o of he...   \n",
       "1521  The patient is a 20 yo female presenting with ...   \n",
       "1522  Stephanie Madden is a 20 yo F who presents wit...   \n",
       "\n",
       "                                  New_annotation  \n",
       "0     tylenol  and ibuprofen and found no relief  \n",
       "1                  ibuprofen and found no relief  \n",
       "2                                    20 year old  \n",
       "3                                      yesterday  \n",
       "4                                       vomiting  \n",
       "...                                          ...  \n",
       "1518                                 denies rash  \n",
       "1519                                 denies rash  \n",
       "1520                                     no rash  \n",
       "1521                                     no rash  \n",
       "1522                                 Denies rash  \n",
       "\n",
       "[1523 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9[\"New_annotation\"] = case_9[\"New_annotation\"].apply(lambda x: re.sub(r'''[/\"+,()\\r\\n]''',' ',x))\n",
    "case_9[\"New_annotation\"] = case_9[\"New_annotation\"].apply(lambda x: re.sub(r'''[']''','',x))\n",
    "case_9[\"New_annotation\"] = case_9[\"New_annotation\"].apply(lambda x: x.strip())\n",
    "case_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7a6bede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "      <th>New_pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief'</td>\n",
       "      <td>'251 258;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>251</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>tylenol  and ibuprofen and found no relief</td>\n",
       "      <td>CC: Headache  HPI: Ms Maddon is a 20 year old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90127</td>\n",
       "      <td>'ibuprofen no relief'</td>\n",
       "      <td>'264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>264</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>ibuprofen and found no relief</td>\n",
       "      <td>CC: Headache  HPI: Ms Maddon is a 20 year old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>20 year old</td>\n",
       "      <td>CC: Headache  HPI: Ms Maddon is a 20 year old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "      <td>102</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>CC: Headache  HPI: Ms Maddon is a 20 year old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "      <td>347</td>\n",
       "      <td>355</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>vomiting</td>\n",
       "      <td>CC: Headache  HPI: Ms Maddon is a 20 year old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>93959</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'384 395'</td>\n",
       "      <td>907</td>\n",
       "      <td>384</td>\n",
       "      <td>395</td>\n",
       "      <td>9</td>\n",
       "      <td>20 yo F c/o headache that started 2 days ago, ...</td>\n",
       "      <td>denies rash</td>\n",
       "      <td>20 yo F c o headache that started 2 days ago  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>92690</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'493 504'</td>\n",
       "      <td>907</td>\n",
       "      <td>493</td>\n",
       "      <td>504</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F complaining of H...</td>\n",
       "      <td>denies rash</td>\n",
       "      <td>Stephanie Madden is a 20 yo F complaining of H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>92872</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'483 490'</td>\n",
       "      <td>907</td>\n",
       "      <td>483</td>\n",
       "      <td>490</td>\n",
       "      <td>9</td>\n",
       "      <td>Patient is a 20 yo F presenting with c/o of he...</td>\n",
       "      <td>no rash</td>\n",
       "      <td>Patient is a 20 yo F presenting with c o of he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>94339</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'688 695'</td>\n",
       "      <td>907</td>\n",
       "      <td>688</td>\n",
       "      <td>695</td>\n",
       "      <td>9</td>\n",
       "      <td>The patient is a 20 yo female presenting with ...</td>\n",
       "      <td>no rash</td>\n",
       "      <td>The patient is a 20 yo female presenting with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>94603</td>\n",
       "      <td>'Denies rash'</td>\n",
       "      <td>'355 366'</td>\n",
       "      <td>907</td>\n",
       "      <td>355</td>\n",
       "      <td>366</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F who presents wit...</td>\n",
       "      <td>Denies rash</td>\n",
       "      <td>Stephanie Madden is a 20 yo F who presents wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1523 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num              annotation            location  feature_num  \\\n",
       "0      90127     'tylenol no relief'   '251 258;284 293'          900   \n",
       "1      90127   'ibuprofen no relief'   '264 273;284 293'          900   \n",
       "2      90127           '20 year old'             '34 45'          901   \n",
       "3      90127             'yesterday'           '102 111'          902   \n",
       "4      90127              'vomiting'           '347 355'          906   \n",
       "...      ...                     ...                 ...          ...   \n",
       "1518   93959           'denies rash'           '384 395'          907   \n",
       "1519   92690           'denies rash'           '493 504'          907   \n",
       "1520   92872               'no rash'           '483 490'          907   \n",
       "1521   94339               'no rash'           '688 695'          907   \n",
       "1522   94603           'Denies rash'           '355 366'          907   \n",
       "\n",
       "     start_location end_location  case_num  \\\n",
       "0               251          293         9   \n",
       "1               264          293         9   \n",
       "2                34           45         9   \n",
       "3               102          111         9   \n",
       "4               347          355         9   \n",
       "...             ...          ...       ...   \n",
       "1518            384          395         9   \n",
       "1519            493          504         9   \n",
       "1520            483          490         9   \n",
       "1521            688          695         9   \n",
       "1522            355          366         9   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "1     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "2     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "3     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "4     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "...                                                 ...   \n",
       "1518  20 yo F c/o headache that started 2 days ago, ...   \n",
       "1519  Stephanie Madden is a 20 yo F complaining of H...   \n",
       "1520  Patient is a 20 yo F presenting with c/o of he...   \n",
       "1521  The patient is a 20 yo female presenting with ...   \n",
       "1522  Stephanie Madden is a 20 yo F who presents wit...   \n",
       "\n",
       "                                  New_annotation  \\\n",
       "0     tylenol  and ibuprofen and found no relief   \n",
       "1                  ibuprofen and found no relief   \n",
       "2                                    20 year old   \n",
       "3                                      yesterday   \n",
       "4                                       vomiting   \n",
       "...                                          ...   \n",
       "1518                                 denies rash   \n",
       "1519                                 denies rash   \n",
       "1520                                     no rash   \n",
       "1521                                     no rash   \n",
       "1522                                 Denies rash   \n",
       "\n",
       "                                         New_pn_history  \n",
       "0     CC: Headache  HPI: Ms Maddon is a 20 year old ...  \n",
       "1     CC: Headache  HPI: Ms Maddon is a 20 year old ...  \n",
       "2     CC: Headache  HPI: Ms Maddon is a 20 year old ...  \n",
       "3     CC: Headache  HPI: Ms Maddon is a 20 year old ...  \n",
       "4     CC: Headache  HPI: Ms Maddon is a 20 year old ...  \n",
       "...                                                 ...  \n",
       "1518  20 yo F c o headache that started 2 days ago  ...  \n",
       "1519  Stephanie Madden is a 20 yo F complaining of H...  \n",
       "1520  Patient is a 20 yo F presenting with c o of he...  \n",
       "1521  The patient is a 20 yo female presenting with ...  \n",
       "1522  Stephanie Madden is a 20 yo F who presents wit...  \n",
       "\n",
       "[1523 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9[\"New_pn_history\"] = case_9[\"pn_history\"].apply(lambda x: re.sub(r'''[/\",+()\\r\\n]''',' ',x))\n",
    "case_9[\"New_pn_history\"] = case_9[\"New_pn_history\"].apply(lambda x: re.sub(r'''[']''','',x))\n",
    "case_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daea8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemm(sentence):\n",
    "    word_list = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    lemmaztier = WordNetLemmatizer()\n",
    "    lemmatized_output = ' '.join([lemmaztier.lemmatize(w) for w in word_list])\n",
    "    return(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfe57215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "      <th>New_pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief'</td>\n",
       "      <td>'251 258;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>251</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>tylenol and ibuprofen and found no relief</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90127</td>\n",
       "      <td>'ibuprofen no relief'</td>\n",
       "      <td>'264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>264</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>ibuprofen and found no relief</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>20 year old</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "      <td>102</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "      <td>347</td>\n",
       "      <td>355</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>vomiting</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pn_num              annotation            location  feature_num  \\\n",
       "0   90127     'tylenol no relief'   '251 258;284 293'          900   \n",
       "1   90127   'ibuprofen no relief'   '264 273;284 293'          900   \n",
       "2   90127           '20 year old'             '34 45'          901   \n",
       "3   90127             'yesterday'           '102 111'          902   \n",
       "4   90127              'vomiting'           '347 355'          906   \n",
       "\n",
       "  start_location end_location  case_num  \\\n",
       "0            251          293         9   \n",
       "1            264          293         9   \n",
       "2             34           45         9   \n",
       "3            102          111         9   \n",
       "4            347          355         9   \n",
       "\n",
       "                                          pn_history  \\\n",
       "0  CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "1  CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "2  CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "3  CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "4  CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "\n",
       "                              New_annotation  \\\n",
       "0  tylenol and ibuprofen and found no relief   \n",
       "1              ibuprofen and found no relief   \n",
       "2                                20 year old   \n",
       "3                                  yesterday   \n",
       "4                                   vomiting   \n",
       "\n",
       "                                      New_pn_history  \n",
       "0  CC : Headache HPI : Ms Maddon is a 20 year old...  \n",
       "1  CC : Headache HPI : Ms Maddon is a 20 year old...  \n",
       "2  CC : Headache HPI : Ms Maddon is a 20 year old...  \n",
       "3  CC : Headache HPI : Ms Maddon is a 20 year old...  \n",
       "4  CC : Headache HPI : Ms Maddon is a 20 year old...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9[\"New_annotation\"] = case_9[\"New_annotation\"].apply(word_lemm)\n",
    "case_9[\"New_pn_history\"] = case_9[\"New_pn_history\"].apply(word_lemm)\n",
    "case_9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "499502ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "      <th>New_pn_history</th>\n",
       "      <th>new_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief'</td>\n",
       "      <td>'251 258;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>251</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>tylenol and ibuprofen and found no relief</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(248, 289), match='tyle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90127</td>\n",
       "      <td>'ibuprofen no relief'</td>\n",
       "      <td>'264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>264</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>ibuprofen and found no relief</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(260, 289), match='ibup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>20 year old</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(35, 46), match='20 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "      <td>102</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(102, 111), match='yest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "      <td>347</td>\n",
       "      <td>355</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>vomiting</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(341, 349), match='vomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>93959</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'384 395'</td>\n",
       "      <td>907</td>\n",
       "      <td>384</td>\n",
       "      <td>395</td>\n",
       "      <td>9</td>\n",
       "      <td>20 yo F c/o headache that started 2 days ago, ...</td>\n",
       "      <td>denies rash</td>\n",
       "      <td>20 yo F c o headache that started 2 day ago de...</td>\n",
       "      <td>&lt;re.Match object; span=(370, 381), match='deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>92690</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'493 504'</td>\n",
       "      <td>907</td>\n",
       "      <td>493</td>\n",
       "      <td>504</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F complaining of H...</td>\n",
       "      <td>denies rash</td>\n",
       "      <td>Stephanie Madden is a 20 yo F complaining of H...</td>\n",
       "      <td>&lt;re.Match object; span=(487, 498), match='deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>92872</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'483 490'</td>\n",
       "      <td>907</td>\n",
       "      <td>483</td>\n",
       "      <td>490</td>\n",
       "      <td>9</td>\n",
       "      <td>Patient is a 20 yo F presenting with c/o of he...</td>\n",
       "      <td>no rash</td>\n",
       "      <td>Patient is a 20 yo F presenting with c o of he...</td>\n",
       "      <td>&lt;re.Match object; span=(485, 492), match='no r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>94339</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'688 695'</td>\n",
       "      <td>907</td>\n",
       "      <td>688</td>\n",
       "      <td>695</td>\n",
       "      <td>9</td>\n",
       "      <td>The patient is a 20 yo female presenting with ...</td>\n",
       "      <td>no rash</td>\n",
       "      <td>The patient is a 20 yo female presenting with ...</td>\n",
       "      <td>&lt;re.Match object; span=(670, 677), match='no r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>94603</td>\n",
       "      <td>'Denies rash'</td>\n",
       "      <td>'355 366'</td>\n",
       "      <td>907</td>\n",
       "      <td>355</td>\n",
       "      <td>366</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F who presents wit...</td>\n",
       "      <td>Denies rash</td>\n",
       "      <td>Stephanie Madden is a 20 yo F who present with...</td>\n",
       "      <td>&lt;re.Match object; span=(353, 364), match='Deni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1523 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num              annotation            location  feature_num  \\\n",
       "0      90127     'tylenol no relief'   '251 258;284 293'          900   \n",
       "1      90127   'ibuprofen no relief'   '264 273;284 293'          900   \n",
       "2      90127           '20 year old'             '34 45'          901   \n",
       "3      90127             'yesterday'           '102 111'          902   \n",
       "4      90127              'vomiting'           '347 355'          906   \n",
       "...      ...                     ...                 ...          ...   \n",
       "1518   93959           'denies rash'           '384 395'          907   \n",
       "1519   92690           'denies rash'           '493 504'          907   \n",
       "1520   92872               'no rash'           '483 490'          907   \n",
       "1521   94339               'no rash'           '688 695'          907   \n",
       "1522   94603           'Denies rash'           '355 366'          907   \n",
       "\n",
       "     start_location end_location  case_num  \\\n",
       "0               251          293         9   \n",
       "1               264          293         9   \n",
       "2                34           45         9   \n",
       "3               102          111         9   \n",
       "4               347          355         9   \n",
       "...             ...          ...       ...   \n",
       "1518            384          395         9   \n",
       "1519            493          504         9   \n",
       "1520            483          490         9   \n",
       "1521            688          695         9   \n",
       "1522            355          366         9   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "1     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "2     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "3     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "4     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "...                                                 ...   \n",
       "1518  20 yo F c/o headache that started 2 days ago, ...   \n",
       "1519  Stephanie Madden is a 20 yo F complaining of H...   \n",
       "1520  Patient is a 20 yo F presenting with c/o of he...   \n",
       "1521  The patient is a 20 yo female presenting with ...   \n",
       "1522  Stephanie Madden is a 20 yo F who presents wit...   \n",
       "\n",
       "                                 New_annotation  \\\n",
       "0     tylenol and ibuprofen and found no relief   \n",
       "1                 ibuprofen and found no relief   \n",
       "2                                   20 year old   \n",
       "3                                     yesterday   \n",
       "4                                      vomiting   \n",
       "...                                         ...   \n",
       "1518                                denies rash   \n",
       "1519                                denies rash   \n",
       "1520                                    no rash   \n",
       "1521                                    no rash   \n",
       "1522                                Denies rash   \n",
       "\n",
       "                                         New_pn_history  \\\n",
       "0     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "1     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "2     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "3     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "4     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "...                                                 ...   \n",
       "1518  20 yo F c o headache that started 2 day ago de...   \n",
       "1519  Stephanie Madden is a 20 yo F complaining of H...   \n",
       "1520  Patient is a 20 yo F presenting with c o of he...   \n",
       "1521  The patient is a 20 yo female presenting with ...   \n",
       "1522  Stephanie Madden is a 20 yo F who present with...   \n",
       "\n",
       "                                           new_location  \n",
       "0     <re.Match object; span=(248, 289), match='tyle...  \n",
       "1     <re.Match object; span=(260, 289), match='ibup...  \n",
       "2     <re.Match object; span=(35, 46), match='20 yea...  \n",
       "3     <re.Match object; span=(102, 111), match='yest...  \n",
       "4     <re.Match object; span=(341, 349), match='vomi...  \n",
       "...                                                 ...  \n",
       "1518  <re.Match object; span=(370, 381), match='deni...  \n",
       "1519  <re.Match object; span=(487, 498), match='deni...  \n",
       "1520  <re.Match object; span=(485, 492), match='no r...  \n",
       "1521  <re.Match object; span=(670, 677), match='no r...  \n",
       "1522  <re.Match object; span=(353, 364), match='Deni...  \n",
       "\n",
       "[1523 rows x 11 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9[\"new_location\"] = case_9.apply(lambda x :re.search(r'\\b' + x.New_annotation + r'\\b', x.New_pn_history),axis =1)\n",
    "case_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edbea142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[304, 308, 309, 312, 463, 591, 656, 665, 763, 764, 906, 909, 915, 930, 1025, 1083, 1169, 1170, 1418]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 19)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_index = []\n",
    "for  index,row in case_9.iterrows():\n",
    "    if row[\"new_location\"] == None:\n",
    "        drop_index.append(index)\n",
    "        \n",
    "print(drop_index),len(drop_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e01a9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "      <th>New_pn_history</th>\n",
       "      <th>new_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief'</td>\n",
       "      <td>'251 258;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>251</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>tylenol and ibuprofen and found no relief</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(248, 289), match='tyle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90127</td>\n",
       "      <td>'ibuprofen no relief'</td>\n",
       "      <td>'264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>264</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>ibuprofen and found no relief</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(260, 289), match='ibup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>20 year old</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(35, 46), match='20 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "      <td>102</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(102, 111), match='yest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "      <td>347</td>\n",
       "      <td>355</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>vomiting</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(341, 349), match='vomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>93959</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'384 395'</td>\n",
       "      <td>907</td>\n",
       "      <td>384</td>\n",
       "      <td>395</td>\n",
       "      <td>9</td>\n",
       "      <td>20 yo F c/o headache that started 2 days ago, ...</td>\n",
       "      <td>denies rash</td>\n",
       "      <td>20 yo F c o headache that started 2 day ago de...</td>\n",
       "      <td>&lt;re.Match object; span=(370, 381), match='deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>92690</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'493 504'</td>\n",
       "      <td>907</td>\n",
       "      <td>493</td>\n",
       "      <td>504</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F complaining of H...</td>\n",
       "      <td>denies rash</td>\n",
       "      <td>Stephanie Madden is a 20 yo F complaining of H...</td>\n",
       "      <td>&lt;re.Match object; span=(487, 498), match='deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>92872</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'483 490'</td>\n",
       "      <td>907</td>\n",
       "      <td>483</td>\n",
       "      <td>490</td>\n",
       "      <td>9</td>\n",
       "      <td>Patient is a 20 yo F presenting with c/o of he...</td>\n",
       "      <td>no rash</td>\n",
       "      <td>Patient is a 20 yo F presenting with c o of he...</td>\n",
       "      <td>&lt;re.Match object; span=(485, 492), match='no r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>94339</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'688 695'</td>\n",
       "      <td>907</td>\n",
       "      <td>688</td>\n",
       "      <td>695</td>\n",
       "      <td>9</td>\n",
       "      <td>The patient is a 20 yo female presenting with ...</td>\n",
       "      <td>no rash</td>\n",
       "      <td>The patient is a 20 yo female presenting with ...</td>\n",
       "      <td>&lt;re.Match object; span=(670, 677), match='no r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>94603</td>\n",
       "      <td>'Denies rash'</td>\n",
       "      <td>'355 366'</td>\n",
       "      <td>907</td>\n",
       "      <td>355</td>\n",
       "      <td>366</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F who presents wit...</td>\n",
       "      <td>Denies rash</td>\n",
       "      <td>Stephanie Madden is a 20 yo F who present with...</td>\n",
       "      <td>&lt;re.Match object; span=(353, 364), match='Deni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1504 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num              annotation            location  feature_num  \\\n",
       "0      90127     'tylenol no relief'   '251 258;284 293'          900   \n",
       "1      90127   'ibuprofen no relief'   '264 273;284 293'          900   \n",
       "2      90127           '20 year old'             '34 45'          901   \n",
       "3      90127             'yesterday'           '102 111'          902   \n",
       "4      90127              'vomiting'           '347 355'          906   \n",
       "...      ...                     ...                 ...          ...   \n",
       "1518   93959           'denies rash'           '384 395'          907   \n",
       "1519   92690           'denies rash'           '493 504'          907   \n",
       "1520   92872               'no rash'           '483 490'          907   \n",
       "1521   94339               'no rash'           '688 695'          907   \n",
       "1522   94603           'Denies rash'           '355 366'          907   \n",
       "\n",
       "     start_location end_location  case_num  \\\n",
       "0               251          293         9   \n",
       "1               264          293         9   \n",
       "2                34           45         9   \n",
       "3               102          111         9   \n",
       "4               347          355         9   \n",
       "...             ...          ...       ...   \n",
       "1518            384          395         9   \n",
       "1519            493          504         9   \n",
       "1520            483          490         9   \n",
       "1521            688          695         9   \n",
       "1522            355          366         9   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "1     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "2     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "3     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "4     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "...                                                 ...   \n",
       "1518  20 yo F c/o headache that started 2 days ago, ...   \n",
       "1519  Stephanie Madden is a 20 yo F complaining of H...   \n",
       "1520  Patient is a 20 yo F presenting with c/o of he...   \n",
       "1521  The patient is a 20 yo female presenting with ...   \n",
       "1522  Stephanie Madden is a 20 yo F who presents wit...   \n",
       "\n",
       "                                 New_annotation  \\\n",
       "0     tylenol and ibuprofen and found no relief   \n",
       "1                 ibuprofen and found no relief   \n",
       "2                                   20 year old   \n",
       "3                                     yesterday   \n",
       "4                                      vomiting   \n",
       "...                                         ...   \n",
       "1518                                denies rash   \n",
       "1519                                denies rash   \n",
       "1520                                    no rash   \n",
       "1521                                    no rash   \n",
       "1522                                Denies rash   \n",
       "\n",
       "                                         New_pn_history  \\\n",
       "0     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "1     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "2     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "3     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "4     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "...                                                 ...   \n",
       "1518  20 yo F c o headache that started 2 day ago de...   \n",
       "1519  Stephanie Madden is a 20 yo F complaining of H...   \n",
       "1520  Patient is a 20 yo F presenting with c o of he...   \n",
       "1521  The patient is a 20 yo female presenting with ...   \n",
       "1522  Stephanie Madden is a 20 yo F who present with...   \n",
       "\n",
       "                                           new_location  \n",
       "0     <re.Match object; span=(248, 289), match='tyle...  \n",
       "1     <re.Match object; span=(260, 289), match='ibup...  \n",
       "2     <re.Match object; span=(35, 46), match='20 yea...  \n",
       "3     <re.Match object; span=(102, 111), match='yest...  \n",
       "4     <re.Match object; span=(341, 349), match='vomi...  \n",
       "...                                                 ...  \n",
       "1518  <re.Match object; span=(370, 381), match='deni...  \n",
       "1519  <re.Match object; span=(487, 498), match='deni...  \n",
       "1520  <re.Match object; span=(485, 492), match='no r...  \n",
       "1521  <re.Match object; span=(670, 677), match='no r...  \n",
       "1522  <re.Match object; span=(353, 364), match='Deni...  \n",
       "\n",
       "[1504 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9 = case_9.drop(drop_index,axis = 0)\n",
    "case_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a857148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "      <th>New_pn_history</th>\n",
       "      <th>new_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90127</td>\n",
       "      <td>'tylenol no relief'</td>\n",
       "      <td>'251 258;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>248</td>\n",
       "      <td>289</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>tylenol and ibuprofen and found no relief</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(248, 289), match='tyle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90127</td>\n",
       "      <td>'ibuprofen no relief'</td>\n",
       "      <td>'264 273;284 293'</td>\n",
       "      <td>900</td>\n",
       "      <td>260</td>\n",
       "      <td>289</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>ibuprofen and found no relief</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(260, 289), match='ibup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90127</td>\n",
       "      <td>'20 year old'</td>\n",
       "      <td>'34 45'</td>\n",
       "      <td>901</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>20 year old</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(35, 46), match='20 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90127</td>\n",
       "      <td>'yesterday'</td>\n",
       "      <td>'102 111'</td>\n",
       "      <td>902</td>\n",
       "      <td>102</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(102, 111), match='yest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90127</td>\n",
       "      <td>'vomiting'</td>\n",
       "      <td>'347 355'</td>\n",
       "      <td>906</td>\n",
       "      <td>341</td>\n",
       "      <td>349</td>\n",
       "      <td>9</td>\n",
       "      <td>CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...</td>\n",
       "      <td>vomiting</td>\n",
       "      <td>CC : Headache HPI : Ms Maddon is a 20 year old...</td>\n",
       "      <td>&lt;re.Match object; span=(341, 349), match='vomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>93959</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'384 395'</td>\n",
       "      <td>907</td>\n",
       "      <td>370</td>\n",
       "      <td>381</td>\n",
       "      <td>9</td>\n",
       "      <td>20 yo F c/o headache that started 2 days ago, ...</td>\n",
       "      <td>denies rash</td>\n",
       "      <td>20 yo F c o headache that started 2 day ago de...</td>\n",
       "      <td>&lt;re.Match object; span=(370, 381), match='deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>92690</td>\n",
       "      <td>'denies rash'</td>\n",
       "      <td>'493 504'</td>\n",
       "      <td>907</td>\n",
       "      <td>487</td>\n",
       "      <td>498</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F complaining of H...</td>\n",
       "      <td>denies rash</td>\n",
       "      <td>Stephanie Madden is a 20 yo F complaining of H...</td>\n",
       "      <td>&lt;re.Match object; span=(487, 498), match='deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>92872</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'483 490'</td>\n",
       "      <td>907</td>\n",
       "      <td>485</td>\n",
       "      <td>492</td>\n",
       "      <td>9</td>\n",
       "      <td>Patient is a 20 yo F presenting with c/o of he...</td>\n",
       "      <td>no rash</td>\n",
       "      <td>Patient is a 20 yo F presenting with c o of he...</td>\n",
       "      <td>&lt;re.Match object; span=(485, 492), match='no r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>94339</td>\n",
       "      <td>'no rash'</td>\n",
       "      <td>'688 695'</td>\n",
       "      <td>907</td>\n",
       "      <td>670</td>\n",
       "      <td>677</td>\n",
       "      <td>9</td>\n",
       "      <td>The patient is a 20 yo female presenting with ...</td>\n",
       "      <td>no rash</td>\n",
       "      <td>The patient is a 20 yo female presenting with ...</td>\n",
       "      <td>&lt;re.Match object; span=(670, 677), match='no r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>94603</td>\n",
       "      <td>'Denies rash'</td>\n",
       "      <td>'355 366'</td>\n",
       "      <td>907</td>\n",
       "      <td>353</td>\n",
       "      <td>364</td>\n",
       "      <td>9</td>\n",
       "      <td>Stephanie Madden is a 20 yo F who presents wit...</td>\n",
       "      <td>Denies rash</td>\n",
       "      <td>Stephanie Madden is a 20 yo F who present with...</td>\n",
       "      <td>&lt;re.Match object; span=(353, 364), match='Deni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1504 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num              annotation            location  feature_num  \\\n",
       "0      90127     'tylenol no relief'   '251 258;284 293'          900   \n",
       "1      90127   'ibuprofen no relief'   '264 273;284 293'          900   \n",
       "2      90127           '20 year old'             '34 45'          901   \n",
       "3      90127             'yesterday'           '102 111'          902   \n",
       "4      90127              'vomiting'           '347 355'          906   \n",
       "...      ...                     ...                 ...          ...   \n",
       "1518   93959           'denies rash'           '384 395'          907   \n",
       "1519   92690           'denies rash'           '493 504'          907   \n",
       "1520   92872               'no rash'           '483 490'          907   \n",
       "1521   94339               'no rash'           '688 695'          907   \n",
       "1522   94603           'Denies rash'           '355 366'          907   \n",
       "\n",
       "      start_location  end_location  case_num  \\\n",
       "0                248           289         9   \n",
       "1                260           289         9   \n",
       "2                 35            46         9   \n",
       "3                102           111         9   \n",
       "4                341           349         9   \n",
       "...              ...           ...       ...   \n",
       "1518             370           381         9   \n",
       "1519             487           498         9   \n",
       "1520             485           492         9   \n",
       "1521             670           677         9   \n",
       "1522             353           364         9   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "1     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "2     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "3     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "4     CC: Headache\\r\\nHPI: Ms Maddon is a 20 year ol...   \n",
       "...                                                 ...   \n",
       "1518  20 yo F c/o headache that started 2 days ago, ...   \n",
       "1519  Stephanie Madden is a 20 yo F complaining of H...   \n",
       "1520  Patient is a 20 yo F presenting with c/o of he...   \n",
       "1521  The patient is a 20 yo female presenting with ...   \n",
       "1522  Stephanie Madden is a 20 yo F who presents wit...   \n",
       "\n",
       "                                 New_annotation  \\\n",
       "0     tylenol and ibuprofen and found no relief   \n",
       "1                 ibuprofen and found no relief   \n",
       "2                                   20 year old   \n",
       "3                                     yesterday   \n",
       "4                                      vomiting   \n",
       "...                                         ...   \n",
       "1518                                denies rash   \n",
       "1519                                denies rash   \n",
       "1520                                    no rash   \n",
       "1521                                    no rash   \n",
       "1522                                Denies rash   \n",
       "\n",
       "                                         New_pn_history  \\\n",
       "0     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "1     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "2     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "3     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "4     CC : Headache HPI : Ms Maddon is a 20 year old...   \n",
       "...                                                 ...   \n",
       "1518  20 yo F c o headache that started 2 day ago de...   \n",
       "1519  Stephanie Madden is a 20 yo F complaining of H...   \n",
       "1520  Patient is a 20 yo F presenting with c o of he...   \n",
       "1521  The patient is a 20 yo female presenting with ...   \n",
       "1522  Stephanie Madden is a 20 yo F who present with...   \n",
       "\n",
       "                                           new_location  \n",
       "0     <re.Match object; span=(248, 289), match='tyle...  \n",
       "1     <re.Match object; span=(260, 289), match='ibup...  \n",
       "2     <re.Match object; span=(35, 46), match='20 yea...  \n",
       "3     <re.Match object; span=(102, 111), match='yest...  \n",
       "4     <re.Match object; span=(341, 349), match='vomi...  \n",
       "...                                                 ...  \n",
       "1518  <re.Match object; span=(370, 381), match='deni...  \n",
       "1519  <re.Match object; span=(487, 498), match='deni...  \n",
       "1520  <re.Match object; span=(485, 492), match='no r...  \n",
       "1521  <re.Match object; span=(670, 677), match='no r...  \n",
       "1522  <re.Match object; span=(353, 364), match='Deni...  \n",
       "\n",
       "[1504 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9[\"start_location\"] = case_9.apply(lambda x :re.search(r'\\b' + x.New_annotation + r'\\b', x.New_pn_history).start(),axis =1)\n",
    "case_9[\"end_location\"] = case_9.apply(lambda x :re.search(r'\\b' + x.New_annotation + r'\\b', x.New_pn_history).end(),axis =1)\n",
    "case_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570648c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93125d53",
   "metadata": {},
   "source": [
    "### Feature 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bfbf474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 11)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_900 = case_9[case_9[\"feature_num\"] == 900]\n",
    "case_9_900.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e7f5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_900 = case_9_900.drop(index=1, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=25, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=34, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=61, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=89, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=103, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=114, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=128, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=176, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=193, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=213, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=229, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=243, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=254, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=280, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=302, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=316, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=330, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=368, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=392, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=415, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=428, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=468, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=495, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=512, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=535, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=594, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=640, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=668, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=713, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=734, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=750, axis = 0) \n",
    "case_9_900 = case_9_900.drop(index=820, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=836, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=861, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=870, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=882, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=896, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=917, axis = 0)\n",
    "\n",
    "case_9_900 = case_9_900.drop(index=933, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=952, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=968, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=999, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=1010, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=1039, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=1050, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=1079, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=1091, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=1124, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=1137, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=1177, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=1186, axis = 0)\n",
    "case_9_900 = case_9_900.drop(index=1202, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e596c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 15)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_900.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_900[case_9_900.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_900[case_9_900.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "    \n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_900.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_900.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddb846b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 56/56 [00:00<00:00, 172.76it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_900.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed602059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 406.46it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_900.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78cad5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 20:38:22.364736: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 20:38:22.364814: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Saved config\n",
      "config_900.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_900.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_900.cfg ./config_900.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d6d0a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_900\n",
      "[i] Saving to output directory: output_900\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     59.17    0.00    0.00    0.00    0.00\n",
      "  3     200       1953.33   2649.30   29.63   33.33   26.67    0.30\n",
      "  7     400        858.48    158.44   56.25   52.94   60.00    0.56\n",
      " 10     600        229.75     35.75   53.33   53.33   53.33    0.53\n",
      " 14     800          4.54      3.69   51.85   58.33   46.67    0.52\n",
      " 17    1000          0.42      0.36   37.04   41.67   33.33    0.37\n",
      " 21    1200          0.02      0.02   37.04   41.67   33.33    0.37\n",
      " 25    1400        491.31     25.90   46.15   54.55   40.00    0.46\n",
      " 30    1600       2750.58     77.06   59.26   66.67   53.33    0.59\n",
      " 37    1800         27.93     16.31   66.67   75.00   60.00    0.67\n",
      " 46    2000          0.01      0.00   55.17   57.14   53.33    0.55\n",
      " 57    2200         21.15      6.29   46.15   54.55   40.00    0.46\n",
      " 71    2400         11.71      3.71   62.07   64.29   60.00    0.62\n",
      " 88    2600         16.30      7.93   53.85   63.64   46.67    0.54\n",
      "109    2800       4406.64     79.13   51.61   50.00   53.33    0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 20:38:34.273390: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 20:38:34.273454: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 20:38:40,641] [INFO] Set up nlp object from config\n",
      "[2022-04-26 20:38:40,655] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 20:38:40,660] [INFO] Created vocabulary\n",
      "[2022-04-26 20:38:40,717] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 20:38:41,845] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131    3000         42.23     10.72   62.07   64.29   60.00    0.62\n",
      "154    3200         22.99      2.30   74.07   83.33   66.67    0.74\n",
      "176    3400          0.00      0.00   74.07   83.33   66.67    0.74\n",
      "198    3600          0.04      0.01   76.92   90.91   66.67    0.77\n",
      "220    3800          0.00      0.00   69.23   81.82   60.00    0.69\n",
      "242    4000          0.00      0.00   69.23   81.82   60.00    0.69\n",
      "265    4200          0.00      0.00   69.23   81.82   60.00    0.69\n",
      "287    4400        192.76     34.61   59.26   66.67   53.33    0.59\n",
      "309    4600        677.14     33.77   64.29   69.23   60.00    0.64\n",
      "331    4800          0.19      0.03   50.00   53.85   46.67    0.50\n",
      "353    5000         47.45      5.89   61.54   72.73   53.33    0.62\n",
      "375    5200          0.00      0.00   61.54   72.73   53.33    0.62\n",
      "[+] Saved pipeline to output directory\n",
      "output_900\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_900.cfg --output ./output_900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a4641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6114983",
   "metadata": {},
   "source": [
    "### Feature 901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfa8d21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 11)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_901 = case_9[case_9[\"feature_num\"] == 901]\n",
    "case_9_901.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "915ba0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_901.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_901[case_9_901.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_901[case_9_901.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_901.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_901.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8563271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 76/76 [00:00<00:00, 165.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_901.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e56fadd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 253.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_901.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a25f4543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_901.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_901.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 20:53:30.913878: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 20:53:30.913951: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_901.cfg ./config_901.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72ea27db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_901\n",
      "[i] Saving to output directory: output_901\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     60.67    0.00    0.00    0.00    0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 20:53:39.156077: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 20:53:39.156129: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 20:53:45,134] [INFO] Set up nlp object from config\n",
      "[2022-04-26 20:53:45,148] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 20:53:45,153] [INFO] Created vocabulary\n",
      "[2022-04-26 20:53:45,154] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 20:53:45,886] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2     200       9704.88   2761.81   72.73   85.71   63.16    0.73\n",
      "  5     400         11.00     28.61   86.49   88.89   84.21    0.86\n",
      "  7     600          2.38      4.58   84.21   84.21   84.21    0.84\n",
      " 10     800          1.42      3.60   84.21   84.21   84.21    0.84\n",
      " 13    1000          0.00      0.00   84.21   84.21   84.21    0.84\n",
      " 16    1200          0.00      0.00   84.21   84.21   84.21    0.84\n",
      " 19    1400          0.00      0.00   84.21   84.21   84.21    0.84\n",
      " 24    1600          0.00      0.00   84.21   84.21   84.21    0.84\n",
      " 30    1800          0.00      0.00   84.21   84.21   84.21    0.84\n",
      " 37    2000          0.00      0.00   84.21   84.21   84.21    0.84\n",
      "[+] Saved pipeline to output directory\n",
      "output_901\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_901.cfg --output ./output_901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569491c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3e4aa20",
   "metadata": {},
   "source": [
    "### Feature 902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d0a64e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 11)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_902 = case_9[case_9[\"feature_num\"] == 902]\n",
    "case_9_902.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3f1293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_902 = case_9_902.drop(index=737, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=515, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=418, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=144, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=64, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=548, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=130, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=320, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=76, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=480, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=618, axis = 0)\n",
    "case_9_902 = case_9_902.drop(index=907, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0981e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_902 = case_9_902.drop(index=617, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5cff61db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 18)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_902.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_902[case_9_902.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_902[case_9_902.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_902.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_902.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3159e0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 71/71 [00:00<00:00, 334.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_902.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82df54c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 474.96it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_902.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5856cb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_902.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_902.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 21:10:48.797210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 21:10:48.797260: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_902.cfg ./config_902.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c57352a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_902\n",
      "[i] Saving to output directory: output_902\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     55.50    0.00    0.00    0.00    0.00\n",
      "  2     200         18.50   1070.89   68.42   72.22   65.00    0.68\n",
      "  5     400         34.35     76.50   71.79   73.68   70.00    0.72\n",
      "  8     600         37.32     46.52   75.00   75.00   75.00    0.75\n",
      " 11     800         28.55     27.43   65.31   55.17   80.00    0.65\n",
      " 14    1000         37.53     27.49   70.27   76.47   65.00    0.70\n",
      " 16    1200         48.11     24.08   68.29   66.67   70.00    0.68\n",
      " 20    1400         18.21     13.38   70.27   76.47   65.00    0.70\n",
      " 24    1600         27.66     20.79   72.73   66.67   80.00    0.73\n",
      " 30    1800         29.41     26.56   62.86   73.33   55.00    0.63\n",
      " 37    2000         16.91     21.42   73.68   77.78   70.00    0.74\n",
      " 46    2200         16.64     23.01   75.00   75.00   75.00    0.75\n",
      "[+] Saved pipeline to output directory\n",
      "output_902\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 21:10:57.507948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 21:10:57.507998: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 21:11:03,256] [INFO] Set up nlp object from config\n",
      "[2022-04-26 21:11:03,271] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 21:11:03,276] [INFO] Created vocabulary\n",
      "[2022-04-26 21:11:03,277] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 21:11:03,916] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_902.cfg --output ./output_902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc699c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71611c80",
   "metadata": {},
   "source": [
    "### Feature 903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef5de01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 11)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_903 = case_9[case_9[\"feature_num\"] == 903]\n",
    "case_9_903.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50a1e3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 6)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_903.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_903[case_9_903.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_903[case_9_903.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_903.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_903.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6669c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 228.33it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_903.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4999a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 200.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_903.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12579884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_903.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_903.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 21:15:24.448051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 21:15:24.448101: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_903.cfg ./config_903.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "197e40b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_903\n",
      "[i] Saving to output directory: output_903\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     59.67    0.00    0.00    0.00    0.00\n",
      "  8     200         12.33   1115.56   90.91  100.00   83.33    0.91\n",
      " 17     400         14.95     31.86   90.91  100.00   83.33    0.91\n",
      " 26     600          1.54      2.01   90.91  100.00   83.33    0.91\n",
      " 34     800          0.00      0.00   90.91  100.00   83.33    0.91\n",
      " 43    1000          0.00      0.00   90.91  100.00   83.33    0.91\n",
      " 52    1200          0.00      0.00   90.91  100.00   83.33    0.91\n",
      " 61    1400          0.00      0.00   90.91  100.00   83.33    0.91\n",
      " 72    1600          0.00      0.00   90.91  100.00   83.33    0.91\n",
      " 88    1800          0.00      0.00   90.91  100.00   83.33    0.91\n",
      "[+] Saved pipeline to output directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 21:15:32.833797: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 21:15:32.833847: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 21:15:38,698] [INFO] Set up nlp object from config\n",
      "[2022-04-26 21:15:38,714] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 21:15:38,724] [INFO] Created vocabulary\n",
      "[2022-04-26 21:15:38,726] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 21:15:39,299] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_903\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_903.cfg --output ./output_903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546ca67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e05248f",
   "metadata": {},
   "source": [
    "### Feature 904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a28c81d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 11)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_904 = case_9[case_9[\"feature_num\"] == 904]\n",
    "case_9_904.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3cdde79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_904 = case_9_904.drop(index=203, axis = 0)\n",
    "case_9_904 = case_9_904.drop(index=218, axis = 0)\n",
    "case_9_904 = case_9_904.drop(index=395, axis = 0)\n",
    "case_9_904 = case_9_904.drop(index=825, axis = 0)\n",
    "\n",
    "case_9_904 = case_9_904.drop(index=1191, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "61fdf1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 11)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_904.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_904[case_9_904.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_904[case_9_904.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_904.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_904.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "47d90a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 43/43 [00:00<00:00, 264.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_904.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d64a30a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 344.67it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_904.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "41cc14f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 00:28:48.227164: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-27 00:28:48.227218: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Saved config\n",
      "config_904.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_904.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_904.cfg ./config_904.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c7e79194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: output_904\n",
      "[i] Using CPU\n",
      "\u001b[1m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 00:28:56.928020: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-27 00:28:56.928073: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-27 00:29:02,732] [INFO] Set up nlp object from config\n",
      "[2022-04-27 00:29:02,745] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-27 00:29:02,751] [INFO] Created vocabulary\n",
      "[2022-04-27 00:29:02,752] [INFO] Finished initializing nlp object\n",
      "[2022-04-27 00:29:03,276] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     63.83    0.00    0.00    0.00    0.00\n",
      "  4     200       1416.24   2165.30   72.73   72.73   72.73    0.73\n",
      "  9     400         27.82    102.34   70.00   77.78   63.64    0.70\n",
      " 13     600         44.08     85.29   76.19   80.00   72.73    0.76\n",
      " 18     800         38.34     62.95   70.00   77.78   63.64    0.70\n",
      " 23    1000         45.97     65.10   63.16   75.00   54.55    0.63\n",
      " 28    1200         43.13     60.51   73.68   87.50   63.64    0.74\n",
      " 34    1400         47.85     57.52   66.67   70.00   63.64    0.67\n",
      " 43    1600         49.89     67.97   70.00   77.78   63.64    0.70\n",
      " 54    1800         90.35     81.80   76.19   80.00   72.73    0.76\n",
      " 68    2000         72.56     89.04   81.82   81.82   81.82    0.82\n",
      " 86    2200         87.41    115.53   73.68   87.50   63.64    0.74\n",
      "108    2400         87.26    132.31   80.00   88.89   72.73    0.80\n",
      "135    2600        245.43    161.27   80.00   88.89   72.73    0.80\n",
      "164    2800        135.93    174.27   80.00   88.89   72.73    0.80\n",
      "193    3000        799.50    181.53   73.68   87.50   63.64    0.74\n",
      "221    3200       1610.58    190.46   73.68   87.50   63.64    0.74\n",
      "250    3400        691.97    168.20   84.21  100.00   72.73    0.84\n",
      "278    3600        205.51    172.07   84.21  100.00   72.73    0.84\n",
      "307    3800        514.82    175.94   76.19   80.00   72.73    0.76\n",
      "335    4000       1367.80    166.61   84.21  100.00   72.73    0.84\n",
      "364    4200        451.96    158.95   84.21  100.00   72.73    0.84\n",
      "393    4400        926.48    156.87   72.73   72.73   72.73    0.73\n",
      "421    4600       1260.46    170.21   76.19   80.00   72.73    0.76\n",
      "450    4800        171.98    158.09   80.00   88.89   72.73    0.80\n",
      "478    5000       3323.07    160.74   80.00   88.89   72.73    0.80\n",
      "[+] Saved pipeline to output directory\n",
      "output_904\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_904.cfg --output ./output_904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714a661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c068ffac",
   "metadata": {},
   "source": [
    "### Feature 905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7bc0c8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 11)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_905 = case_9[case_9[\"feature_num\"] == 905]\n",
    "case_9_905.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55abbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_905 = case_9_905.drop(index=79, axis = 0)\n",
    "case_9_905 = case_9_905.drop(index=182, axis = 0)\n",
    "case_9_905 = case_9_905.drop(index=600, axis = 0)\n",
    "case_9_905 = case_9_905.drop(index=852, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33fa25ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 39)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_905.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_905[case_9_905.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_905[case_9_905.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_905.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_905.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3d3b2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 155/155 [00:00<00:00, 308.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_905.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b270f1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 429.71it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_905.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "022545b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 21:31:09.058946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 21:31:09.059002: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_905.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_905.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_905.cfg ./config_905.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4d39877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_905\n",
      "[i] Saving to output directory: output_905\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     50.00    0.00    0.00    0.00    0.00\n",
      "  1     200         23.65    991.92   95.00   95.00   95.00    0.95\n",
      "  2     400         43.73     78.61   96.30   95.12   97.50    0.96\n",
      "  3     600         38.19     74.63   97.50   97.50   97.50    0.97\n",
      "  5     800       3447.54    179.24   76.92   78.95   75.00    0.77\n",
      "  6    1000      11449.83    361.33   95.00   95.00   95.00    0.95\n",
      "  7    1200      25998.02    313.44   82.50   82.50   82.50    0.82\n",
      "  9    1400       1790.34     88.03   93.51   97.30   90.00    0.94\n",
      " 12    1600        109.53     63.64   96.30   95.12   97.50    0.96\n",
      " 15    1800         80.01     32.09   92.50   92.50   92.50    0.93\n",
      " 19    2000         66.17     31.70   91.14   92.31   90.00    0.91\n",
      " 24    2200         28.01      8.16   93.67   94.87   92.50    0.94\n",
      "[+] Saved pipeline to output directory\n",
      "output_905\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 21:31:18.325745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 21:31:18.325806: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 21:31:24,770] [INFO] Set up nlp object from config\n",
      "[2022-04-26 21:31:24,786] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 21:31:24,792] [INFO] Created vocabulary\n",
      "[2022-04-26 21:31:24,794] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 21:31:25,975] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_905.cfg --output ./output_905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03283e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1755760",
   "metadata": {},
   "source": [
    "### Feature 906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b702f70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 11)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_906 = case_9[case_9[\"feature_num\"] == 906]\n",
    "case_9_906.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ffe84386",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_906 = case_9_906.drop(index=728, axis = 0)\n",
    "case_9_906 = case_9_906.drop(index=359, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32667e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 19)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_906.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_906[case_9_906.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_906[case_9_906.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_906.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_906.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dc237648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 381.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_906.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "54d8d995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 388.79it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_906.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aeff4052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_906.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_906.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 21:36:24.157364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 21:36:24.157436: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_906.cfg ./config_906.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6423b6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_906\n",
      "[i] Saving to output directory: output_906\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     61.17    0.00    0.00    0.00    0.00\n",
      "  2     200         24.89   1039.63   87.18   94.44   80.95    0.87\n",
      "  5     400         18.24     30.36   87.18   94.44   80.95    0.87\n",
      "  8     600         18.02     21.96   87.18   94.44   80.95    0.87\n",
      " 10     800       8378.24    184.60   90.00   94.74   85.71    0.90\n",
      " 13    1000        219.68     37.40   90.00   94.74   85.71    0.90\n",
      " 16    1200         14.54     16.87   87.18   94.44   80.95    0.87\n",
      " 19    1400         13.68     10.27   85.71   85.71   85.71    0.86\n",
      " 24    1600         11.27     11.78   90.00   94.74   85.71    0.90\n",
      " 31    1800          0.00      0.01   90.00   94.74   85.71    0.90\n",
      " 39    2000          0.00      0.00   90.00   94.74   85.71    0.90\n",
      " 49    2200         11.17      3.59   90.00   94.74   85.71    0.90\n",
      " 61    2400         28.50     11.80   84.21   94.12   76.19    0.84\n",
      "[+] Saved pipeline to output directory\n",
      "output_906\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 21:36:34.895090: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 21:36:34.895166: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 21:36:43,445] [INFO] Set up nlp object from config\n",
      "[2022-04-26 21:36:43,470] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 21:36:43,478] [INFO] Created vocabulary\n",
      "[2022-04-26 21:36:43,479] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 21:36:44,412] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_906.cfg --output ./output_906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df1915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3fd78f9",
   "metadata": {},
   "source": [
    "### Feature 907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8a1743ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 11)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_907 = case_9[case_9[\"feature_num\"] == 907]\n",
    "case_9_907.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c02985d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_907 = case_9_907.drop(index=1376, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1380, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1381, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1384, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1395, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1460, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1495, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1406, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1403, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1414, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1416, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1414, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1423, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1424, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1477, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1465, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1490, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1445, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1453, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1520, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1522, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1471, axis = 0)\n",
    "case_9_907 = case_9_907.drop(index=1506, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "70862b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_907 = case_9_907.drop(index=1506, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "3fb0141a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 28)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_907.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_907[case_9_907.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_907[case_9_907.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_907.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_907.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3be0f94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 109/109 [00:00<00:00, 365.52it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_907.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "815d7e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 419.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_907.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ffdecc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 00:17:04.643700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-27 00:17:04.643817: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Saved config\n",
      "config_907.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_907.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_907.cfg ./config_907.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "11803991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_907\n",
      "[i] Saving to output directory: output_907\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     61.67    0.00    0.00    0.00    0.00\n",
      "  1     200         12.02    944.06   98.18  100.00   96.43    0.98\n",
      "  3     400         21.76     39.71  100.00  100.00  100.00    1.00\n",
      "  5     600         15.95     31.33  100.00  100.00  100.00    1.00\n",
      "  7     800        803.17     89.95  100.00  100.00  100.00    1.00\n",
      "  9    1000        774.55     59.00   94.74   93.10   96.43    0.95\n",
      " 11    1200      22244.03    198.96   98.18  100.00   96.43    0.98\n",
      " 12    1400         14.95     20.51  100.00  100.00  100.00    1.00\n",
      " 15    1600         14.40     12.46   98.25   96.55  100.00    0.98\n",
      " 19    1800         12.93      6.49   96.43   96.43   96.43    0.96\n",
      " 23    2000         45.09     22.61  100.00  100.00  100.00    1.00\n",
      "[+] Saved pipeline to output directory\n",
      "output_907\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 00:17:13.894604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-27 00:17:13.894654: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-27 00:17:20,449] [INFO] Set up nlp object from config\n",
      "[2022-04-27 00:17:20,466] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-27 00:17:20,473] [INFO] Created vocabulary\n",
      "[2022-04-27 00:17:20,476] [INFO] Finished initializing nlp object\n",
      "[2022-04-27 00:17:21,421] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_907.cfg --output ./output_907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7c1778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1023a405",
   "metadata": {},
   "source": [
    "### Feature 908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1646e717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 11)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_908 = case_9[case_9[\"feature_num\"] == 908]\n",
    "case_9_908.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2fe93f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 15)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_908.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_908[case_9_908.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_908[case_9_908.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_908.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_908.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "624686f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 57/57 [00:00<00:00, 260.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_908.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8409cbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 278.52it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_908.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "297db0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_908.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_908.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 21:56:56.470497: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 21:56:56.470581: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_908.cfg ./config_908.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "95f73a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_908\n",
      "[i] Saving to output directory: output_908\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     58.67    0.00    0.00    0.00    0.00\n",
      "  3     200          8.64    922.75  100.00  100.00  100.00    1.00\n",
      "  7     400          0.20      0.16  100.00  100.00  100.00    1.00\n",
      " 10     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 14     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 17    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 21    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 25    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 31    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 38    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "[+] Saved pipeline to output directory\n",
      "output_908\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 21:57:05.766700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 21:57:05.766757: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 21:57:11,790] [INFO] Set up nlp object from config\n",
      "[2022-04-26 21:57:11,803] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 21:57:11,809] [INFO] Created vocabulary\n",
      "[2022-04-26 21:57:11,810] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 21:57:12,401] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_908.cfg --output ./output_908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6ce44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee3dcdc",
   "metadata": {},
   "source": [
    "### Feature 109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "37b97102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 11)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_909 = case_9[case_9[\"feature_num\"] == 909]\n",
    "case_9_909.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8b2b536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_909 = case_9_909.drop(index=297, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "52397624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 9)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_909.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_909[case_9_909.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_909[case_9_909.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_909.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_909.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "184503d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 267.38it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_909.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2db5b4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 376.00it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_909.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "496800d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 22:03:22.690071: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 22:03:22.690180: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Saved config\n",
      "config_909.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_909.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_909.cfg ./config_909.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3b6b88dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 22:03:37.352159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 22:03:37.352274: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 22:03:48,684] [INFO] Set up nlp object from config\n",
      "[2022-04-26 22:03:48,715] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 22:03:48,727] [INFO] Created vocabulary\n",
      "[2022-04-26 22:03:48,730] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 22:03:49,706] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[i] Saving to output directory: output_909\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     65.33    0.00    0.00    0.00    0.00\n",
      "  6     200         25.99   1125.49   85.71   88.24   83.33    0.86\n",
      " 12     400        120.19     80.01   66.67   73.33   61.11    0.67\n",
      " 18     600         20.38     23.12   88.89   88.89   88.89    0.89\n",
      " 25     800         12.19      9.69   82.35   87.50   77.78    0.82\n",
      " 31    1000          0.43      0.28   70.59   75.00   66.67    0.71\n",
      " 37    1200          0.29      0.10   85.71   88.24   83.33    0.86\n",
      " 44    1400          0.00      0.00   82.35   87.50   77.78    0.82\n",
      " 53    1600          0.00      0.00   82.35   87.50   77.78    0.82\n",
      " 65    1800          0.00      0.00   82.35   87.50   77.78    0.82\n",
      " 79    2000          0.00      0.00   82.35   87.50   77.78    0.82\n",
      " 98    2200          0.00      0.00   82.35   87.50   77.78    0.82\n",
      "[+] Saved pipeline to output directory\n",
      "output_909\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_909.cfg --output ./output_909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03ce5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b16a4fa8",
   "metadata": {},
   "source": [
    "### Feature 910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "75e52d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 11)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_910 = case_9[case_9[\"feature_num\"] == 910]\n",
    "case_9_910.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "765c0c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 5)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_910.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_910[case_9_910.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_910[case_9_910.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_910.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_910.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f7947de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 130.31it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_910.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d4d2f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 185.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_910.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c145acf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 22:11:22.837987: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 22:11:22.838052: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Saved config\n",
      "config_910.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_910.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_910.cfg ./config_910.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "db5fe8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_910\n",
      "[i] Saving to output directory: output_910\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     50.17    0.00    0.00    0.00    0.00\n",
      " 11     200         99.02   1165.86   80.00   80.00   80.00    0.80\n",
      " 22     400          0.29      0.74   80.00   80.00   80.00    0.80\n",
      " 33     600          0.00      0.00   80.00   80.00   80.00    0.80\n",
      " 44     800          0.00      0.00   80.00   80.00   80.00    0.80\n",
      " 55    1000          0.00      0.00   80.00   80.00   80.00    0.80\n",
      " 66    1200          0.00      0.00   80.00   80.00   80.00    0.80\n",
      " 77    1400          0.00      0.00   80.00   80.00   80.00    0.80\n",
      " 89    1600          0.00      0.00   80.00   80.00   80.00    0.80\n",
      "106    1800          0.00      0.00   80.00   80.00   80.00    0.80\n",
      "[+] Saved pipeline to output directory\n",
      "output_910\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 22:11:38.105986: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 22:11:38.106041: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 22:11:50,051] [INFO] Set up nlp object from config\n",
      "[2022-04-26 22:11:50,078] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 22:11:50,090] [INFO] Created vocabulary\n",
      "[2022-04-26 22:11:50,093] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 22:11:50,855] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_910.cfg --output ./output_910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f6dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9186c819",
   "metadata": {},
   "source": [
    "### Feature 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2db65a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 11)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_911 = case_9[case_9[\"feature_num\"] == 911]\n",
    "case_9_911.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ba851a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_911.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_911[case_9_911.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_911[case_9_911.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_911.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_911.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "49933798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 99.92it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_911.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "41a1eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 167.25it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_911.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3d001bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_911.cfg"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 22:58:26.239268: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 22:58:26.239318: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_911.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_911.cfg ./config_911.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "caeb6801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_911\n",
      "[i] Saving to output directory: output_911\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     57.83    0.00    0.00    0.00    0.00\n",
      "200     200       1244.29   1725.35    0.00    0.00    0.00    0.00\n",
      "400     400          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "600     600          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "800     800          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1000    1000          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1200    1200          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1400    1400          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "1600    1600          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "[+] Saved pipeline to output directory\n",
      "output_911\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 22:58:39.144519: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 22:58:39.144645: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 22:58:48,261] [INFO] Set up nlp object from config\n",
      "[2022-04-26 22:58:48,280] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 22:58:48,293] [INFO] Created vocabulary\n",
      "[2022-04-26 22:58:48,296] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 22:58:48,522] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_911.cfg --output ./output_911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29483e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83ced13f",
   "metadata": {},
   "source": [
    "### Feature 912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "31c5c3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 11)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_912 = case_9[case_9[\"feature_num\"] == 912]\n",
    "case_9_912.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "151aea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_912 = case_9_912.drop(index=684, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=945, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=891, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=878, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=867, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=844, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=830, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=815, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=802, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=782, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=771, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=756, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=745, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=55, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=19, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=17, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=589, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=634, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=622, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=607, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=731, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=722, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=697, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=664, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=649, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=963, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=223, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=207, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=188, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=976, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=170, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=160, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=150, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=137, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=123, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=98, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=85, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=362, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=464, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=237, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=453, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=445, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=434, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=423, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=410, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=386, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=350, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=325, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=286, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=275, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=571, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=555, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=531, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=522, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=507, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=926, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=488, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "466d094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_912 = case_9_912.drop(index=987, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=996, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=1195, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=1162, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=1152, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=1131, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=1098, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=1087, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=1075, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=1060, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=1044, axis = 0)\n",
    "case_9_912 = case_9_912.drop(index=1034, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d9012c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 17)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_912.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_912[case_9_912.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_912[case_9_912.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_912.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_912.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1c6f33e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████                                                     | 23/65 [00:00<00:00, 94.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 65/65 [00:00<00:00, 157.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_912.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "08be9ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 253.55it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_912.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "91ab1a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_912.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_912.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:04:12.767411: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 23:04:12.767461: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_912.cfg ./config_912.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0b12913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_912\n",
      "[i] Saving to output directory: output_912\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     58.17    0.00    0.00    0.00    0.00\n",
      "  3     200        288.26   1520.30   52.94   56.25   50.00    0.53\n",
      "  6     400         59.79     85.89   64.71   68.75   61.11    0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:04:27.010481: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 23:04:27.010589: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 23:04:36,509] [INFO] Set up nlp object from config\n",
      "[2022-04-26 23:04:36,533] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 23:04:36,543] [INFO] Created vocabulary\n",
      "[2022-04-26 23:04:36,545] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 23:04:37,664] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9     600         20.17     27.03   70.27   68.42   72.22    0.70\n",
      " 12     800          0.53      0.31   68.57   70.59   66.67    0.69\n",
      " 15    1000          9.65      8.05   66.67   66.67   66.67    0.67\n",
      " 18    1200          2.38      1.50   72.22   72.22   72.22    0.72\n",
      " 21    1400          0.67      1.47   68.42   65.00   72.22    0.68\n",
      " 26    1600         78.87     29.26   68.57   70.59   66.67    0.69\n",
      " 32    1800         23.15     13.17   66.67   73.33   61.11    0.67\n",
      " 40    2000          0.00      0.00   72.22   72.22   72.22    0.72\n",
      " 50    2200          0.00      0.00   68.57   70.59   66.67    0.69\n",
      " 62    2400         26.67      8.21   66.67   61.90   72.22    0.67\n",
      " 77    2600       1739.31    117.70   75.00   85.71   66.67    0.75\n",
      " 95    2800          0.00      0.00   75.00   85.71   66.67    0.75\n",
      "113    3000          0.00      0.00   75.00   85.71   66.67    0.75\n",
      "132    3200          0.00      0.00   75.00   85.71   66.67    0.75\n",
      "150    3400        139.27     27.97   61.54   57.14   66.67    0.62\n",
      "169    3600         59.54     19.00   74.29   76.47   72.22    0.74\n",
      "187    3800          0.02      0.01   74.29   76.47   72.22    0.74\n",
      "206    4000          0.00      0.00   74.29   76.47   72.22    0.74\n",
      "224    4200          0.00      0.00   74.29   76.47   72.22    0.74\n",
      "[+] Saved pipeline to output directory\n",
      "output_912\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_912.cfg --output ./output_912"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd8874",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f08c90f",
   "metadata": {},
   "source": [
    "# Feature 913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e79d182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 11)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_913 = case_9[case_9[\"feature_num\"] == 913]\n",
    "case_9_913.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "471118bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 19)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_913.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_913[case_9_913.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_913[case_9_913.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_913.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_913.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "996a6e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████▏                         | 49/72 [00:00<00:00, 139.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 178.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_913.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a78e4c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 414.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_913.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a8f46f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_913.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_913.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:24:28.247257: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 23:24:28.247338: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_913.cfg ./config_913.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "21fd5280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:24:42.659786: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 23:24:42.659857: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 23:24:52,910] [INFO] Set up nlp object from config\n",
      "[2022-04-26 23:24:52,938] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 23:24:52,950] [INFO] Created vocabulary\n",
      "[2022-04-26 23:24:52,951] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 23:24:54,062] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[i] Saving to output directory: output_913\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     63.00    0.00    0.00    0.00    0.00\n",
      "  2     200          6.57    941.20  100.00  100.00  100.00    1.00\n",
      "  5     400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "  8     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 11     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 13    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 16    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 20    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 25    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      " 31    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "[+] Saved pipeline to output directory\n",
      "output_913\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_913.cfg --output ./output_913"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fee619",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b143a6f",
   "metadata": {},
   "source": [
    "# Feature 914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9a8cc210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 11)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_914 = case_9[case_9[\"feature_num\"] == 914]\n",
    "case_9_914.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "619a4a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_9_914 = case_9_914.drop(index=365, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4d1b8d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 17)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_914.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_914[case_9_914.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_914[case_9_914.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_914.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_914.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "75367a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 67/67 [00:00<00:00, 301.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_914.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dbb532f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 529.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_914.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "af944a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:35:17.458295: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 23:35:17.458347: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Saved config\n",
      "config_914.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_914.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_914.cfg ./config_914.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "23785d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_914\n",
      "[i] Saving to output directory: output_914\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     54.50    0.00    0.00    0.00    0.00\n",
      "  2     200         31.42   1125.19   82.76  100.00   70.59    0.83\n",
      "  5     400        495.70    211.82   82.76  100.00   70.59    0.83\n",
      "  8     600        719.96    116.19   82.76  100.00   70.59    0.83\n",
      " 11     800         38.69     42.59   86.67  100.00   76.47    0.87\n",
      " 14    1000         64.66     33.71   86.67  100.00   76.47    0.87\n",
      " 18    1200         25.83     21.16   83.87   92.86   76.47    0.84\n",
      " 21    1400         32.10     27.96   68.97   83.33   58.82    0.69\n",
      " 27    1600         44.77     26.44   82.76  100.00   70.59    0.83\n",
      " 33    1800         14.39      2.90   77.42   85.71   70.59    0.77\n",
      " 42    2000         11.34      3.56   82.76  100.00   70.59    0.83\n",
      " 53    2200         44.86      6.01   68.97   83.33   58.82    0.69\n",
      " 66    2400          5.71      2.01   82.76  100.00   70.59    0.83\n",
      "[+] Saved pipeline to output directory\n",
      "output_914\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:35:29.282824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 23:35:29.282875: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 23:35:38,129] [INFO] Set up nlp object from config\n",
      "[2022-04-26 23:35:38,152] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 23:35:38,162] [INFO] Created vocabulary\n",
      "[2022-04-26 23:35:38,164] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 23:35:39,367] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_914.cfg --output ./output_914"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80afc8",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cdad9d",
   "metadata": {},
   "source": [
    "# Feature 915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "887bd22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 11)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_915 = case_9[case_9[\"feature_num\"] == 915]\n",
    "case_9_915.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4fb5639f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 8)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_915.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_915[case_9_915.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_915[case_9_915.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_915.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_915.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "67db0d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 264.46it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_915.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e5f9b26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 445.94it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_915.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "93fbabe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_915.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_915.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:44:34.431948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 23:44:34.432013: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_915.cfg ./config_915.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8329f779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_915\n",
      "[i] Saving to output directory: output_915\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     53.67    0.00    0.00    0.00    0.00\n",
      "  6     200       1767.71   2197.30   55.56   50.00   62.50    0.56\n",
      " 12     400         66.36    104.61   75.00   75.00   75.00    0.75\n",
      " 19     600         18.01     22.14   75.00   75.00   75.00    0.75\n",
      " 25     800          0.00      0.00   75.00   75.00   75.00    0.75\n",
      " 32    1000          0.00      0.00   75.00   75.00   75.00    0.75\n",
      " 38    1200          0.00      0.00   75.00   75.00   75.00    0.75\n",
      " 45    1400          0.00      0.00   75.00   75.00   75.00    0.75\n",
      " 54    1600          0.00      0.00   75.00   75.00   75.00    0.75\n",
      " 67    1800          0.00      0.00   75.00   75.00   75.00    0.75\n",
      " 82    2000          0.00      0.00   75.00   75.00   75.00    0.75\n",
      "[+] Saved pipeline to output directory\n",
      "output_915\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:44:47.890169: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 23:44:47.890238: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 23:44:59,477] [INFO] Set up nlp object from config\n",
      "[2022-04-26 23:44:59,501] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 23:44:59,510] [INFO] Created vocabulary\n",
      "[2022-04-26 23:44:59,512] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 23:45:00,303] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_915.cfg --output ./output_915"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe36e8e",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b14e1",
   "metadata": {},
   "source": [
    "# Feature 916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ba48574e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 11)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_9_916 = case_9[case_9[\"feature_num\"] == 916]\n",
    "case_9_916.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a28ad6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 14)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_9_916.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_9_916[case_9_916.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_9_916[case_9_916.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_916.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_916.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "n = int(len(data)*0.8)\n",
    "\n",
    "train = data[:n]\n",
    "validation = data[n:]\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "201c284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 244.70it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_916.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "423d9876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 218.01it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_916.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "52df51b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_916.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_916.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:51:46.488845: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 23:51:46.488923: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_916.cfg ./config_916.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5159eb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_916\n",
      "[i] Saving to output directory: output_916\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     53.83    0.00    0.00    0.00    0.00\n",
      "  3     200        174.31   1396.08   66.67   69.23   64.29    0.67\n",
      "  7     400       2692.02    183.70   69.23   75.00   64.29    0.69\n",
      " 11     600        310.15     42.50   78.57   78.57   78.57    0.79\n",
      " 15     800          6.76      7.22   74.07   76.92   71.43    0.74\n",
      " 19    1000          0.02      0.01   82.76   80.00   85.71    0.83\n",
      " 23    1200          0.00      0.00   78.57   78.57   78.57    0.79\n",
      " 28    1400          0.00      0.00   78.57   78.57   78.57    0.79\n",
      " 35    1600          0.00      0.00   78.57   78.57   78.57    0.79\n",
      " 44    1800         13.34      8.01   69.23   75.00   64.29    0.69\n",
      " 55    2000         98.24     53.10   72.00   81.82   64.29    0.72\n",
      " 70    2200      59142.78    475.50   74.07   76.92   71.43    0.74\n",
      " 87    2400          7.66      3.04   74.07   76.92   71.43    0.74\n",
      "109    2600          0.00      0.00   69.23   75.00   64.29    0.69\n",
      "[+] Saved pipeline to output directory\n",
      "output_916\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:52:01.815373: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-26 23:52:01.815484: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-26 23:52:12,503] [INFO] Set up nlp object from config\n",
      "[2022-04-26 23:52:12,525] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-26 23:52:12,533] [INFO] Created vocabulary\n",
      "[2022-04-26 23:52:12,535] [INFO] Finished initializing nlp object\n",
      "[2022-04-26 23:52:13,552] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_916.cfg --output ./output_916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f43f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
