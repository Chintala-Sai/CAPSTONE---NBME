{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f663e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import spacy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaeec52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r\"C:\\Users\\sai\\Desktop\\PRAXIS\\Term - 3\\CAPP\\Datasets\\train.csv\")\n",
    "features = pd.read_csv(r\"C:\\Users\\sai\\Desktop\\PRAXIS\\Term - 3\\CAPP\\Datasets\\features.csv\")\n",
    "patient_notes = pd.read_csv(r\"C:\\Users\\sai\\Desktop\\PRAXIS\\Term - 3\\CAPP\\Datasets\\patient_notes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e55e8c",
   "metadata": {},
   "source": [
    "### CASE - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a545e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>Prior-normal-periods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>201</td>\n",
       "      <td>2</td>\n",
       "      <td>Last-Pap-smear-I-year-ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "      <td>IUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>203</td>\n",
       "      <td>2</td>\n",
       "      <td>Sexually-active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>204</td>\n",
       "      <td>2</td>\n",
       "      <td>Vaginal-dryness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "      <td>Irregular-menses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>Recent-nausea-vomiting-OR-Recent-flulike-symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "      <td>No-premenstrual-symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>209</td>\n",
       "      <td>2</td>\n",
       "      <td>Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>210</td>\n",
       "      <td>2</td>\n",
       "      <td>LMP-2-months-ago-or-Last-menstrual-period-2-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>Hot-flashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>Irregular-flow-OR-Irregular-frequency-OR-Irreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>213</td>\n",
       "      <td>2</td>\n",
       "      <td>Onset-3-years-ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>Heavy-sweating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>215</td>\n",
       "      <td>2</td>\n",
       "      <td>Sleep-disturbance-OR-Early-awakenings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>44-year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_num  case_num                                       feature_text\n",
       "26          200         2                               Prior-normal-periods\n",
       "27          201         2                          Last-Pap-smear-I-year-ago\n",
       "28          202         2                                                IUD\n",
       "29          203         2                                    Sexually-active\n",
       "30          204         2                                    Vaginal-dryness\n",
       "31          205         2                                   Irregular-menses\n",
       "32          206         2  Recent-nausea-vomiting-OR-Recent-flulike-symptoms\n",
       "33          207         2                           No-premenstrual-symptoms\n",
       "34          208         2                                             Female\n",
       "35          209         2                                             Stress\n",
       "36          210         2  LMP-2-months-ago-or-Last-menstrual-period-2-mo...\n",
       "37          211         2                                        Hot-flashes\n",
       "38          212         2  Irregular-flow-OR-Irregular-frequency-OR-Irreg...\n",
       "39          213         2                                  Onset-3-years-ago\n",
       "40          214         2                                     Heavy-sweating\n",
       "41          215         2              Sleep-disturbance-OR-Early-awakenings\n",
       "42          216         2                                            44-year"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_features = features[features[\"case_num\"] == 2]\n",
    "case_2_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60951747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo F. C/o irregular mestrual periods.  prev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>20001</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>20002</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolores Montgomery, a 44-year-old female, has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>20003</td>\n",
       "      <td>2</td>\n",
       "      <td>HPI: 44 yo female presenting with menstrual ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>20004</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: irregular mentrual bleeding \\r\\n44 yo F G2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>22137</td>\n",
       "      <td>2</td>\n",
       "      <td>44 y/o F, c/o irregular menstrual periods. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>22138</td>\n",
       "      <td>2</td>\n",
       "      <td>Ms. Montgomery is a 44 y/o F who presents with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>22139</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo female complains of irregular periods fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>22140</td>\n",
       "      <td>2</td>\n",
       "      <td>a 44 y o f comes to clinic to for irregular pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>22141</td>\n",
       "      <td>2</td>\n",
       "      <td>Ms Montgomery is a 44yo G2P2 who presents with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1958 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num  case_num                                         pn_history\n",
       "3076   20000         2  44 yo F. C/o irregular mestrual periods.  prev...\n",
       "3077   20001         2  CC: 44 yo female c/o irregular periods\\r\\nHPI:...\n",
       "3078   20002         2  Dolores Montgomery, a 44-year-old female, has ...\n",
       "3079   20003         2  HPI: 44 yo female presenting with menstrual ir...\n",
       "3080   20004         2  CC: irregular mentrual bleeding \\r\\n44 yo F G2...\n",
       "...      ...       ...                                                ...\n",
       "5029   22137         2  44 y/o F, c/o irregular menstrual periods. It ...\n",
       "5030   22138         2  Ms. Montgomery is a 44 y/o F who presents with...\n",
       "5031   22139         2  44 yo female complains of irregular periods fo...\n",
       "5032   22140         2  a 44 y o f comes to clinic to for irregular pe...\n",
       "5033   22141         2  Ms Montgomery is a 44yo G2P2 who presents with...\n",
       "\n",
       "[1958 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_pn = patient_notes[patient_notes[\"case_num\"] ==  2]\n",
    "case_2_pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feef090b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>20001_204</td>\n",
       "      <td>2</td>\n",
       "      <td>20001</td>\n",
       "      <td>204</td>\n",
       "      <td>['vaginal dryness', 'dryness which she uses lu...</td>\n",
       "      <td>['465 480', '473 509']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>20001_205</td>\n",
       "      <td>2</td>\n",
       "      <td>20001</td>\n",
       "      <td>205</td>\n",
       "      <td>['irregular periods', 'irregular periods']</td>\n",
       "      <td>['21 38', '63 80']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>20001_206</td>\n",
       "      <td>2</td>\n",
       "      <td>20001</td>\n",
       "      <td>206</td>\n",
       "      <td>['one week ago with nausea and vomiting', 'flu...</td>\n",
       "      <td>['238 275', '220 250']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>20001_208</td>\n",
       "      <td>2</td>\n",
       "      <td>20001</td>\n",
       "      <td>208</td>\n",
       "      <td>['female']</td>\n",
       "      <td>['10 16']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>20001_210</td>\n",
       "      <td>2</td>\n",
       "      <td>20001</td>\n",
       "      <td>210</td>\n",
       "      <td>['LMP was 2 months ago']</td>\n",
       "      <td>['129 149']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>22123_211</td>\n",
       "      <td>2</td>\n",
       "      <td>22123</td>\n",
       "      <td>211</td>\n",
       "      <td>['hot flashes']</td>\n",
       "      <td>['349 360']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>22123_212</td>\n",
       "      <td>2</td>\n",
       "      <td>22123</td>\n",
       "      <td>212</td>\n",
       "      <td>['1 or more elements (bleeding, duration) chan...</td>\n",
       "      <td>['172 235', '262 280', '237 260']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>22123_213</td>\n",
       "      <td>2</td>\n",
       "      <td>22123</td>\n",
       "      <td>213</td>\n",
       "      <td>['3 year history of']</td>\n",
       "      <td>['18 35']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>22123_214</td>\n",
       "      <td>2</td>\n",
       "      <td>22123</td>\n",
       "      <td>214</td>\n",
       "      <td>['sweating', 'sweating']</td>\n",
       "      <td>['318 326', '365 373']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>22123_216</td>\n",
       "      <td>2</td>\n",
       "      <td>22123</td>\n",
       "      <td>216</td>\n",
       "      <td>['44']</td>\n",
       "      <td>['0 2']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  case_num  pn_num  feature_num  \\\n",
       "2604  20001_204         2   20001          204   \n",
       "2605  20001_205         2   20001          205   \n",
       "2606  20001_206         2   20001          206   \n",
       "2608  20001_208         2   20001          208   \n",
       "2610  20001_210         2   20001          210   \n",
       "...         ...       ...     ...          ...   \n",
       "4294  22123_211         2   22123          211   \n",
       "4295  22123_212         2   22123          212   \n",
       "4296  22123_213         2   22123          213   \n",
       "4297  22123_214         2   22123          214   \n",
       "4299  22123_216         2   22123          216   \n",
       "\n",
       "                                             annotation  \\\n",
       "2604  ['vaginal dryness', 'dryness which she uses lu...   \n",
       "2605         ['irregular periods', 'irregular periods']   \n",
       "2606  ['one week ago with nausea and vomiting', 'flu...   \n",
       "2608                                         ['female']   \n",
       "2610                           ['LMP was 2 months ago']   \n",
       "...                                                 ...   \n",
       "4294                                    ['hot flashes']   \n",
       "4295  ['1 or more elements (bleeding, duration) chan...   \n",
       "4296                              ['3 year history of']   \n",
       "4297                           ['sweating', 'sweating']   \n",
       "4299                                             ['44']   \n",
       "\n",
       "                               location  \n",
       "2604             ['465 480', '473 509']  \n",
       "2605                 ['21 38', '63 80']  \n",
       "2606             ['238 275', '220 250']  \n",
       "2608                          ['10 16']  \n",
       "2610                        ['129 149']  \n",
       "...                                 ...  \n",
       "4294                        ['349 360']  \n",
       "4295  ['172 235', '262 280', '237 260']  \n",
       "4296                          ['18 35']  \n",
       "4297             ['318 326', '365 373']  \n",
       "4299                            ['0 2']  \n",
       "\n",
       "[998 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_train = train_data[train_data[\"case_num\"] == 2]\n",
    "case_2_train = case_2_train[case_2_train.annotation != '[]']\n",
    "case_2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da1ff03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[8,6])\n",
    "case_2_train.groupby(\"feature_num\").size().plot.bar()\n",
    "plt.title(\"CASE - 2\")\n",
    "plt.ylabel(\"Number of observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d685d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 201(25), 206(25), 207(11), 215(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6aea53",
   "metadata": {},
   "source": [
    "### Over Sampling for CASE - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e671458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_dict = {}\n",
    "for idx, row in case_2_pn.iterrows():\n",
    "    pn_dict[row['pn_num']] = row['pn_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beaa8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_annotation = []\n",
    "for case_id in case_2_features['case_num'].unique():\n",
    "    \n",
    "    all_pn_id = set(case_2_pn[case_2_pn['case_num']==case_id]['pn_num'].tolist())\n",
    "    \n",
    "    for feature_id in case_2_features[case_2_features['case_num']==case_id]['feature_num'].unique():\n",
    "        # get all the pn_num that have already been annotated\n",
    "        annotated_pn = set(case_2_train[case_2_train['feature_num']==feature_id]['pn_num'].tolist())\n",
    "        # get all the pn_num that have NOT been annotated\n",
    "        pn_to_annotate = all_pn_id-annotated_pn\n",
    "        \n",
    "        # get all current annotations\n",
    "        # we will use them to find more annotations\n",
    "        annotations = case_2_train[case_2_train['feature_num']==feature_id]['annotation'].tolist()\n",
    "        annotation_texts = set()\n",
    "        for a in annotations:\n",
    "            anns = eval(a)\n",
    "            for at in anns:\n",
    "                annotation_texts.add(at)\n",
    "                \n",
    "        # annotate       \n",
    "        for pn_id in pn_to_annotate:\n",
    "            new_annotation_pn, new_location_pn = [], []\n",
    "            pn_text = pn_dict[pn_id]\n",
    "            for at in annotation_texts:\n",
    "                start = pn_text.find(at)\n",
    "                if start>=0:\n",
    "                    new_annotation_pn.append(at)\n",
    "                    new_location_pn.append(f'{start} {start+len(at)}')\n",
    "            if len(new_annotation_pn)>0:\n",
    "                new_annotation.append((\n",
    "                    f'{pn_id:04d}_{feature_id:03d}',\n",
    "                    case_id,\n",
    "                    pn_id,\n",
    "                    feature_id,\n",
    "                    new_annotation_pn,\n",
    "                    new_location_pn\n",
    "                ))\n",
    "     #   break\n",
    "    break\n",
    "    # break to get sample results quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fbbf58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15224"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27e30925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20481_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20481</td>\n",
       "      <td>200</td>\n",
       "      <td>[periods were regular]</td>\n",
       "      <td>[117 137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20489_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20489</td>\n",
       "      <td>200</td>\n",
       "      <td>[Prior to this she had regular periods, had re...</td>\n",
       "      <td>[107 144, 125 144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20493_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20493</td>\n",
       "      <td>200</td>\n",
       "      <td>[periods were regular]</td>\n",
       "      <td>[594 614]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20496_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20496</td>\n",
       "      <td>200</td>\n",
       "      <td>[had regular periods]</td>\n",
       "      <td>[117 136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20499_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20499</td>\n",
       "      <td>200</td>\n",
       "      <td>[periods were regular]</td>\n",
       "      <td>[303 323]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1      2    3  \\\n",
       "0  20481_200  2  20481  200   \n",
       "1  20489_200  2  20489  200   \n",
       "2  20493_200  2  20493  200   \n",
       "3  20496_200  2  20496  200   \n",
       "4  20499_200  2  20499  200   \n",
       "\n",
       "                                                   4                   5  \n",
       "0                             [periods were regular]           [117 137]  \n",
       "1  [Prior to this she had regular periods, had re...  [107 144, 125 144]  \n",
       "2                             [periods were regular]           [594 614]  \n",
       "3                              [had regular periods]           [117 136]  \n",
       "4                             [periods were regular]           [303 323]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(new_annotation)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca32b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20481_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20481</td>\n",
       "      <td>200</td>\n",
       "      <td>[periods were regular]</td>\n",
       "      <td>[117 137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20489_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20489</td>\n",
       "      <td>200</td>\n",
       "      <td>[Prior to this she had regular periods, had re...</td>\n",
       "      <td>[107 144, 125 144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20493_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20493</td>\n",
       "      <td>200</td>\n",
       "      <td>[periods were regular]</td>\n",
       "      <td>[594 614]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20496_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20496</td>\n",
       "      <td>200</td>\n",
       "      <td>[had regular periods]</td>\n",
       "      <td>[117 136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20499_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20499</td>\n",
       "      <td>200</td>\n",
       "      <td>[periods were regular]</td>\n",
       "      <td>[303 323]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  20481_200         2   20481          200   \n",
       "1  20489_200         2   20489          200   \n",
       "2  20493_200         2   20493          200   \n",
       "3  20496_200         2   20496          200   \n",
       "4  20499_200         2   20499          200   \n",
       "\n",
       "                                          annotation            location  \n",
       "0                             [periods were regular]           [117 137]  \n",
       "1  [Prior to this she had regular periods, had re...  [107 144, 125 144]  \n",
       "2                             [periods were regular]           [594 614]  \n",
       "3                              [had regular periods]           [117 136]  \n",
       "4                             [periods were regular]           [303 323]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['id','case_num','pn_num','feature_num','annotation','location']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bb7cc0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20481_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20481</td>\n",
       "      <td>200</td>\n",
       "      <td>'periods were regular'</td>\n",
       "      <td>'117 137'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20489_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20489</td>\n",
       "      <td>200</td>\n",
       "      <td>'Prior to this she had regular periods', 'had ...</td>\n",
       "      <td>'107 144', '125 144'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20493_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20493</td>\n",
       "      <td>200</td>\n",
       "      <td>'periods were regular'</td>\n",
       "      <td>'594 614'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20496_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20496</td>\n",
       "      <td>200</td>\n",
       "      <td>'had regular periods'</td>\n",
       "      <td>'117 136'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20499_200</td>\n",
       "      <td>2</td>\n",
       "      <td>20499</td>\n",
       "      <td>200</td>\n",
       "      <td>'periods were regular'</td>\n",
       "      <td>'303 323'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  20481_200         2   20481          200   \n",
       "1  20489_200         2   20489          200   \n",
       "2  20493_200         2   20493          200   \n",
       "3  20496_200         2   20496          200   \n",
       "4  20499_200         2   20499          200   \n",
       "\n",
       "                                          annotation              location  \n",
       "0                             'periods were regular'             '117 137'  \n",
       "1  'Prior to this she had regular periods', 'had ...  '107 144', '125 144'  \n",
       "2                             'periods were regular'             '594 614'  \n",
       "3                              'had regular periods'             '117 136'  \n",
       "4                             'periods were regular'             '303 323'  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"location\"] = df[\"location\"].apply(str)\n",
    "df[\"annotation\"] = df[\"annotation\"].apply(str)\n",
    "\n",
    "df[\"annotation\"] = df.annotation.str.replace('[','')\n",
    "df[\"annotation\"] = df.annotation.str.replace(']','')\n",
    "df[\"location\"] = df.location.str.replace('[','')\n",
    "df[\"location\"] = df.location.str.replace(']','')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a209233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 201(25), 206(25), 207(11), 215(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "050cca3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3984, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df[\"feature_num\"] == 200)|(df[\"feature_num\"] == 201)|(df[\"feature_num\"] == 203)|(df[\"feature_num\"] == 206)|(df[\"feature_num\"] == 207)|(df[\"feature_num\"] == 215)|(df[\"feature_num\"] == 216)][['pn_num','annotation',\"location\",\"feature_num\"]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "839941f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20481</td>\n",
       "      <td>'periods were regular'</td>\n",
       "      <td>'117 137'</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20489</td>\n",
       "      <td>'Prior to this she had regular periods'</td>\n",
       "      <td>'107 144'</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20489</td>\n",
       "      <td>'had regular periods'</td>\n",
       "      <td>'125 144'</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20493</td>\n",
       "      <td>'periods were regular'</td>\n",
       "      <td>'594 614'</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20496</td>\n",
       "      <td>'had regular periods'</td>\n",
       "      <td>'117 136'</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294</th>\n",
       "      <td>20477</td>\n",
       "      <td>'44'</td>\n",
       "      <td>'34 36'</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295</th>\n",
       "      <td>20478</td>\n",
       "      <td>'44yo'</td>\n",
       "      <td>'8 12'</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7296</th>\n",
       "      <td>20478</td>\n",
       "      <td>'44'</td>\n",
       "      <td>'8 10'</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>20479</td>\n",
       "      <td>'44 YO'</td>\n",
       "      <td>'0 5'</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>20479</td>\n",
       "      <td>'44'</td>\n",
       "      <td>'0 2'</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  feature_num\n",
       "0      20481                   'periods were regular'   '117 137'          200\n",
       "1      20489  'Prior to this she had regular periods'   '107 144'          200\n",
       "2      20489                    'had regular periods'   '125 144'          200\n",
       "3      20493                   'periods were regular'   '594 614'          200\n",
       "4      20496                    'had regular periods'   '117 136'          200\n",
       "...      ...                                      ...         ...          ...\n",
       "7294   20477                                     '44'     '34 36'          216\n",
       "7295   20478                                   '44yo'      '8 12'          216\n",
       "7296   20478                                     '44'      '8 10'          216\n",
       "7297   20479                                  '44 YO'       '0 5'          216\n",
       "7298   20479                                     '44'       '0 2'          216\n",
       "\n",
       "[7299 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (df.set_index(['pn_num',\"feature_num\"]) \n",
    "   .apply(lambda col: col.str.split(',').explode())\n",
    "   .reset_index()\n",
    "   .reindex(df.columns, axis=1))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bddc89e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20481</td>\n",
       "      <td>'periods were regular'</td>\n",
       "      <td>'117 137'</td>\n",
       "      <td>200</td>\n",
       "      <td>117</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20489</td>\n",
       "      <td>'Prior to this she had regular periods'</td>\n",
       "      <td>'107 144'</td>\n",
       "      <td>200</td>\n",
       "      <td>107</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20489</td>\n",
       "      <td>'had regular periods'</td>\n",
       "      <td>'125 144'</td>\n",
       "      <td>200</td>\n",
       "      <td>125</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20493</td>\n",
       "      <td>'periods were regular'</td>\n",
       "      <td>'594 614'</td>\n",
       "      <td>200</td>\n",
       "      <td>594</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20496</td>\n",
       "      <td>'had regular periods'</td>\n",
       "      <td>'117 136'</td>\n",
       "      <td>200</td>\n",
       "      <td>117</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294</th>\n",
       "      <td>20477</td>\n",
       "      <td>'44'</td>\n",
       "      <td>'34 36'</td>\n",
       "      <td>216</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295</th>\n",
       "      <td>20478</td>\n",
       "      <td>'44yo'</td>\n",
       "      <td>'8 12'</td>\n",
       "      <td>216</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7296</th>\n",
       "      <td>20478</td>\n",
       "      <td>'44'</td>\n",
       "      <td>'8 10'</td>\n",
       "      <td>216</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>20479</td>\n",
       "      <td>'44 YO'</td>\n",
       "      <td>'0 5'</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>20479</td>\n",
       "      <td>'44'</td>\n",
       "      <td>'0 2'</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7299 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  \\\n",
       "0      20481                   'periods were regular'   '117 137'   \n",
       "1      20489  'Prior to this she had regular periods'   '107 144'   \n",
       "2      20489                    'had regular periods'   '125 144'   \n",
       "3      20493                   'periods were regular'   '594 614'   \n",
       "4      20496                    'had regular periods'   '117 136'   \n",
       "...      ...                                      ...         ...   \n",
       "7294   20477                                     '44'     '34 36'   \n",
       "7295   20478                                   '44yo'      '8 12'   \n",
       "7296   20478                                     '44'      '8 10'   \n",
       "7297   20479                                  '44 YO'       '0 5'   \n",
       "7298   20479                                     '44'       '0 2'   \n",
       "\n",
       "      feature_num start_location end_location  \n",
       "0             200            117          137  \n",
       "1             200            107          144  \n",
       "2             200            125          144  \n",
       "3             200            594          614  \n",
       "4             200            117          136  \n",
       "...           ...            ...          ...  \n",
       "7294          216             34           36  \n",
       "7295          216              8           12  \n",
       "7296          216              8           10  \n",
       "7297          216              0            5  \n",
       "7298          216              0            2  \n",
       "\n",
       "[7299 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"start_location\"] = df[\"location\"].apply(lambda x: x.split()[0][1:])\n",
    "df[\"end_location\"] = df[\"location\"].apply(lambda x: x.split()[-1][:-1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daec1836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_200 = df[df[\"feature_num\"] == 200].sample(n = 50, random_state = 100)\n",
    "df_200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e27a3009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_201 = df[df[\"feature_num\"] == 201].sample(n = 80, random_state = 100)\n",
    "df_201.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fc72d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_203 = df[df[\"feature_num\"] == 203].sample(n = 50, random_state = 100)\n",
    "df_203.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40234284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_206 = df[df[\"feature_num\"] == 206]\n",
    "df_206.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a88ae60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_207 = df[df[\"feature_num\"] == 207]\n",
    "df_207.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75e7b847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_215 = df[df[\"feature_num\"] == 215].sample(n = 88, random_state = 100)\n",
    "df_215.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f4cc8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7219, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df201_1 = df.drop(df_201.index, axis=0)\n",
    "df201_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b47b62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df201_1 = df201_1[df201_1[\"feature_num\"] == 201].sample(n = 50, random_state = 100)\n",
    "df201_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40b584bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_216 = df[df[\"feature_num\"] == 216].sample(n = 80, random_state = 100)\n",
    "df_216.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2c09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaabbfc6",
   "metadata": {},
   "source": [
    "### CASE - 2 Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2110f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_2_train = case_2_train[['pn_num','annotation',\"location\",\"feature_num\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "265bbe45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness', 'dryness which she uses lub...</td>\n",
       "      <td>'465 480', '473 509'</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods', 'irregular periods'</td>\n",
       "      <td>'21 38', '63 80'</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting', 'flu ...</td>\n",
       "      <td>'238 275', '220 250'</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>20001</td>\n",
       "      <td>'female'</td>\n",
       "      <td>'10 16'</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>20001</td>\n",
       "      <td>'LMP was 2 months ago'</td>\n",
       "      <td>'129 149'</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>22123</td>\n",
       "      <td>'hot flashes'</td>\n",
       "      <td>'349 360'</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>22123</td>\n",
       "      <td>'1 or more elements (bleeding, duration) chang...</td>\n",
       "      <td>'172 235', '262 280', '237 260'</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>22123</td>\n",
       "      <td>'3 year history of'</td>\n",
       "      <td>'18 35'</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>22123</td>\n",
       "      <td>'sweating', 'sweating'</td>\n",
       "      <td>'318 326', '365 373'</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>22123</td>\n",
       "      <td>'44'</td>\n",
       "      <td>'0 2'</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                                         annotation  \\\n",
       "2604   20001  'vaginal dryness', 'dryness which she uses lub...   \n",
       "2605   20001           'irregular periods', 'irregular periods'   \n",
       "2606   20001  'one week ago with nausea and vomiting', 'flu ...   \n",
       "2608   20001                                           'female'   \n",
       "2610   20001                             'LMP was 2 months ago'   \n",
       "...      ...                                                ...   \n",
       "4294   22123                                      'hot flashes'   \n",
       "4295   22123  '1 or more elements (bleeding, duration) chang...   \n",
       "4296   22123                                '3 year history of'   \n",
       "4297   22123                             'sweating', 'sweating'   \n",
       "4299   22123                                               '44'   \n",
       "\n",
       "                             location  feature_num  \n",
       "2604             '465 480', '473 509'          204  \n",
       "2605                 '21 38', '63 80'          205  \n",
       "2606             '238 275', '220 250'          206  \n",
       "2608                          '10 16'          208  \n",
       "2610                        '129 149'          210  \n",
       "...                               ...          ...  \n",
       "4294                        '349 360'          211  \n",
       "4295  '172 235', '262 280', '237 260'          212  \n",
       "4296                          '18 35'          213  \n",
       "4297             '318 326', '365 373'          214  \n",
       "4299                            '0 2'          216  \n",
       "\n",
       "[998 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_train[\"annotation\"] = case_2_train.annotation.str.replace('[','')\n",
    "case_2_train[\"annotation\"] = case_2_train.annotation.str.replace(']','')\n",
    "case_2_train[\"location\"] = case_2_train.location.str.replace('[','')\n",
    "case_2_train[\"location\"] = case_2_train.location.str.replace(']','')\n",
    "\n",
    "case_2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd7da78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'until 3 years ago, periods were regular'\",\"annotation\"] = \"'until 3 years ago  periods were regular'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'sometimes heavier sometimes lighter', 'sometimes with 6-7 pad changes/day, and sometimes lighter', 'interval is irregular', 'last between 2-6 days'\",\"annotation\"] = \"'sometimes heavier sometimes lighter', 'sometimes with 6-7 pad changes/day  and sometimes lighter', 'interval is irregular', 'last between 2-6 days'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'Previously, she had her period every 28-29 days'\",\"annotation\"] = \"'Previously  she had her period every 28-29 days'\" \n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'Last week, she also notes 48 hours of some kind of illness (nausea/vomiting)'\",\"annotation\"] = \"'Last week  she also notes 48 hours of some kind of illness (nausea/vomiting)'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'had menstrucal cramps and breast tenderness, but has not had these symptoms'\",\"annotation\"] = \"'had menstrucal cramps and breast tenderness  but has not had these symptoms'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'a week ago, she experienced nausea and vomiting'\",\"annotation\"] = \"'a week ago  she experienced nausea and vomiting'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'breast tenderness, mild cramps before her periods disappeared when her periods became irregular'\",\"annotation\"] = \"'breast tenderness  mild cramps before her periods disappeared when her periods became irregular'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'periods became very irregular', 'Sometimes the bleeding is very light, sometimes heavy', 'duration varies from 2-6 days'\",\"annotation\"] = \"'periods became very irregular', 'Sometimes the bleeding is very light  sometimes heavy', 'duration varies from 2-6 days'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"\"\"'irregular periods', 'have been \"unpredictable,\"'\"\"\",\"annotation\"] = \"\"\"'irregular periods', 'have been \"unpredictable \"'\"\"\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'previously regular periods', 'previously periods, each 28 days', 'previously periods lasting 5 days', 'previously periods moderate flow'\",\"annotation\"] = \"'previously regular periods', 'previously periods  each 28 days', 'previously periods lasting 5 days', 'previously periods moderate flow'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'until age 41 menses every 28-29 days', 'until age 41 menses lasting 4 days', 'until age 41, had regular menses', 'had regular menses'\",\"annotation\"] = \"'until age 41 menses every 28-29 days', 'until age 41 menses lasting 4 days', 'until age 41  had regular menses', 'had regular menses'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'periods occur from 3 weeks to 4 months', 'periods 2-6 days of bleeding', 'periods are heavy or light', 'Her periods no occur anywhere from 3 weeks to 4 months, 2-6 days of bleeding, and her periods are heavy or light', '2-6 days of bleeding', 'occur anywhere from 3 weeks to 4 months'\",\"annotation\"] = \"'periods occur from 3 weeks to 4 months', 'periods 2-6 days of bleeding', 'periods are heavy or light', 'Her periods no occur anywhere from 3 weeks to 4 months  2-6 days of bleeding  and her periods are heavy or light', '2-6 days of bleeding', 'occur anywhere from 3 weeks to 4 months'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'pap smears, last was 1 year'\",\"annotation\"] = \"'pap smears  last was 1 year'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'not associated with PMS symptoms', 'not associated with crmaps, breast tenderness, or back pain'\",\"annotation\"] = \"'not associated with PMS symptoms', 'not associated with crmaps  breast tenderness  or back pain'\"\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == ''''Last week, nausea', \"Last week flu-like sx's\"''',\"annotation\"] = ''''Last week  nausea', \"Last week flu-like sx's\"'''\n",
    "case_2_train.loc[case_2_train[\"annotation\"] == \"'1 or more elements (bleeding, duration) change with each period', '2-6 days of period', 'light to heavy bleeding'\",\"annotation\"] = \"'1 or more elements (bleeding  duration) change with each period', '2-6 days of period', 'light to heavy bleeding'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b544efc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness'</td>\n",
       "      <td>'465 480'</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>'dryness which she uses lubricant for'</td>\n",
       "      <td>'473 509'</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'21 38'</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'63 80'</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting'</td>\n",
       "      <td>'238 275'</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>22123</td>\n",
       "      <td>'light to heavy bleeding'</td>\n",
       "      <td>'237 260'</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>22123</td>\n",
       "      <td>'3 year history of'</td>\n",
       "      <td>'18 35'</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>22123</td>\n",
       "      <td>'sweating'</td>\n",
       "      <td>'318 326'</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>22123</td>\n",
       "      <td>'sweating'</td>\n",
       "      <td>'365 373'</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>22123</td>\n",
       "      <td>'44'</td>\n",
       "      <td>'0 2'</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1384 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  feature_num\n",
       "0      20001                        'vaginal dryness'   '465 480'          204\n",
       "1      20001   'dryness which she uses lubricant for'   '473 509'          204\n",
       "2      20001                      'irregular periods'     '21 38'          205\n",
       "3      20001                      'irregular periods'     '63 80'          205\n",
       "4      20001  'one week ago with nausea and vomiting'   '238 275'          206\n",
       "...      ...                                      ...         ...          ...\n",
       "1379   22123                'light to heavy bleeding'   '237 260'          212\n",
       "1380   22123                      '3 year history of'     '18 35'          213\n",
       "1381   22123                               'sweating'   '318 326'          214\n",
       "1382   22123                               'sweating'   '365 373'          214\n",
       "1383   22123                                     '44'       '0 2'          216\n",
       "\n",
       "[1384 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_train = (case_2_train.set_index(['pn_num',\"feature_num\"]) \n",
    "   .apply(lambda col: col.str.split(',').explode())\n",
    "   .reset_index()\n",
    "   .reindex(case_2_train.columns, axis=1))\n",
    "case_2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94487e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness'</td>\n",
       "      <td>'465 480'</td>\n",
       "      <td>204</td>\n",
       "      <td>465</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>'dryness which she uses lubricant for'</td>\n",
       "      <td>'473 509'</td>\n",
       "      <td>204</td>\n",
       "      <td>473</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'21 38'</td>\n",
       "      <td>205</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'63 80'</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting'</td>\n",
       "      <td>'238 275'</td>\n",
       "      <td>206</td>\n",
       "      <td>238</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>22123</td>\n",
       "      <td>'light to heavy bleeding'</td>\n",
       "      <td>'237 260'</td>\n",
       "      <td>212</td>\n",
       "      <td>237</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>22123</td>\n",
       "      <td>'3 year history of'</td>\n",
       "      <td>'18 35'</td>\n",
       "      <td>213</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>22123</td>\n",
       "      <td>'sweating'</td>\n",
       "      <td>'318 326'</td>\n",
       "      <td>214</td>\n",
       "      <td>318</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>22123</td>\n",
       "      <td>'sweating'</td>\n",
       "      <td>'365 373'</td>\n",
       "      <td>214</td>\n",
       "      <td>365</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>22123</td>\n",
       "      <td>'44'</td>\n",
       "      <td>'0 2'</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1384 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  \\\n",
       "0      20001                        'vaginal dryness'   '465 480'   \n",
       "1      20001   'dryness which she uses lubricant for'   '473 509'   \n",
       "2      20001                      'irregular periods'     '21 38'   \n",
       "3      20001                      'irregular periods'     '63 80'   \n",
       "4      20001  'one week ago with nausea and vomiting'   '238 275'   \n",
       "...      ...                                      ...         ...   \n",
       "1379   22123                'light to heavy bleeding'   '237 260'   \n",
       "1380   22123                      '3 year history of'     '18 35'   \n",
       "1381   22123                               'sweating'   '318 326'   \n",
       "1382   22123                               'sweating'   '365 373'   \n",
       "1383   22123                                     '44'       '0 2'   \n",
       "\n",
       "      feature_num start_location end_location  \n",
       "0             204            465          480  \n",
       "1             204            473          509  \n",
       "2             205             21           38  \n",
       "3             205             63           80  \n",
       "4             206            238          275  \n",
       "...           ...            ...          ...  \n",
       "1379          212            237          260  \n",
       "1380          213             18           35  \n",
       "1381          214            318          326  \n",
       "1382          214            365          373  \n",
       "1383          216              0            2  \n",
       "\n",
       "[1384 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_train[\"start_location\"] = case_2_train[\"location\"].apply(lambda x: x.split()[0][1:])\n",
    "case_2_train[\"end_location\"] = case_2_train[\"location\"].apply(lambda x: x.split()[-1][:-1])\n",
    "case_2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a3321e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1902, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2 = pd.concat([case_2_train, df_201, df_206, df_207, df_215,df_200,df201_1,df_216, df_203])\n",
    "case_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfa429da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness'</td>\n",
       "      <td>'465 480'</td>\n",
       "      <td>204</td>\n",
       "      <td>465</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>'dryness which she uses lubricant for'</td>\n",
       "      <td>'473 509'</td>\n",
       "      <td>204</td>\n",
       "      <td>473</td>\n",
       "      <td>509</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'21 38'</td>\n",
       "      <td>205</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'63 80'</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting'</td>\n",
       "      <td>'238 275'</td>\n",
       "      <td>206</td>\n",
       "      <td>238</td>\n",
       "      <td>275</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>20420</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'531 546'</td>\n",
       "      <td>203</td>\n",
       "      <td>531</td>\n",
       "      <td>546</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo f came to office with irregular periods ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>22013</td>\n",
       "      <td>'sex with her husband'</td>\n",
       "      <td>'486 506'</td>\n",
       "      <td>203</td>\n",
       "      <td>486</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>20781</td>\n",
       "      <td>'sexually active'</td>\n",
       "      <td>'514 529'</td>\n",
       "      <td>203</td>\n",
       "      <td>514</td>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>21001</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'599 614'</td>\n",
       "      <td>203</td>\n",
       "      <td>599</td>\n",
       "      <td>614</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo F complaining of irregular periods for l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>21629</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'829 844'</td>\n",
       "      <td>203</td>\n",
       "      <td>829</td>\n",
       "      <td>844</td>\n",
       "      <td>2</td>\n",
       "      <td>HPI: 44 yo female who presents with irregular ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1902 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  \\\n",
       "0      20001                        'vaginal dryness'   '465 480'   \n",
       "1      20001   'dryness which she uses lubricant for'   '473 509'   \n",
       "2      20001                      'irregular periods'     '21 38'   \n",
       "3      20001                      'irregular periods'     '63 80'   \n",
       "4      20001  'one week ago with nausea and vomiting'   '238 275'   \n",
       "...      ...                                      ...         ...   \n",
       "1897   20420                        'Sexually active'   '531 546'   \n",
       "1898   22013                   'sex with her husband'   '486 506'   \n",
       "1899   20781                        'sexually active'   '514 529'   \n",
       "1900   21001                        'Sexually active'   '599 614'   \n",
       "1901   21629                        'Sexually active'   '829 844'   \n",
       "\n",
       "      feature_num start_location end_location  case_num  \\\n",
       "0             204            465          480         2   \n",
       "1             204            473          509         2   \n",
       "2             205             21           38         2   \n",
       "3             205             63           80         2   \n",
       "4             206            238          275         2   \n",
       "...           ...            ...          ...       ...   \n",
       "1897          203            531          546         2   \n",
       "1898          203            486          506         2   \n",
       "1899          203            514          529         2   \n",
       "1900          203            599          614         2   \n",
       "1901          203            829          844         2   \n",
       "\n",
       "                                             pn_history  \n",
       "0     CC: 44 yo female c/o irregular periods\\r\\nHPI:...  \n",
       "1     CC: 44 yo female c/o irregular periods\\r\\nHPI:...  \n",
       "2     CC: 44 yo female c/o irregular periods\\r\\nHPI:...  \n",
       "3     CC: 44 yo female c/o irregular periods\\r\\nHPI:...  \n",
       "4     CC: 44 yo female c/o irregular periods\\r\\nHPI:...  \n",
       "...                                                 ...  \n",
       "1897  44 yo f came to office with irregular periods ...  \n",
       "1898  Pt is a 44 year old female coming in for irreg...  \n",
       "1899  pt is a 44 yo f presenting with irregular peri...  \n",
       "1900  44 yo F complaining of irregular periods for l...  \n",
       "1901  HPI: 44 yo female who presents with irregular ...  \n",
       "\n",
       "[1902 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2 = case_2.merge(patient_notes, on='pn_num', how='left')\n",
    "case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ec6542b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness'</td>\n",
       "      <td>'465 480'</td>\n",
       "      <td>204</td>\n",
       "      <td>465</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>vaginal dryness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>'dryness which she uses lubricant for'</td>\n",
       "      <td>'473 509'</td>\n",
       "      <td>204</td>\n",
       "      <td>473</td>\n",
       "      <td>509</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>dryness which she uses lubricant for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'21 38'</td>\n",
       "      <td>205</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular periods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'63 80'</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular periods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting'</td>\n",
       "      <td>'238 275'</td>\n",
       "      <td>206</td>\n",
       "      <td>238</td>\n",
       "      <td>275</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>one week ago with nausea and vomiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>20420</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'531 546'</td>\n",
       "      <td>203</td>\n",
       "      <td>531</td>\n",
       "      <td>546</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo f came to office with irregular periods ...</td>\n",
       "      <td>Sexually active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>22013</td>\n",
       "      <td>'sex with her husband'</td>\n",
       "      <td>'486 506'</td>\n",
       "      <td>203</td>\n",
       "      <td>486</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "      <td>sex with her husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>20781</td>\n",
       "      <td>'sexually active'</td>\n",
       "      <td>'514 529'</td>\n",
       "      <td>203</td>\n",
       "      <td>514</td>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "      <td>sexually active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>21001</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'599 614'</td>\n",
       "      <td>203</td>\n",
       "      <td>599</td>\n",
       "      <td>614</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo F complaining of irregular periods for l...</td>\n",
       "      <td>Sexually active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>21629</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'829 844'</td>\n",
       "      <td>203</td>\n",
       "      <td>829</td>\n",
       "      <td>844</td>\n",
       "      <td>2</td>\n",
       "      <td>HPI: 44 yo female who presents with irregular ...</td>\n",
       "      <td>Sexually active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1902 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  \\\n",
       "0      20001                        'vaginal dryness'   '465 480'   \n",
       "1      20001   'dryness which she uses lubricant for'   '473 509'   \n",
       "2      20001                      'irregular periods'     '21 38'   \n",
       "3      20001                      'irregular periods'     '63 80'   \n",
       "4      20001  'one week ago with nausea and vomiting'   '238 275'   \n",
       "...      ...                                      ...         ...   \n",
       "1897   20420                        'Sexually active'   '531 546'   \n",
       "1898   22013                   'sex with her husband'   '486 506'   \n",
       "1899   20781                        'sexually active'   '514 529'   \n",
       "1900   21001                        'Sexually active'   '599 614'   \n",
       "1901   21629                        'Sexually active'   '829 844'   \n",
       "\n",
       "      feature_num start_location end_location  case_num  \\\n",
       "0             204            465          480         2   \n",
       "1             204            473          509         2   \n",
       "2             205             21           38         2   \n",
       "3             205             63           80         2   \n",
       "4             206            238          275         2   \n",
       "...           ...            ...          ...       ...   \n",
       "1897          203            531          546         2   \n",
       "1898          203            486          506         2   \n",
       "1899          203            514          529         2   \n",
       "1900          203            599          614         2   \n",
       "1901          203            829          844         2   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "1     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "2     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "3     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "4     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "...                                                 ...   \n",
       "1897  44 yo f came to office with irregular periods ...   \n",
       "1898  Pt is a 44 year old female coming in for irreg...   \n",
       "1899  pt is a 44 yo f presenting with irregular peri...   \n",
       "1900  44 yo F complaining of irregular periods for l...   \n",
       "1901  HPI: 44 yo female who presents with irregular ...   \n",
       "\n",
       "                             New_annotation  \n",
       "0                           vaginal dryness  \n",
       "1      dryness which she uses lubricant for  \n",
       "2                         irregular periods  \n",
       "3                         irregular periods  \n",
       "4     one week ago with nausea and vomiting  \n",
       "...                                     ...  \n",
       "1897                        Sexually active  \n",
       "1898                   sex with her husband  \n",
       "1899                        sexually active  \n",
       "1900                        Sexually active  \n",
       "1901                        Sexually active  \n",
       "\n",
       "[1902 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2[\"New_annotation\"] = case_2.apply(lambda x: x.pn_history[int(x.start_location):int(x.end_location)],axis=1)\n",
    "case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aea3f30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness'</td>\n",
       "      <td>'465 480'</td>\n",
       "      <td>204</td>\n",
       "      <td>465</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>vaginal dryness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>'dryness which she uses lubricant for'</td>\n",
       "      <td>'473 509'</td>\n",
       "      <td>204</td>\n",
       "      <td>473</td>\n",
       "      <td>509</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>dryness which she uses lubricant for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'21 38'</td>\n",
       "      <td>205</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular periods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'63 80'</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular periods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting'</td>\n",
       "      <td>'238 275'</td>\n",
       "      <td>206</td>\n",
       "      <td>238</td>\n",
       "      <td>275</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>one week ago with nausea and vomiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>20420</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'531 546'</td>\n",
       "      <td>203</td>\n",
       "      <td>531</td>\n",
       "      <td>546</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo f came to office with irregular periods ...</td>\n",
       "      <td>Sexually active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>22013</td>\n",
       "      <td>'sex with her husband'</td>\n",
       "      <td>'486 506'</td>\n",
       "      <td>203</td>\n",
       "      <td>486</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "      <td>sex with her husband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>20781</td>\n",
       "      <td>'sexually active'</td>\n",
       "      <td>'514 529'</td>\n",
       "      <td>203</td>\n",
       "      <td>514</td>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "      <td>sexually active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>21001</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'599 614'</td>\n",
       "      <td>203</td>\n",
       "      <td>599</td>\n",
       "      <td>614</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo F complaining of irregular periods for l...</td>\n",
       "      <td>Sexually active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>21629</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'829 844'</td>\n",
       "      <td>203</td>\n",
       "      <td>829</td>\n",
       "      <td>844</td>\n",
       "      <td>2</td>\n",
       "      <td>HPI: 44 yo female who presents with irregular ...</td>\n",
       "      <td>Sexually active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1902 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  \\\n",
       "0      20001                        'vaginal dryness'   '465 480'   \n",
       "1      20001   'dryness which she uses lubricant for'   '473 509'   \n",
       "2      20001                      'irregular periods'     '21 38'   \n",
       "3      20001                      'irregular periods'     '63 80'   \n",
       "4      20001  'one week ago with nausea and vomiting'   '238 275'   \n",
       "...      ...                                      ...         ...   \n",
       "1897   20420                        'Sexually active'   '531 546'   \n",
       "1898   22013                   'sex with her husband'   '486 506'   \n",
       "1899   20781                        'sexually active'   '514 529'   \n",
       "1900   21001                        'Sexually active'   '599 614'   \n",
       "1901   21629                        'Sexually active'   '829 844'   \n",
       "\n",
       "      feature_num start_location end_location  case_num  \\\n",
       "0             204            465          480         2   \n",
       "1             204            473          509         2   \n",
       "2             205             21           38         2   \n",
       "3             205             63           80         2   \n",
       "4             206            238          275         2   \n",
       "...           ...            ...          ...       ...   \n",
       "1897          203            531          546         2   \n",
       "1898          203            486          506         2   \n",
       "1899          203            514          529         2   \n",
       "1900          203            599          614         2   \n",
       "1901          203            829          844         2   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "1     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "2     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "3     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "4     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "...                                                 ...   \n",
       "1897  44 yo f came to office with irregular periods ...   \n",
       "1898  Pt is a 44 year old female coming in for irreg...   \n",
       "1899  pt is a 44 yo f presenting with irregular peri...   \n",
       "1900  44 yo F complaining of irregular periods for l...   \n",
       "1901  HPI: 44 yo female who presents with irregular ...   \n",
       "\n",
       "                             New_annotation  \n",
       "0                           vaginal dryness  \n",
       "1      dryness which she uses lubricant for  \n",
       "2                         irregular periods  \n",
       "3                         irregular periods  \n",
       "4     one week ago with nausea and vomiting  \n",
       "...                                     ...  \n",
       "1897                        Sexually active  \n",
       "1898                   sex with her husband  \n",
       "1899                        sexually active  \n",
       "1900                        Sexually active  \n",
       "1901                        Sexually active  \n",
       "\n",
       "[1902 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2[\"New_annotation\"] = case_2[\"New_annotation\"].apply(lambda x: re.sub(r'''[/\"+,()\\r\\n]''',' ',x))\n",
    "case_2[\"New_annotation\"] = case_2[\"New_annotation\"].apply(lambda x: re.sub(r'''[']''','',x))\n",
    "case_2[\"New_annotation\"] = case_2[\"New_annotation\"].apply(lambda x: x.strip())\n",
    "case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "099b0e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "      <th>New_pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness'</td>\n",
       "      <td>'465 480'</td>\n",
       "      <td>204</td>\n",
       "      <td>465</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>vaginal dryness</td>\n",
       "      <td>CC: 44 yo female c o irregular periods  HPI: x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>'dryness which she uses lubricant for'</td>\n",
       "      <td>'473 509'</td>\n",
       "      <td>204</td>\n",
       "      <td>473</td>\n",
       "      <td>509</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>dryness which she uses lubricant for</td>\n",
       "      <td>CC: 44 yo female c o irregular periods  HPI: x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'21 38'</td>\n",
       "      <td>205</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular periods</td>\n",
       "      <td>CC: 44 yo female c o irregular periods  HPI: x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'63 80'</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular periods</td>\n",
       "      <td>CC: 44 yo female c o irregular periods  HPI: x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting'</td>\n",
       "      <td>'238 275'</td>\n",
       "      <td>206</td>\n",
       "      <td>238</td>\n",
       "      <td>275</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>one week ago with nausea and vomiting</td>\n",
       "      <td>CC: 44 yo female c o irregular periods  HPI: x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>20420</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'531 546'</td>\n",
       "      <td>203</td>\n",
       "      <td>531</td>\n",
       "      <td>546</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo f came to office with irregular periods ...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>44 yo f came to office with irregular periods ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>22013</td>\n",
       "      <td>'sex with her husband'</td>\n",
       "      <td>'486 506'</td>\n",
       "      <td>203</td>\n",
       "      <td>486</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "      <td>sex with her husband</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>20781</td>\n",
       "      <td>'sexually active'</td>\n",
       "      <td>'514 529'</td>\n",
       "      <td>203</td>\n",
       "      <td>514</td>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "      <td>sexually active</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>21001</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'599 614'</td>\n",
       "      <td>203</td>\n",
       "      <td>599</td>\n",
       "      <td>614</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo F complaining of irregular periods for l...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>44 yo F complaining of irregular periods for l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>21629</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'829 844'</td>\n",
       "      <td>203</td>\n",
       "      <td>829</td>\n",
       "      <td>844</td>\n",
       "      <td>2</td>\n",
       "      <td>HPI: 44 yo female who presents with irregular ...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>HPI: 44 yo female who presents with irregular ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1902 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  \\\n",
       "0      20001                        'vaginal dryness'   '465 480'   \n",
       "1      20001   'dryness which she uses lubricant for'   '473 509'   \n",
       "2      20001                      'irregular periods'     '21 38'   \n",
       "3      20001                      'irregular periods'     '63 80'   \n",
       "4      20001  'one week ago with nausea and vomiting'   '238 275'   \n",
       "...      ...                                      ...         ...   \n",
       "1897   20420                        'Sexually active'   '531 546'   \n",
       "1898   22013                   'sex with her husband'   '486 506'   \n",
       "1899   20781                        'sexually active'   '514 529'   \n",
       "1900   21001                        'Sexually active'   '599 614'   \n",
       "1901   21629                        'Sexually active'   '829 844'   \n",
       "\n",
       "      feature_num start_location end_location  case_num  \\\n",
       "0             204            465          480         2   \n",
       "1             204            473          509         2   \n",
       "2             205             21           38         2   \n",
       "3             205             63           80         2   \n",
       "4             206            238          275         2   \n",
       "...           ...            ...          ...       ...   \n",
       "1897          203            531          546         2   \n",
       "1898          203            486          506         2   \n",
       "1899          203            514          529         2   \n",
       "1900          203            599          614         2   \n",
       "1901          203            829          844         2   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "1     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "2     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "3     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "4     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "...                                                 ...   \n",
       "1897  44 yo f came to office with irregular periods ...   \n",
       "1898  Pt is a 44 year old female coming in for irreg...   \n",
       "1899  pt is a 44 yo f presenting with irregular peri...   \n",
       "1900  44 yo F complaining of irregular periods for l...   \n",
       "1901  HPI: 44 yo female who presents with irregular ...   \n",
       "\n",
       "                             New_annotation  \\\n",
       "0                           vaginal dryness   \n",
       "1      dryness which she uses lubricant for   \n",
       "2                         irregular periods   \n",
       "3                         irregular periods   \n",
       "4     one week ago with nausea and vomiting   \n",
       "...                                     ...   \n",
       "1897                        Sexually active   \n",
       "1898                   sex with her husband   \n",
       "1899                        sexually active   \n",
       "1900                        Sexually active   \n",
       "1901                        Sexually active   \n",
       "\n",
       "                                         New_pn_history  \n",
       "0     CC: 44 yo female c o irregular periods  HPI: x...  \n",
       "1     CC: 44 yo female c o irregular periods  HPI: x...  \n",
       "2     CC: 44 yo female c o irregular periods  HPI: x...  \n",
       "3     CC: 44 yo female c o irregular periods  HPI: x...  \n",
       "4     CC: 44 yo female c o irregular periods  HPI: x...  \n",
       "...                                                 ...  \n",
       "1897  44 yo f came to office with irregular periods ...  \n",
       "1898  Pt is a 44 year old female coming in for irreg...  \n",
       "1899  pt is a 44 yo f presenting with irregular peri...  \n",
       "1900  44 yo F complaining of irregular periods for l...  \n",
       "1901  HPI: 44 yo female who presents with irregular ...  \n",
       "\n",
       "[1902 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2[\"New_pn_history\"] = case_2[\"pn_history\"].apply(lambda x: re.sub(r'''[/\",+()\\r\\n]''',' ',x))\n",
    "case_2[\"New_pn_history\"] = case_2[\"New_pn_history\"].apply(lambda x: re.sub(r'''[']''','',x))\n",
    "case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d589871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemm(sentence):\n",
    "    word_list = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    lemmaztier = WordNetLemmatizer()\n",
    "    lemmatized_output = ' '.join([lemmaztier.lemmatize(w) for w in word_list])\n",
    "    return(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4b3e690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "      <th>New_pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness'</td>\n",
       "      <td>'465 480'</td>\n",
       "      <td>204</td>\n",
       "      <td>465</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>vaginal dryness</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>'dryness which she uses lubricant for'</td>\n",
       "      <td>'473 509'</td>\n",
       "      <td>204</td>\n",
       "      <td>473</td>\n",
       "      <td>509</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>dryness which she us lubricant for</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'21 38'</td>\n",
       "      <td>205</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular period</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'63 80'</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular period</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting'</td>\n",
       "      <td>'238 275'</td>\n",
       "      <td>206</td>\n",
       "      <td>238</td>\n",
       "      <td>275</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>one week ago with nausea and vomiting</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pn_num                               annotation    location  feature_num  \\\n",
       "0   20001                        'vaginal dryness'   '465 480'          204   \n",
       "1   20001   'dryness which she uses lubricant for'   '473 509'          204   \n",
       "2   20001                      'irregular periods'     '21 38'          205   \n",
       "3   20001                      'irregular periods'     '63 80'          205   \n",
       "4   20001  'one week ago with nausea and vomiting'   '238 275'          206   \n",
       "\n",
       "  start_location end_location  case_num  \\\n",
       "0            465          480         2   \n",
       "1            473          509         2   \n",
       "2             21           38         2   \n",
       "3             63           80         2   \n",
       "4            238          275         2   \n",
       "\n",
       "                                          pn_history  \\\n",
       "0  CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "1  CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "2  CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "3  CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "4  CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "\n",
       "                          New_annotation  \\\n",
       "0                        vaginal dryness   \n",
       "1     dryness which she us lubricant for   \n",
       "2                       irregular period   \n",
       "3                       irregular period   \n",
       "4  one week ago with nausea and vomiting   \n",
       "\n",
       "                                      New_pn_history  \n",
       "0  CC : 44 yo female c o irregular period HPI : x...  \n",
       "1  CC : 44 yo female c o irregular period HPI : x...  \n",
       "2  CC : 44 yo female c o irregular period HPI : x...  \n",
       "3  CC : 44 yo female c o irregular period HPI : x...  \n",
       "4  CC : 44 yo female c o irregular period HPI : x...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2[\"New_annotation\"] = case_2[\"New_annotation\"].apply(word_lemm)\n",
    "case_2[\"New_pn_history\"] = case_2[\"New_pn_history\"].apply(word_lemm)\n",
    "case_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9d2cfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "      <th>New_pn_history</th>\n",
       "      <th>new_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness'</td>\n",
       "      <td>'465 480'</td>\n",
       "      <td>204</td>\n",
       "      <td>465</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>vaginal dryness</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(455, 470), match='vagi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>'dryness which she uses lubricant for'</td>\n",
       "      <td>'473 509'</td>\n",
       "      <td>204</td>\n",
       "      <td>473</td>\n",
       "      <td>509</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>dryness which she us lubricant for</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(463, 497), match='dryn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'21 38'</td>\n",
       "      <td>205</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular period</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(22, 38), match='irregu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'63 80'</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular period</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(22, 38), match='irregu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting'</td>\n",
       "      <td>'238 275'</td>\n",
       "      <td>206</td>\n",
       "      <td>238</td>\n",
       "      <td>275</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>one week ago with nausea and vomiting</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(233, 270), match='one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>20420</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'531 546'</td>\n",
       "      <td>203</td>\n",
       "      <td>531</td>\n",
       "      <td>546</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo f came to office with irregular periods ...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>44 yo f came to office with irregular period f...</td>\n",
       "      <td>&lt;re.Match object; span=(503, 518), match='Sexu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>22013</td>\n",
       "      <td>'sex with her husband'</td>\n",
       "      <td>'486 506'</td>\n",
       "      <td>203</td>\n",
       "      <td>486</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "      <td>sex with her husband</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "      <td>&lt;re.Match object; span=(480, 500), match='sex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>20781</td>\n",
       "      <td>'sexually active'</td>\n",
       "      <td>'514 529'</td>\n",
       "      <td>203</td>\n",
       "      <td>514</td>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "      <td>sexually active</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "      <td>&lt;re.Match object; span=(495, 510), match='sexu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>21001</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'599 614'</td>\n",
       "      <td>203</td>\n",
       "      <td>599</td>\n",
       "      <td>614</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo F complaining of irregular periods for l...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>44 yo F complaining of irregular period for la...</td>\n",
       "      <td>&lt;re.Match object; span=(580, 595), match='Sexu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>21629</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'829 844'</td>\n",
       "      <td>203</td>\n",
       "      <td>829</td>\n",
       "      <td>844</td>\n",
       "      <td>2</td>\n",
       "      <td>HPI: 44 yo female who presents with irregular ...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>HPI : 44 yo female who present with irregular ...</td>\n",
       "      <td>&lt;re.Match object; span=(811, 826), match='Sexu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1902 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  \\\n",
       "0      20001                        'vaginal dryness'   '465 480'   \n",
       "1      20001   'dryness which she uses lubricant for'   '473 509'   \n",
       "2      20001                      'irregular periods'     '21 38'   \n",
       "3      20001                      'irregular periods'     '63 80'   \n",
       "4      20001  'one week ago with nausea and vomiting'   '238 275'   \n",
       "...      ...                                      ...         ...   \n",
       "1897   20420                        'Sexually active'   '531 546'   \n",
       "1898   22013                   'sex with her husband'   '486 506'   \n",
       "1899   20781                        'sexually active'   '514 529'   \n",
       "1900   21001                        'Sexually active'   '599 614'   \n",
       "1901   21629                        'Sexually active'   '829 844'   \n",
       "\n",
       "      feature_num start_location end_location  case_num  \\\n",
       "0             204            465          480         2   \n",
       "1             204            473          509         2   \n",
       "2             205             21           38         2   \n",
       "3             205             63           80         2   \n",
       "4             206            238          275         2   \n",
       "...           ...            ...          ...       ...   \n",
       "1897          203            531          546         2   \n",
       "1898          203            486          506         2   \n",
       "1899          203            514          529         2   \n",
       "1900          203            599          614         2   \n",
       "1901          203            829          844         2   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "1     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "2     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "3     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "4     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "...                                                 ...   \n",
       "1897  44 yo f came to office with irregular periods ...   \n",
       "1898  Pt is a 44 year old female coming in for irreg...   \n",
       "1899  pt is a 44 yo f presenting with irregular peri...   \n",
       "1900  44 yo F complaining of irregular periods for l...   \n",
       "1901  HPI: 44 yo female who presents with irregular ...   \n",
       "\n",
       "                             New_annotation  \\\n",
       "0                           vaginal dryness   \n",
       "1        dryness which she us lubricant for   \n",
       "2                          irregular period   \n",
       "3                          irregular period   \n",
       "4     one week ago with nausea and vomiting   \n",
       "...                                     ...   \n",
       "1897                        Sexually active   \n",
       "1898                   sex with her husband   \n",
       "1899                        sexually active   \n",
       "1900                        Sexually active   \n",
       "1901                        Sexually active   \n",
       "\n",
       "                                         New_pn_history  \\\n",
       "0     CC : 44 yo female c o irregular period HPI : x...   \n",
       "1     CC : 44 yo female c o irregular period HPI : x...   \n",
       "2     CC : 44 yo female c o irregular period HPI : x...   \n",
       "3     CC : 44 yo female c o irregular period HPI : x...   \n",
       "4     CC : 44 yo female c o irregular period HPI : x...   \n",
       "...                                                 ...   \n",
       "1897  44 yo f came to office with irregular period f...   \n",
       "1898  Pt is a 44 year old female coming in for irreg...   \n",
       "1899  pt is a 44 yo f presenting with irregular peri...   \n",
       "1900  44 yo F complaining of irregular period for la...   \n",
       "1901  HPI : 44 yo female who present with irregular ...   \n",
       "\n",
       "                                           new_location  \n",
       "0     <re.Match object; span=(455, 470), match='vagi...  \n",
       "1     <re.Match object; span=(463, 497), match='dryn...  \n",
       "2     <re.Match object; span=(22, 38), match='irregu...  \n",
       "3     <re.Match object; span=(22, 38), match='irregu...  \n",
       "4     <re.Match object; span=(233, 270), match='one ...  \n",
       "...                                                 ...  \n",
       "1897  <re.Match object; span=(503, 518), match='Sexu...  \n",
       "1898  <re.Match object; span=(480, 500), match='sex ...  \n",
       "1899  <re.Match object; span=(495, 510), match='sexu...  \n",
       "1900  <re.Match object; span=(580, 595), match='Sexu...  \n",
       "1901  <re.Match object; span=(811, 826), match='Sexu...  \n",
       "\n",
       "[1902 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2[\"new_location\"] = case_2.apply(lambda x :re.search(r'\\b' + x.New_annotation + r'\\b', x.New_pn_history),axis =1)\n",
    "case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5929ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 157, 164, 234, 241, 253, 263, 270, 473, 490, 503, 808, 810, 852, 1175, 1283, 1289, 1315, 1388, 1389, 1393, 1398, 1401, 1402, 1403, 1415, 1417, 1418, 1419, 1421, 1433, 1437, 1439, 1445, 1453, 1454, 1600, 1685, 1724, 1728, 1729, 1730, 1736, 1737, 1739, 1740, 1743, 1749, 1761, 1777, 1782, 1794, 1796, 1813, 1832, 1895, 1896]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 57)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_index = []\n",
    "for  index,row in case_2.iterrows():\n",
    "    if row[\"new_location\"] == None:\n",
    "        drop_index.append(index)\n",
    "        \n",
    "print(drop_index),len(drop_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a680e6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "      <th>New_pn_history</th>\n",
       "      <th>new_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness'</td>\n",
       "      <td>'465 480'</td>\n",
       "      <td>204</td>\n",
       "      <td>465</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>vaginal dryness</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(455, 470), match='vagi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>'dryness which she uses lubricant for'</td>\n",
       "      <td>'473 509'</td>\n",
       "      <td>204</td>\n",
       "      <td>473</td>\n",
       "      <td>509</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>dryness which she us lubricant for</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(463, 497), match='dryn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'21 38'</td>\n",
       "      <td>205</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular period</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(22, 38), match='irregu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'63 80'</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular period</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(22, 38), match='irregu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting'</td>\n",
       "      <td>'238 275'</td>\n",
       "      <td>206</td>\n",
       "      <td>238</td>\n",
       "      <td>275</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>one week ago with nausea and vomiting</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(233, 270), match='one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>20420</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'531 546'</td>\n",
       "      <td>203</td>\n",
       "      <td>531</td>\n",
       "      <td>546</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo f came to office with irregular periods ...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>44 yo f came to office with irregular period f...</td>\n",
       "      <td>&lt;re.Match object; span=(503, 518), match='Sexu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>22013</td>\n",
       "      <td>'sex with her husband'</td>\n",
       "      <td>'486 506'</td>\n",
       "      <td>203</td>\n",
       "      <td>486</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "      <td>sex with her husband</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "      <td>&lt;re.Match object; span=(480, 500), match='sex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>20781</td>\n",
       "      <td>'sexually active'</td>\n",
       "      <td>'514 529'</td>\n",
       "      <td>203</td>\n",
       "      <td>514</td>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "      <td>sexually active</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "      <td>&lt;re.Match object; span=(495, 510), match='sexu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>21001</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'599 614'</td>\n",
       "      <td>203</td>\n",
       "      <td>599</td>\n",
       "      <td>614</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo F complaining of irregular periods for l...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>44 yo F complaining of irregular period for la...</td>\n",
       "      <td>&lt;re.Match object; span=(580, 595), match='Sexu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>21629</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'829 844'</td>\n",
       "      <td>203</td>\n",
       "      <td>829</td>\n",
       "      <td>844</td>\n",
       "      <td>2</td>\n",
       "      <td>HPI: 44 yo female who presents with irregular ...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>HPI : 44 yo female who present with irregular ...</td>\n",
       "      <td>&lt;re.Match object; span=(811, 826), match='Sexu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1845 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  \\\n",
       "0      20001                        'vaginal dryness'   '465 480'   \n",
       "1      20001   'dryness which she uses lubricant for'   '473 509'   \n",
       "2      20001                      'irregular periods'     '21 38'   \n",
       "3      20001                      'irregular periods'     '63 80'   \n",
       "4      20001  'one week ago with nausea and vomiting'   '238 275'   \n",
       "...      ...                                      ...         ...   \n",
       "1897   20420                        'Sexually active'   '531 546'   \n",
       "1898   22013                   'sex with her husband'   '486 506'   \n",
       "1899   20781                        'sexually active'   '514 529'   \n",
       "1900   21001                        'Sexually active'   '599 614'   \n",
       "1901   21629                        'Sexually active'   '829 844'   \n",
       "\n",
       "      feature_num start_location end_location  case_num  \\\n",
       "0             204            465          480         2   \n",
       "1             204            473          509         2   \n",
       "2             205             21           38         2   \n",
       "3             205             63           80         2   \n",
       "4             206            238          275         2   \n",
       "...           ...            ...          ...       ...   \n",
       "1897          203            531          546         2   \n",
       "1898          203            486          506         2   \n",
       "1899          203            514          529         2   \n",
       "1900          203            599          614         2   \n",
       "1901          203            829          844         2   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "1     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "2     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "3     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "4     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "...                                                 ...   \n",
       "1897  44 yo f came to office with irregular periods ...   \n",
       "1898  Pt is a 44 year old female coming in for irreg...   \n",
       "1899  pt is a 44 yo f presenting with irregular peri...   \n",
       "1900  44 yo F complaining of irregular periods for l...   \n",
       "1901  HPI: 44 yo female who presents with irregular ...   \n",
       "\n",
       "                             New_annotation  \\\n",
       "0                           vaginal dryness   \n",
       "1        dryness which she us lubricant for   \n",
       "2                          irregular period   \n",
       "3                          irregular period   \n",
       "4     one week ago with nausea and vomiting   \n",
       "...                                     ...   \n",
       "1897                        Sexually active   \n",
       "1898                   sex with her husband   \n",
       "1899                        sexually active   \n",
       "1900                        Sexually active   \n",
       "1901                        Sexually active   \n",
       "\n",
       "                                         New_pn_history  \\\n",
       "0     CC : 44 yo female c o irregular period HPI : x...   \n",
       "1     CC : 44 yo female c o irregular period HPI : x...   \n",
       "2     CC : 44 yo female c o irregular period HPI : x...   \n",
       "3     CC : 44 yo female c o irregular period HPI : x...   \n",
       "4     CC : 44 yo female c o irregular period HPI : x...   \n",
       "...                                                 ...   \n",
       "1897  44 yo f came to office with irregular period f...   \n",
       "1898  Pt is a 44 year old female coming in for irreg...   \n",
       "1899  pt is a 44 yo f presenting with irregular peri...   \n",
       "1900  44 yo F complaining of irregular period for la...   \n",
       "1901  HPI : 44 yo female who present with irregular ...   \n",
       "\n",
       "                                           new_location  \n",
       "0     <re.Match object; span=(455, 470), match='vagi...  \n",
       "1     <re.Match object; span=(463, 497), match='dryn...  \n",
       "2     <re.Match object; span=(22, 38), match='irregu...  \n",
       "3     <re.Match object; span=(22, 38), match='irregu...  \n",
       "4     <re.Match object; span=(233, 270), match='one ...  \n",
       "...                                                 ...  \n",
       "1897  <re.Match object; span=(503, 518), match='Sexu...  \n",
       "1898  <re.Match object; span=(480, 500), match='sex ...  \n",
       "1899  <re.Match object; span=(495, 510), match='sexu...  \n",
       "1900  <re.Match object; span=(580, 595), match='Sexu...  \n",
       "1901  <re.Match object; span=(811, 826), match='Sexu...  \n",
       "\n",
       "[1845 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2 = case_2.drop(drop_index,axis = 0)\n",
    "case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d4013c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>New_annotation</th>\n",
       "      <th>New_pn_history</th>\n",
       "      <th>new_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>'vaginal dryness'</td>\n",
       "      <td>'465 480'</td>\n",
       "      <td>204</td>\n",
       "      <td>455</td>\n",
       "      <td>470</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>vaginal dryness</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(455, 470), match='vagi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>'dryness which she uses lubricant for'</td>\n",
       "      <td>'473 509'</td>\n",
       "      <td>204</td>\n",
       "      <td>463</td>\n",
       "      <td>497</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>dryness which she us lubricant for</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(463, 497), match='dryn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'21 38'</td>\n",
       "      <td>205</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular period</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(22, 38), match='irregu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>'irregular periods'</td>\n",
       "      <td>'63 80'</td>\n",
       "      <td>205</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>irregular period</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(22, 38), match='irregu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>'one week ago with nausea and vomiting'</td>\n",
       "      <td>'238 275'</td>\n",
       "      <td>206</td>\n",
       "      <td>233</td>\n",
       "      <td>270</td>\n",
       "      <td>2</td>\n",
       "      <td>CC: 44 yo female c/o irregular periods\\r\\nHPI:...</td>\n",
       "      <td>one week ago with nausea and vomiting</td>\n",
       "      <td>CC : 44 yo female c o irregular period HPI : x...</td>\n",
       "      <td>&lt;re.Match object; span=(233, 270), match='one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>20420</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'531 546'</td>\n",
       "      <td>203</td>\n",
       "      <td>503</td>\n",
       "      <td>518</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo f came to office with irregular periods ...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>44 yo f came to office with irregular period f...</td>\n",
       "      <td>&lt;re.Match object; span=(503, 518), match='Sexu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>22013</td>\n",
       "      <td>'sex with her husband'</td>\n",
       "      <td>'486 506'</td>\n",
       "      <td>203</td>\n",
       "      <td>480</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "      <td>sex with her husband</td>\n",
       "      <td>Pt is a 44 year old female coming in for irreg...</td>\n",
       "      <td>&lt;re.Match object; span=(480, 500), match='sex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>20781</td>\n",
       "      <td>'sexually active'</td>\n",
       "      <td>'514 529'</td>\n",
       "      <td>203</td>\n",
       "      <td>495</td>\n",
       "      <td>510</td>\n",
       "      <td>2</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "      <td>sexually active</td>\n",
       "      <td>pt is a 44 yo f presenting with irregular peri...</td>\n",
       "      <td>&lt;re.Match object; span=(495, 510), match='sexu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>21001</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'599 614'</td>\n",
       "      <td>203</td>\n",
       "      <td>580</td>\n",
       "      <td>595</td>\n",
       "      <td>2</td>\n",
       "      <td>44 yo F complaining of irregular periods for l...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>44 yo F complaining of irregular period for la...</td>\n",
       "      <td>&lt;re.Match object; span=(580, 595), match='Sexu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>21629</td>\n",
       "      <td>'Sexually active'</td>\n",
       "      <td>'829 844'</td>\n",
       "      <td>203</td>\n",
       "      <td>811</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>HPI: 44 yo female who presents with irregular ...</td>\n",
       "      <td>Sexually active</td>\n",
       "      <td>HPI : 44 yo female who present with irregular ...</td>\n",
       "      <td>&lt;re.Match object; span=(811, 826), match='Sexu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1845 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pn_num                               annotation    location  \\\n",
       "0      20001                        'vaginal dryness'   '465 480'   \n",
       "1      20001   'dryness which she uses lubricant for'   '473 509'   \n",
       "2      20001                      'irregular periods'     '21 38'   \n",
       "3      20001                      'irregular periods'     '63 80'   \n",
       "4      20001  'one week ago with nausea and vomiting'   '238 275'   \n",
       "...      ...                                      ...         ...   \n",
       "1897   20420                        'Sexually active'   '531 546'   \n",
       "1898   22013                   'sex with her husband'   '486 506'   \n",
       "1899   20781                        'sexually active'   '514 529'   \n",
       "1900   21001                        'Sexually active'   '599 614'   \n",
       "1901   21629                        'Sexually active'   '829 844'   \n",
       "\n",
       "      feature_num  start_location  end_location  case_num  \\\n",
       "0             204             455           470         2   \n",
       "1             204             463           497         2   \n",
       "2             205              22            38         2   \n",
       "3             205              22            38         2   \n",
       "4             206             233           270         2   \n",
       "...           ...             ...           ...       ...   \n",
       "1897          203             503           518         2   \n",
       "1898          203             480           500         2   \n",
       "1899          203             495           510         2   \n",
       "1900          203             580           595         2   \n",
       "1901          203             811           826         2   \n",
       "\n",
       "                                             pn_history  \\\n",
       "0     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "1     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "2     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "3     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "4     CC: 44 yo female c/o irregular periods\\r\\nHPI:...   \n",
       "...                                                 ...   \n",
       "1897  44 yo f came to office with irregular periods ...   \n",
       "1898  Pt is a 44 year old female coming in for irreg...   \n",
       "1899  pt is a 44 yo f presenting with irregular peri...   \n",
       "1900  44 yo F complaining of irregular periods for l...   \n",
       "1901  HPI: 44 yo female who presents with irregular ...   \n",
       "\n",
       "                             New_annotation  \\\n",
       "0                           vaginal dryness   \n",
       "1        dryness which she us lubricant for   \n",
       "2                          irregular period   \n",
       "3                          irregular period   \n",
       "4     one week ago with nausea and vomiting   \n",
       "...                                     ...   \n",
       "1897                        Sexually active   \n",
       "1898                   sex with her husband   \n",
       "1899                        sexually active   \n",
       "1900                        Sexually active   \n",
       "1901                        Sexually active   \n",
       "\n",
       "                                         New_pn_history  \\\n",
       "0     CC : 44 yo female c o irregular period HPI : x...   \n",
       "1     CC : 44 yo female c o irregular period HPI : x...   \n",
       "2     CC : 44 yo female c o irregular period HPI : x...   \n",
       "3     CC : 44 yo female c o irregular period HPI : x...   \n",
       "4     CC : 44 yo female c o irregular period HPI : x...   \n",
       "...                                                 ...   \n",
       "1897  44 yo f came to office with irregular period f...   \n",
       "1898  Pt is a 44 year old female coming in for irreg...   \n",
       "1899  pt is a 44 yo f presenting with irregular peri...   \n",
       "1900  44 yo F complaining of irregular period for la...   \n",
       "1901  HPI : 44 yo female who present with irregular ...   \n",
       "\n",
       "                                           new_location  \n",
       "0     <re.Match object; span=(455, 470), match='vagi...  \n",
       "1     <re.Match object; span=(463, 497), match='dryn...  \n",
       "2     <re.Match object; span=(22, 38), match='irregu...  \n",
       "3     <re.Match object; span=(22, 38), match='irregu...  \n",
       "4     <re.Match object; span=(233, 270), match='one ...  \n",
       "...                                                 ...  \n",
       "1897  <re.Match object; span=(503, 518), match='Sexu...  \n",
       "1898  <re.Match object; span=(480, 500), match='sex ...  \n",
       "1899  <re.Match object; span=(495, 510), match='sexu...  \n",
       "1900  <re.Match object; span=(580, 595), match='Sexu...  \n",
       "1901  <re.Match object; span=(811, 826), match='Sexu...  \n",
       "\n",
       "[1845 rows x 11 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2[\"start_location\"] = case_2.apply(lambda x :re.search(r'\\b' + x.New_annotation + r'\\b', x.New_pn_history).start(),axis =1)\n",
    "case_2[\"end_location\"] = case_2.apply(lambda x :re.search(r'\\b' + x.New_annotation + r'\\b', x.New_pn_history).end(),axis =1)\n",
    "case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c7e1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_2 = case_2.drop(index = [66,67,68], axis= 0)\n",
    "case_2 = case_2.drop(index = 138, axis= 0)\n",
    "case_2 = case_2.drop(index = [166,167,168,697,699], axis= 0)\n",
    "case_2 = case_2.drop(index = [190,192], axis= 0)\n",
    "case_2 = case_2.drop(index = [225,227], axis= 0)\n",
    "case_2 = case_2.drop(index = [256,258], axis= 0)\n",
    "case_2 = case_2.drop(index = [318,320,321,322,323], axis= 0)\n",
    "case_2 = case_2.drop(index = 336, axis= 0)\n",
    "case_2 = case_2.drop(index = [387,388,389], axis= 0)\n",
    "case_2 = case_2.drop(index = 435, axis= 0)\n",
    "case_2 = case_2.drop(index = [136,454,1065,1066], axis= 0)\n",
    "case_2 = case_2.drop(index = 452, axis= 0)\n",
    "case_2 = case_2.drop(index = [471,634,636,637], axis= 0)\n",
    "case_2 = case_2.drop(index = [481,482], axis= 0)\n",
    "case_2 = case_2.drop(index = 590, axis= 0)\n",
    "case_2 = case_2.drop(index = [154,684], axis= 0)\n",
    "case_2 = case_2.drop(index = 686, axis= 0)\n",
    "case_2 = case_2.drop(index = [720,722], axis= 0)\n",
    "case_2 = case_2.drop(index = [801,802], axis= 0)\n",
    "case_2 = case_2.drop(index = [823,825], axis= 0)\n",
    "case_2 = case_2.drop(index = [854, 856], axis= 0)\n",
    "case_2 = case_2.drop(index = 923, axis= 0)\n",
    "case_2 = case_2.drop(index = [1014, 1015,1017], axis= 0)\n",
    "case_2 = case_2.drop(index = [1033,1034,1036], axis= 0)\n",
    "case_2 = case_2.drop(index = 1067, axis= 0)\n",
    "case_2 = case_2.drop(index = 1085, axis= 0)\n",
    "case_2 = case_2.drop(index = [1195,1197], axis= 0)\n",
    "case_2 = case_2.drop(index = [1244,1245], axis= 0)\n",
    "case_2 = case_2.drop(index = [1310,1311,1312] , axis= 0)\n",
    "case_2 = case_2.drop(index = 1330, axis= 0)\n",
    "case_2 = case_2.drop(index = 1069, axis= 0)\n",
    "case_2 = case_2.drop(index = 1087, axis= 0)\n",
    "case_2 = case_2.drop(index = 170, axis= 0)\n",
    "case_2 = case_2.drop(index = 338, axis= 0)\n",
    "case_2 = case_2.drop(index = 624, axis= 0)\n",
    "case_2 = case_2.drop(index = 639, axis= 0)\n",
    "case_2 = case_2.drop(index = 870, axis= 0)\n",
    "case_2 = case_2.drop(index = 993, axis= 0)\n",
    "case_2 = case_2.drop(index = 116, axis= 0)\n",
    "case_2 = case_2.drop(index = 172, axis= 0)\n",
    "case_2 = case_2.drop(index = 340, axis= 0)\n",
    "case_2 = case_2.drop(index = 0, axis= 0)\n",
    "case_2 = case_2.drop(index = [174, 175], axis= 0)\n",
    "case_2 = case_2.drop(index = 211, axis= 0)\n",
    "case_2 = case_2.drop(index = 485, axis= 0)\n",
    "case_2 = case_2.drop(index = 641, axis= 0)\n",
    "case_2 = case_2.drop(index = 668, axis= 0)\n",
    "case_2 = case_2.drop(index = 928, axis= 0)\n",
    "case_2 = case_2.drop(index = 1090, axis= 0)\n",
    "case_2 = case_2.drop(index = 3, axis= 0)\n",
    "case_2 = case_2.drop(index = [90,88], axis= 0)\n",
    "case_2 = case_2.drop(index = 197, axis= 0)\n",
    "case_2 = case_2.drop(index = 213, axis= 0)\n",
    "case_2 = case_2.drop(index = 364, axis= 0)\n",
    "case_2 = case_2.drop(index = 391, axis= 0)\n",
    "case_2 = case_2.drop(index = 419, axis= 0)\n",
    "case_2 = case_2.drop(index = 487, axis= 0)\n",
    "case_2 = case_2.drop(index = 615, axis= 0)\n",
    "case_2 = case_2.drop(index = 627, axis= 0)\n",
    "case_2 = case_2.drop(index = 690, axis= 0)\n",
    "case_2 = case_2.drop(index = 761, axis= 0)\n",
    "case_2 = case_2.drop(index = 777, axis= 0)\n",
    "case_2 = case_2.drop(index = 829, axis= 0)\n",
    "case_2 = case_2.drop(index = 844, axis= 0)\n",
    "case_2 = case_2.drop(index = 1023, axis= 0)\n",
    "case_2 = case_2.drop(index = 1039, axis= 0)\n",
    "case_2 = case_2.drop(index = 1053, axis= 0)\n",
    "case_2 = case_2.drop(index = 1091, axis= 0)\n",
    "case_2 = case_2.drop(index = 1116, axis= 0)\n",
    "case_2 = case_2.drop(index = 1235, axis= 0)\n",
    "case_2 = case_2.drop(index = 1250, axis= 0)\n",
    "case_2 = case_2.drop(index = 5, axis= 0)\n",
    "case_2 = case_2.drop(index = 233, axis= 0)\n",
    "case_2 = case_2.drop(index = [1055,1054], axis= 0)\n",
    "case_2 = case_2.drop(index = 1202, axis= 0)\n",
    "case_2 = case_2.drop(index = 1279, axis= 0)\n",
    "case_2 = case_2.drop(index = 1318, axis= 0)\n",
    "case_2 = case_2.drop(index = 345, axis= 0)\n",
    "case_2 = case_2.drop(index = 1077, axis= 0)\n",
    "case_2 = case_2.drop(index = 1280, axis= 0)\n",
    "case_2 = case_2.drop(index = 179, axis= 0)\n",
    "case_2 = case_2.drop(index = 348, axis= 0)\n",
    "case_2 = case_2.drop(index = 1094, axis= 0)\n",
    "case_2 = case_2.drop(index = 181, axis= 0)\n",
    "case_2 = case_2.drop(index = 571, axis= 0)\n",
    "case_2 = case_2.drop(index = 349, axis= 0)\n",
    "case_2 = case_2.drop(index = 396, axis= 0)\n",
    "case_2 = case_2.drop(index = 493, axis= 0)\n",
    "case_2 = case_2.drop(index = 675, axis= 0)\n",
    "case_2 = case_2.drop(index = 1079, axis= 0)\n",
    "case_2 = case_2.drop(index = 1095, axis= 0)\n",
    "case_2 = case_2.drop(index = 108, axis= 0)\n",
    "case_2 = case_2.drop(index = 299, axis= 0)\n",
    "case_2 = case_2.drop(index = 354, axis= 0)\n",
    "case_2 = case_2.drop(index = 426, axis= 0)\n",
    "case_2 = case_2.drop(index = 445, axis= 0)\n",
    "case_2 = case_2.drop(index = 496, axis= 0)\n",
    "case_2 = case_2.drop(index = [572,573], axis= 0)\n",
    "case_2 = case_2.drop(index = 610, axis= 0)\n",
    "case_2 = case_2.drop(index = 783, axis= 0)\n",
    "case_2 = case_2.drop(index = 862, axis= 0)\n",
    "case_2 = case_2.drop(index = 1002, axis= 0)\n",
    "case_2 = case_2.drop(index = [1027,1029], axis= 0)\n",
    "case_2 = case_2.drop(index = 1062, axis= 0)\n",
    "case_2 = case_2.drop(index = [1102,1098,1100], axis= 0)\n",
    "case_2 = case_2.drop(index = 1209, axis= 0)\n",
    "case_2 = case_2.drop(index = 1270, axis= 0)\n",
    "case_2 = case_2.drop(index = 1340, axis= 0)\n",
    "case_2 = case_2.drop(index = 81, axis= 0)\n",
    "case_2 = case_2.drop(index = 185, axis= 0)\n",
    "case_2 = case_2.drop(index = 238, axis= 0)\n",
    "case_2 = case_2.drop(index = 357, axis= 0)\n",
    "case_2 = case_2.drop(index = 499, axis= 0)\n",
    "case_2 = case_2.drop(index = 883, axis= 0)\n",
    "case_2 = case_2.drop(index = 1104, axis= 0)\n",
    "case_2 = case_2.drop(index = 1122, axis= 0)\n",
    "case_2 = case_2.drop(index = 1258, axis= 0)\n",
    "case_2 = case_2.drop(index = 359, axis= 0)\n",
    "case_2 = case_2.drop(index = 501, axis= 0)\n",
    "case_2 = case_2.drop(index = 653, axis= 0)\n",
    "case_2 = case_2.drop(index = [679,680], axis= 0)\n",
    "case_2 = case_2.drop(index = 770, axis= 0)\n",
    "case_2 = case_2.drop(index = 1084, axis= 0)\n",
    "case_2 = case_2.drop(index = 1107, axis= 0)\n",
    "case_2 = case_2.drop(index = 1326, axis= 0)\n",
    "case_2 = case_2.drop(index = 1382, axis= 0)\n",
    "case_2 = case_2.drop(index = 787, axis= 0)\n",
    "case_2 = case_2.drop(index = 188, axis= 0)\n",
    "case_2 = case_2.drop(index = 1390, axis= 0)\n",
    "case_2 = case_2.drop(index = 1396, axis= 0)\n",
    "case_2 = case_2.drop(index = 1465, axis= 0)\n",
    "case_2 = case_2.drop(index = 1468, axis= 0)\n",
    "case_2 = case_2.drop(index = 1470, axis= 0)\n",
    "case_2 = case_2.drop(index = 1473, axis= 0)\n",
    "case_2 = case_2.drop(index = 1476, axis= 0)\n",
    "case_2 = case_2.drop(index = 1479, axis= 0)\n",
    "case_2 = case_2.drop(index = 1483, axis= 0)\n",
    "case_2 = case_2.drop(index = 1485, axis= 0)\n",
    "case_2 = case_2.drop(index = [1488, 1490], axis= 0)\n",
    "case_2 = case_2.drop(index = 1492, axis= 0)\n",
    "case_2 = case_2.drop(index = 1493, axis= 0)\n",
    "case_2 = case_2.drop(index = 1496, axis= 0)\n",
    "case_2 = case_2.drop(index = 1498, axis= 0)\n",
    "case_2 = case_2.drop(index = 1500, axis= 0)\n",
    "case_2 = case_2.drop(index = 1503, axis= 0)\n",
    "case_2 = case_2.drop(index = 1508, axis= 0)\n",
    "case_2 = case_2.drop(index = 1512, axis= 0)\n",
    "case_2 = case_2.drop(index = 1516, axis= 0)\n",
    "case_2 = case_2.drop(index = 1519, axis= 0)\n",
    "case_2 = case_2.drop(index = 1523, axis= 0)\n",
    "case_2 = case_2.drop(index = 1531, axis= 0)\n",
    "case_2 = case_2.drop(index = 1534, axis= 0)\n",
    "case_2 = case_2.drop(index = 1536, axis= 0)\n",
    "case_2 = case_2.drop(index = [1539, 1578], axis= 0)\n",
    "case_2 = case_2.drop(index = 1542, axis= 0)\n",
    "case_2 = case_2.drop(index = 1548, axis= 0)\n",
    "case_2 = case_2.drop(index = 1550, axis= 0)\n",
    "case_2 = case_2.drop(index = 1552, axis= 0)\n",
    "case_2 = case_2.drop(index = 1555, axis= 0)\n",
    "case_2 = case_2.drop(index = 1564, axis= 0)\n",
    "case_2 = case_2.drop(index = 1566, axis= 0)\n",
    "case_2 = case_2.drop(index = 1568, axis= 0)\n",
    "case_2 = case_2.drop(index = 1572, axis= 0)\n",
    "case_2 = case_2.drop(index = 1574, axis= 0)\n",
    "case_2 = case_2.drop(index = 1576, axis= 0)\n",
    "case_2 = case_2.drop(index = 1582, axis= 0)\n",
    "case_2 = case_2.drop(index = 1584, axis= 0)\n",
    "case_2 = case_2.drop(index = 1636, axis= 0)\n",
    "case_2 = case_2.drop(index = 1610, axis= 0)\n",
    "case_2 = case_2.drop(index = 1664, axis= 0)\n",
    "case_2 = case_2.drop(index = 1662, axis= 0)\n",
    "case_2 = case_2.drop(index = 1629, axis= 0)\n",
    "case_2 = case_2.drop(index = 1648, axis= 0)\n",
    "case_2 = case_2.drop(index = 1657, axis= 0)\n",
    "case_2 = case_2.drop(index = 1668, axis= 0)\n",
    "case_2 = case_2.drop(index = 1702, axis= 0)\n",
    "case_2 = case_2.drop(index = 1756, axis= 0)\n",
    "case_2 = case_2.drop(index = 1397, axis= 0)\n",
    "case_2 = case_2.drop(index = 1757, axis= 0)\n",
    "case_2 = case_2.drop(index = 1752, axis= 0)\n",
    "case_2 = case_2.drop(index = 1750, axis= 0)\n",
    "case_2 = case_2.drop(index = 1789, axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c78669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "749f9fed",
   "metadata": {},
   "source": [
    "### Feature 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78a20acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 11)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_200 = case_2[case_2[\"feature_num\"] == 200]\n",
    "case_2_200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b72944e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 23)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_200.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_200[case_2_200.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_200[case_2_200.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_200.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_200.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0085774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 89/89 [00:00<00:00, 1026.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_200.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73710339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 923.12it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_200.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc3919d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_200.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_200.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 14:54:34.753048: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 14:54:34.753086: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_200.cfg ./config_200.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47a07eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_200\n",
      "[i] Saving to output directory: output_200\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     59.67    0.00    0.00    0.00    0.00\n",
      "  2     200       1968.28   2802.39   32.56   38.89   28.00    0.33\n",
      "  4     400         39.62    260.76   42.86   52.94   36.00    0.43\n",
      "  6     600         79.65    188.21   13.64   15.79   12.00    0.14\n",
      "  8     800        100.16    137.20   43.48   47.62   40.00    0.43\n",
      " 11    1000        111.76    127.40   34.04   36.36   32.00    0.34\n",
      " 13    1200        113.88     98.49   39.02   50.00   32.00    0.39\n",
      " 15    1400         95.65     71.14   14.29   17.65   12.00    0.14\n",
      " 17    1600        144.42     92.18   38.10   47.06   32.00    0.38\n",
      " 20    1800        104.92     69.02   28.57   35.29   24.00    0.29\n",
      " 22    2000         85.41     44.04   26.67   30.00   24.00    0.27\n",
      " 24    2200        107.16     70.35   32.56   38.89   28.00    0.33\n",
      " 26    2400         83.23     53.22   40.00   45.00   36.00    0.40\n",
      "[+] Saved pipeline to output directory\n",
      "output_200\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 14:54:38.804940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 14:54:38.804976: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 14:54:41,305] [INFO] Set up nlp object from config\n",
      "[2022-05-02 14:54:41,311] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 14:54:41,314] [INFO] Created vocabulary\n",
      "[2022-05-02 14:54:41,314] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 14:54:41,708] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_200.cfg --output ./output_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5dfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0befa341",
   "metadata": {},
   "source": [
    "### Feature 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "995a0887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 11)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_201 = case_2[case_2[\"feature_num\"] == 201]\n",
    "case_2_201.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6fd3b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 24)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_201.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_201[case_2_201.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_201[case_2_201.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_201.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_201.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ffc35e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 94/94 [00:00<00:00, 880.44it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_201.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a338ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 1046.99it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_201.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d155fa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_201.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_201.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 14:57:11.142384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 14:57:11.142421: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_201.cfg ./config_201.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "503d1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_201\n",
      "[i] Saving to output directory: output_201\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     63.17    0.00    0.00    0.00    0.00\n",
      "  2     200        898.79   1759.57   73.91   77.27   70.83    0.74\n",
      "  4     400         49.51    173.87   72.34   73.91   70.83    0.72\n",
      "  6     600         77.47    133.36   63.64   70.00   58.33    0.64\n",
      "  8     800         53.80     81.69   69.57   72.73   66.67    0.70\n",
      " 10    1000         83.12     77.60   76.60   78.26   75.00    0.77\n",
      " 12    1200         79.95     52.76   76.60   78.26   75.00    0.77\n",
      " 14    1400       1559.64     67.95   60.87   63.64   58.33    0.61\n",
      " 17    1600         43.22     39.86   62.22   66.67   58.33    0.62\n",
      " 19    1800         29.87     18.22   55.32   56.52   54.17    0.55\n",
      " 21    2000         25.08     29.77   65.22   68.18   62.50    0.65\n",
      " 23    2200        154.69     39.39   65.22   68.18   62.50    0.65\n",
      " 25    2400         31.98     14.71   66.67   77.78   58.33    0.67\n",
      " 27    2600         10.71      9.73   65.22   68.18   62.50    0.65\n",
      "[+] Saved pipeline to output directory\n",
      "output_201\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 14:57:15.056212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 14:57:15.056249: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 14:57:17,664] [INFO] Set up nlp object from config\n",
      "[2022-05-02 14:57:17,671] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 14:57:17,673] [INFO] Created vocabulary\n",
      "[2022-05-02 14:57:17,674] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 14:57:18,091] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_201.cfg --output ./output_201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048561fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea3d98b1",
   "metadata": {},
   "source": [
    "### Feature 202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e71280b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 11)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_202 = case_2[case_2[\"feature_num\"] == 202]\n",
    "case_2_202.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45dcc00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_202.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_202[case_2_202.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_202[case_2_202.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_202.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_202.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3a42a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 711.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_202.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b09e6a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 668.81it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_202.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5fa9aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_202.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_202.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:00:25.736039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:00:25.736082: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_202.cfg ./config_202.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73695eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_202\n",
      "[i] Saving to output directory: output_202\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     55.00    0.00    0.00    0.00    0.00\n",
      "  5     200         21.97   1065.40   80.00   80.00   80.00    0.80\n",
      " 10     400         29.19     47.56   90.00   90.00   90.00    0.90\n",
      " 15     600         18.64     22.14   90.00   90.00   90.00    0.90\n",
      " 20     800         14.53     16.45   78.26   69.23   90.00    0.78\n",
      " 25    1000         14.86     13.00   78.26   69.23   90.00    0.78\n",
      " 30    1200          5.93      5.56   78.26   69.23   90.00    0.78\n",
      " 35    1400          0.00      0.00   78.26   69.23   90.00    0.78\n",
      " 41    1600          0.00      0.00   78.26   69.23   90.00    0.78\n",
      " 46    1800          0.00      0.00   78.26   69.23   90.00    0.78\n",
      " 51    2000          0.00      0.00   81.82   75.00   90.00    0.82\n",
      "[+] Saved pipeline to output directory\n",
      "output_202\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:00:33.479167: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:00:33.479211: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:00:37,397] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:00:37,426] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:00:37,435] [INFO] Created vocabulary\n",
      "[2022-05-02 15:00:37,439] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:00:38,079] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_202.cfg --output ./output_202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f24f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2c96caf",
   "metadata": {},
   "source": [
    "### Feature 203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4802d5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 11)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_203 = case_2[case_2[\"feature_num\"] == 203]\n",
    "case_2_203.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bacd120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 25)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_203.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_203[case_2_203.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_203[case_2_203.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_203.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_203.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "17298f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 99/99 [00:00<00:00, 766.92it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_203.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d2ddab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 760.15it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_203.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0385d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_203.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_203.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:03:13.484152: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:03:13.484202: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_203.cfg ./config_203.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbddc9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_203\n",
      "[i] Saving to output directory: output_203\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     57.17    0.37    0.20    4.00    0.00\n",
      "  2     200         29.22   1082.14   66.67   69.57   64.00    0.67\n",
      "  4     400        329.33    195.44   74.51   73.08   76.00    0.75\n",
      "  6     600        110.34    116.43   60.00   60.00   60.00    0.60\n",
      "  8     800        413.15    135.17   58.82   57.69   60.00    0.59\n",
      " 10    1000         61.86     45.25   36.73   37.50   36.00    0.37\n",
      " 12    1200         72.74     55.19   64.00   64.00   64.00    0.64\n",
      " 14    1400         80.71     38.61   54.17   56.52   52.00    0.54\n",
      " 16    1600         59.32     27.58   47.06   46.15   48.00    0.47\n",
      " 18    1800         44.26     24.84   57.14   58.33   56.00    0.57\n",
      " 20    2000         36.85     16.87   57.14   58.33   56.00    0.57\n",
      "[+] Saved pipeline to output directory\n",
      "output_203\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:03:19.970171: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:03:19.970234: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:03:23,475] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:03:23,483] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:03:23,486] [INFO] Created vocabulary\n",
      "[2022-05-02 15:03:23,487] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:03:23,981] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_203.cfg --output ./output_203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ab9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62842b43",
   "metadata": {},
   "source": [
    "### Feature 204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48759b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 11)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_204 = case_2[case_2[\"feature_num\"] == 204]\n",
    "case_2_204.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b6c2d225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 12)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_204.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_204[case_2_204.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_204[case_2_204.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_204.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_204.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d811b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 455.74it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_204.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb616052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 571.19it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_204.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a08f93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_204.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_204.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:05:40.914595: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:05:40.914634: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_204.cfg ./config_204.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16de853c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_204\n",
      "[i] Saving to output directory: output_204\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     60.50    0.00    0.00    0.00    0.00\n",
      "  4     200        748.66   1377.83   74.07   71.43   76.92    0.74\n",
      "  8     400        591.69    180.23   69.23   69.23   69.23    0.69\n",
      " 13     600         30.71     50.80   72.00   75.00   69.23    0.72\n",
      " 17     800         48.88     26.20   66.67   64.29   69.23    0.67\n",
      " 22    1000         14.87      8.74   78.26   90.00   69.23    0.78\n",
      " 26    1200          0.99      0.26   78.26   90.00   69.23    0.78\n",
      " 31    1400         25.08      7.56   69.23   69.23   69.23    0.69\n",
      " 35    1600          4.64      4.20   75.00   81.82   69.23    0.75\n",
      " 40    1800          0.00      0.00   75.00   81.82   69.23    0.75\n",
      " 44    2000          0.01      0.00   75.00   81.82   69.23    0.75\n",
      " 48    2200          2.11      0.97   75.00   81.82   69.23    0.75\n",
      " 53    2400          0.00      0.00   75.00   81.82   69.23    0.75\n",
      " 58    2600          0.00      0.00   75.00   81.82   69.23    0.75\n",
      "[+] Saved pipeline to output directory\n",
      "output_204\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:05:45.674469: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:05:45.674520: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:05:48,715] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:05:48,722] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:05:48,725] [INFO] Created vocabulary\n",
      "[2022-05-02 15:05:48,726] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:05:49,078] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_204.cfg --output ./output_204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49616e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be7ea145",
   "metadata": {},
   "source": [
    "### Feature 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b44dd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 11)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_205 = case_2[case_2[\"feature_num\"] == 205]\n",
    "case_2_205.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e930182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 20)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_205.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_205[case_2_205.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_205[case_2_205.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_205.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_205.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d620ad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 916.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_205.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "90171a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 1105.12it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_205.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55d0e4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_205.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_205.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:08:31.709562: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:08:31.709616: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_205.cfg ./config_205.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5f90c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_205\n",
      "[i] Saving to output directory: output_205\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     61.67    0.00    0.00    0.00    0.00\n",
      "  2     200       3604.25   1706.02   61.22   75.00   51.72    0.61\n",
      "  5     400         62.68    179.95   62.96   68.00   58.62    0.63\n",
      "  7     600         60.51     86.25   66.67   67.86   65.52    0.67\n",
      " 10     800        412.53     62.03   69.09   73.08   65.52    0.69\n",
      " 12    1000        821.03     57.08   71.43   74.07   68.97    0.71\n",
      " 15    1200        555.32     60.57   66.67   64.52   68.97    0.67\n",
      " 17    1400         63.10     39.67   63.33   61.29   65.52    0.63\n",
      " 20    1600         40.43     19.98   70.37   76.00   65.52    0.70\n",
      " 22    1800        288.50     27.63   50.85   50.00   51.72    0.51\n",
      " 25    2000         54.20     24.53   62.96   68.00   58.62    0.63\n",
      " 28    2200         65.85     29.00   62.07   62.07   62.07    0.62\n",
      " 33    2400         51.22     21.57   59.65   60.71   58.62    0.60\n",
      " 40    2600         26.99      9.29   61.54   69.57   55.17    0.62\n",
      "[+] Saved pipeline to output directory\n",
      "output_205\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:08:35.773135: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:08:35.773173: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:08:38,449] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:08:38,459] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:08:38,462] [INFO] Created vocabulary\n",
      "[2022-05-02 15:08:38,463] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:08:38,829] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_205.cfg --output ./output_205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe2e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2419ca6b",
   "metadata": {},
   "source": [
    "### Feature 206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "493437a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 11)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_206 = case_2[case_2[\"feature_num\"] == 206]\n",
    "case_2_206.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9be0e21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 22)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_206.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_206[case_2_206.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_206[case_2_206.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_206.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_206.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "564adae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 1053.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_206.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "613dd984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 1202.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_206.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "98d7c1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:11:28.706978: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:11:28.707016: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_206.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_206.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_206.cfg ./config_206.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "994c8d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_206\n",
      "[i] Saving to output directory: output_206\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     51.00    0.00    0.00    0.00    0.00\n",
      "  2     200        430.35   1867.66   69.57   66.67   72.73    0.70\n",
      "  4     400        112.71    159.22   69.57   66.67   72.73    0.70\n",
      "  7     600        864.22    118.59   77.27   77.27   77.27    0.77\n",
      "  9     800         60.33     47.92   75.00   83.33   68.18    0.75\n",
      " 11    1000         67.58     36.64   66.67   61.54   72.73    0.67\n",
      " 14    1200        298.47     55.68   63.83   60.00   68.18    0.64\n",
      " 16    1400         79.07     36.66   71.11   69.57   72.73    0.71\n",
      " 19    1600         52.97     25.36   75.56   73.91   77.27    0.76\n",
      " 21    1800          8.44      2.55   72.73   72.73   72.73    0.73\n",
      " 23    2000         88.91     16.47   75.56   73.91   77.27    0.76\n",
      " 26    2200         16.66      5.09   74.42   76.19   72.73    0.74\n",
      "[+] Saved pipeline to output directory\n",
      "output_206\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:11:33.129216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:11:33.129255: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:11:35,891] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:11:35,898] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:11:35,901] [INFO] Created vocabulary\n",
      "[2022-05-02 15:11:35,901] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:11:36,314] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_206.cfg --output ./output_206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efd08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fbe3242",
   "metadata": {},
   "source": [
    "### Feature 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "825ce8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 11)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_207 = case_2[case_2[\"feature_num\"] == 207]\n",
    "case_2_207.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "48b345cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_207.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_207[case_2_207.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_207[case_2_207.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_207.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_207.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37ed349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 561.99it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_207.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cffeadca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 592.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_207.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9ebe53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy init fill-config ./base_config_207.cfg ./config_207.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d090aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy train config_207.cfg --output ./output_207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72c003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ed2ef74",
   "metadata": {},
   "source": [
    "### Feature 208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8eebcab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 11)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_208 = case_2[case_2[\"feature_num\"] == 208]\n",
    "case_2_208.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d2e1038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 18)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_208.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_208[case_2_208.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_208[case_2_208.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_208.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_208.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2803da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 525.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_208.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "033e24d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 806.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_208.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bd05e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_208.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_208.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:13:58.390053: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:13:58.390096: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_208.cfg ./config_208.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c1bba271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_208\n",
      "[i] Saving to output directory: output_208\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     51.50    0.00    0.00    0.00    0.00\n",
      "  2     200         10.45   1009.54   75.00   85.71   66.67    0.75\n",
      "  5     400          8.53     23.11   77.42   92.31   66.67    0.77\n",
      "  8     600          4.60     12.48   77.42   92.31   66.67    0.77\n",
      " 11     800          7.87     20.17   75.00   85.71   66.67    0.75\n",
      " 13    1000         10.01     23.29   77.42   92.31   66.67    0.77\n",
      " 16    1200         10.95     16.95   75.00   85.71   66.67    0.75\n",
      " 19    1400         10.93     19.40   73.33   91.67   61.11    0.73\n",
      " 22    1600          8.38     23.21   75.00   85.71   66.67    0.75\n",
      " 25    1800          6.01     13.57   75.00   85.71   66.67    0.75\n",
      " 27    2000          2.17      8.65   77.42   92.31   66.67    0.77\n",
      "[+] Saved pipeline to output directory\n",
      "output_208\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:14:02.638283: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:14:02.638325: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:14:05,448] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:14:05,455] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:14:05,458] [INFO] Created vocabulary\n",
      "[2022-05-02 15:14:05,459] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:14:05,834] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_208.cfg --output ./output_208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42361fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20fb342b",
   "metadata": {},
   "source": [
    "### Feature 209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "745ee3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_209 = case_2[case_2[\"feature_num\"] == 209]\n",
    "case_2_209.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df00a8",
   "metadata": {},
   "source": [
    "pn_Num_list = list(case_2_209.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_209[case_2_209.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_209[case_2_209.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_209.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_209.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e762c74",
   "metadata": {},
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_209.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67115ee",
   "metadata": {},
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_209.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ccf6120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy init fill-config ./base_config_209.cfg ./config_209.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "853534ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy train config_209.cfg --output ./output_209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d09395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56834d7b",
   "metadata": {},
   "source": [
    "### Feature 210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3da889e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 11)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_210 = case_2[case_2[\"feature_num\"] == 210]\n",
    "case_2_210.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d6a2ce0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 11)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_210.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_210[case_2_210.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_210[case_2_210.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_210.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_210.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aba75806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 793.86it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_210.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4db5b96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 1093.98it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_210.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "38b6d8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_210.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_210.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:16:12.290788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:16:12.290873: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_210.cfg ./config_210.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7fc0eaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_210\n",
      "[i] Saving to output directory: output_210\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     63.17    0.00    0.00    0.00    0.00\n",
      "  4     200       1619.91   2262.15   78.26   75.00   81.82    0.78\n",
      "  9     400         26.98     55.06   70.00   77.78   63.64    0.70\n",
      " 14     600         24.79     37.39   72.00   64.29   81.82    0.72\n",
      " 19     800         39.23     20.93   85.71   90.00   81.82    0.86\n",
      " 23    1000         14.49     13.71   74.07   62.50   90.91    0.74\n",
      " 28    1200          3.63      4.13   75.00   69.23   81.82    0.75\n",
      " 33    1400         18.36      4.91   75.00   69.23   81.82    0.75\n",
      " 38    1600          3.46      3.50   66.67   70.00   63.64    0.67\n",
      " 42    1800         33.03     15.55   69.57   66.67   72.73    0.70\n",
      " 47    2000         45.78     20.42   72.73   72.73   72.73    0.73\n",
      " 53    2200          8.10      3.40   86.96   83.33   90.91    0.87\n",
      " 61    2400          0.00      0.00   90.91   90.91   90.91    0.91\n",
      " 72    2600          0.00      0.00   90.91   90.91   90.91    0.91\n",
      " 85    2800         12.53      5.65   86.96   83.33   90.91    0.87\n",
      "102    3000          0.00      0.00   72.73   72.73   72.73    0.73\n",
      "123    3200          0.00      0.00   85.71   90.00   81.82    0.86\n",
      "148    3400          0.00      0.00   85.71   90.00   81.82    0.86\n",
      "174    3600          0.00      0.00   85.71   90.00   81.82    0.86\n",
      "201    3800          0.00      0.00   85.71   90.00   81.82    0.86\n",
      "226    4000          0.00      0.00   85.71   90.00   81.82    0.86\n",
      "[+] Saved pipeline to output directory\n",
      "output_210\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:16:16.386924: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:16:16.386960: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:16:19,053] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:16:19,060] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:16:19,063] [INFO] Created vocabulary\n",
      "[2022-05-02 15:16:19,064] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:16:19,386] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_210.cfg --output ./output_210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f667710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0719c65",
   "metadata": {},
   "source": [
    "### Feature 211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0cdaba69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 11)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_211 = case_2[case_2[\"feature_num\"] == 211]\n",
    "case_2_211.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "14e3cf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 15)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_211.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_211[case_2_211.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_211[case_2_211.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_211.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_211.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2dc981ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 639.94it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_211.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "37f46a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 717.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_211.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bc5f38b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_211.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_211.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:21:46.267288: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:21:46.267329: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_211.cfg ./config_211.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "34423ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_211\n",
      "[i] Saving to output directory: output_211\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     60.50    1.46    0.82    6.67    0.01\n",
      "  3     200         29.82   1027.71  100.00  100.00  100.00    1.00\n",
      "  6     400         38.10     55.67  100.00  100.00  100.00    1.00\n",
      " 10     600         21.27     36.93   93.33   93.33   93.33    0.93\n",
      " 13     800       8648.08    167.07   86.67   86.67   86.67    0.87\n",
      " 16    1000         20.91     14.83   93.33   93.33   93.33    0.93\n",
      " 20    1200          1.77      1.26   93.33   93.33   93.33    0.93\n",
      " 23    1400          0.00      0.00   93.33   93.33   93.33    0.93\n",
      " 26    1600       6778.59     79.12   89.66   92.86   86.67    0.90\n",
      " 30    1800      12832.98    233.96   86.67   86.67   86.67    0.87\n",
      "[+] Saved pipeline to output directory\n",
      "output_211\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:21:51.648761: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:21:51.648798: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:21:54,581] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:21:54,589] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:21:54,593] [INFO] Created vocabulary\n",
      "[2022-05-02 15:21:54,593] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:21:54,990] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_211.cfg --output ./output_211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb863316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "714ca568",
   "metadata": {},
   "source": [
    "### Feature 212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "18841695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 11)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_212 = case_2[case_2[\"feature_num\"] == 212]\n",
    "case_2_212.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f63d992f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 18)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_212.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_212[case_2_212.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_212[case_2_212.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_212.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_212.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3fa8756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 881.42it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_212.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b91e4872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 1123.66it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_212.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2dfc8c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_212.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_212.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:23:48.799557: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:23:48.799608: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_212.cfg ./config_212.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eb33244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_212\n",
      "[i] Saving to output directory: output_212\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     46.83    0.00    0.00    0.00    0.00\n",
      "  2     200       3933.31   3552.44   10.96   12.50    9.76    0.11\n",
      "  5     400         55.90    429.18   46.91   47.50   46.34    0.47\n",
      "  8     600        112.10    273.55   27.69   37.50   21.95    0.28\n",
      " 11     800        196.49    170.39   29.33   32.35   26.83    0.29\n",
      " 14    1000        159.61    146.80   40.00   44.12   36.59    0.40\n",
      " 17    1200        118.75     76.12   35.62   40.62   31.71    0.36\n",
      " 20    1400        152.04     90.16   41.98   42.50   41.46    0.42\n",
      " 23    1600        121.21     59.01   40.00   48.28   34.15    0.40\n",
      " 26    1800         78.21     26.26   30.99   36.67   26.83    0.31\n",
      " 29    2000        163.93     43.43   30.14   34.38   26.83    0.30\n",
      "[+] Saved pipeline to output directory\n",
      "output_212\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:23:52.914321: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:23:52.914359: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:23:55,595] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:23:55,602] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:23:55,605] [INFO] Created vocabulary\n",
      "[2022-05-02 15:23:55,605] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:23:55,973] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_212.cfg --output ./output_212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69343222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "627a2145",
   "metadata": {},
   "source": [
    "### Feature 213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "50a6d58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 11)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_213 = case_2[case_2[\"feature_num\"] == 213]\n",
    "case_2_213.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5e82b20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 18)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_213.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_213[case_2_213.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_213[case_2_213.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_213.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_213.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "db056c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 767.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_213.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "33365f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 1198.43it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_213.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bda80645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_213.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_213.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:26:02.564765: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:26:02.564802: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_213.cfg ./config_213.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3cf0330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_213\n",
      "[i] Saving to output directory: output_213\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     51.50    0.00    0.00    0.00    0.00\n",
      "  2     200       2513.46   2283.71   54.55   57.14   52.17    0.55\n",
      "  5     400         46.77    161.82   72.22  100.00   56.52    0.72\n",
      "  8     600         50.66     90.13   69.77   75.00   65.22    0.70\n",
      " 11     800         65.43     81.40   66.67   81.25   56.52    0.67\n",
      " 13    1000         52.52     64.87   71.11   72.73   69.57    0.71\n",
      " 16    1200         77.67     71.12   66.67   81.25   56.52    0.67\n",
      " 19    1400         57.69     53.97   78.05   88.89   69.57    0.78\n",
      " 22    1600         24.53     19.73   68.29   77.78   60.87    0.68\n",
      " 25    1800         48.40     26.40   75.00   88.24   65.22    0.75\n",
      " 28    2000         30.26     20.83   74.42   80.00   69.57    0.74\n",
      " 33    2200          8.01      3.86   75.00   88.24   65.22    0.75\n",
      " 39    2400         13.32      4.34   83.72   90.00   78.26    0.84\n",
      " 48    2600          0.00      0.00   78.05   88.89   69.57    0.78\n",
      " 58    2800          0.00      0.00   76.19   84.21   69.57    0.76\n",
      " 71    3000          0.00      0.00   76.19   84.21   69.57    0.76\n",
      " 86    3200          0.00      0.00   76.19   84.21   69.57    0.76\n",
      "102    3400          0.00      0.00   76.19   84.21   69.57    0.76\n",
      "117    3600          0.00      0.00   76.19   84.21   69.57    0.76\n",
      "133    3800          0.00      0.00   76.19   84.21   69.57    0.76\n",
      "149    4000          0.00      0.00   78.05   88.89   69.57    0.78\n",
      "[+] Saved pipeline to output directory\n",
      "output_213\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:26:06.760825: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:26:06.760863: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:26:09,531] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:26:09,539] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:26:09,542] [INFO] Created vocabulary\n",
      "[2022-05-02 15:26:09,542] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:26:09,923] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_213.cfg --output ./output_213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a798fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "459b69f5",
   "metadata": {},
   "source": [
    "### Feature 214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8adeb8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 11)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_214 = case_2[case_2[\"feature_num\"] == 214]\n",
    "case_2_214.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1fe8fc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 16)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_214.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_214[case_2_214.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_214[case_2_214.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_214.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_214.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "946afc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 860.00it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_214.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "79088ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 1146.75it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_214.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2ef5b46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_214.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_214.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:31:46.729337: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:31:46.729377: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_214.cfg ./config_214.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1b19f920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_214\n",
      "[i] Saving to output directory: output_214\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     56.67    0.00    0.00    0.00    0.00\n",
      "  3     200       1739.39   2434.56   81.25   86.67   76.47    0.81\n",
      "  6     400         18.88     45.07   74.29   72.22   76.47    0.74\n",
      " 10     600        194.08     33.14   74.29   72.22   76.47    0.74\n",
      " 13     800          4.74      2.19   72.73   75.00   70.59    0.73\n",
      " 16    1000        101.13     18.01   74.29   72.22   76.47    0.74\n",
      " 20    1200         37.68      7.16   72.73   75.00   70.59    0.73\n",
      " 23    1400      10921.17     85.24   77.78   73.68   82.35    0.78\n",
      " 26    1600         12.84      8.87   77.42   85.71   70.59    0.77\n",
      " 30    1800          0.00      0.00   74.29   72.22   76.47    0.74\n",
      "[+] Saved pipeline to output directory\n",
      "output_214\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:31:50.723615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:31:50.723655: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:31:53,312] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:31:53,319] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:31:53,322] [INFO] Created vocabulary\n",
      "[2022-05-02 15:31:53,323] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:31:53,653] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_214.cfg --output ./output_214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e05110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f7f9222",
   "metadata": {},
   "source": [
    "### Feature 215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d0bc737e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 11)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_215 = case_2[case_2[\"feature_num\"] == 215]\n",
    "case_2_215.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e83ba3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 19)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_215.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_215[case_2_215.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_215[case_2_215.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_215.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_215.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ccf0d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 73/73 [00:00<00:00, 968.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_215.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1eada9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 1271.10it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_215.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2dfd0a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_215.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_215.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:33:39.663002: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:33:39.663044: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_215.cfg ./config_215.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c652d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_215\n",
      "[i] Saving to output directory: output_215\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     67.33    0.48    0.25    5.00    0.00\n",
      "  2     200         34.24   1075.96   66.67   68.42   65.00    0.67\n",
      "  5     400        321.35    191.74   68.42   72.22   65.00    0.68\n",
      "  8     600         63.71    112.64   50.00   50.00   50.00    0.50\n",
      " 10     800         59.31     76.77   63.16   66.67   60.00    0.63\n",
      " 13    1000         65.92     46.63   82.05   84.21   80.00    0.82\n",
      " 16    1200       6113.63    131.42   71.79   73.68   70.00    0.72\n",
      " 19    1400         51.11     34.31   66.67   68.42   65.00    0.67\n",
      " 21    1600         35.37     28.38   68.29   66.67   70.00    0.68\n",
      " 24    1800         44.22     25.45   66.67   68.42   65.00    0.67\n",
      " 27    2000         19.18     12.52   63.16   66.67   60.00    0.63\n",
      " 30    2200         47.89     25.15   68.42   72.22   65.00    0.68\n",
      " 32    2400         15.58     18.85   66.67   68.42   65.00    0.67\n",
      " 35    2600         10.27     11.75   71.79   73.68   70.00    0.72\n",
      "[+] Saved pipeline to output directory\n",
      "output_215\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:33:43.640175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:33:43.640211: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:33:46,262] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:33:46,271] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:33:46,277] [INFO] Created vocabulary\n",
      "[2022-05-02 15:33:46,278] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:33:46,636] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_215.cfg --output ./output_215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd9d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c729d16a",
   "metadata": {},
   "source": [
    "### Feature 216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "50d864c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 11)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_2_216 = case_2[case_2[\"feature_num\"] == 216]\n",
    "case_2_216.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7d15a1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 34)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_Num_list = list(case_2_216.pn_num.unique())\n",
    "\n",
    "final_train = []   # appending all the individual rows\n",
    "for patient_number in pn_Num_list:  # for each unique patient number\n",
    "    entities = []  # saving individaual entities locations\n",
    "    for row_index,row in case_2_216[case_2_216.pn_num == patient_number].iterrows():  # for each unique patient number \n",
    "        \n",
    "        entities.append((int(row[\"start_location\"]),int(row[\"end_location\"]),\"Feature_\" + str(row[\"feature_num\"]))) # store the locations in numeric format\n",
    "        \n",
    "    text = case_2_216[case_2_216.pn_num == patient_number][\"New_pn_history\"].values[0] # save the text for the unique patient number\n",
    "    \n",
    "    final_train.append((text,{\"entities\":entities}))  # for each unique pn_number append to final list\n",
    "\n",
    "# Serializing json \n",
    "json_object = json.dumps(final_train, indent = 4)\n",
    "  \n",
    "# Writing to sample.json\n",
    "with open(\"sample_216.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open(\"sample_216.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for text, annot in tqdm(TRAIN_DATA):\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print (\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "train, validation = train_test_split(data, test_size = 0.2, random_state = 100)\n",
    "len(train),len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a5da1455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 132/132 [00:00<00:00, 1067.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#train data set\n",
    "camp_train = create_training(train)\n",
    "camp_train.to_disk(\"nbme_train_216.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e4280cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1306.80it/s]\n"
     ]
    }
   ],
   "source": [
    "#Validation data set\n",
    "camp_validation = create_training(validation)\n",
    "camp_validation.to_disk(\"nbme_validation_216.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "00e0594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config_216.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_216.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:36:18.984734: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:36:18.984775: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config_216.cfg ./config_216.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4ae32a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output_216\n",
      "[i] Saving to output directory: output_216\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     56.67    0.14    0.07    2.94    0.00\n",
      "  1     200        316.40   1040.94   49.28   48.57   50.00    0.49\n",
      "  3     400         11.95    156.70   69.57   68.57   70.59    0.70\n",
      "  4     600         22.66    154.06   52.94   52.94   52.94    0.53\n",
      "  6     800         26.45    140.29   61.97   59.46   64.71    0.62\n",
      "  7    1000         42.55    146.15   57.14   55.56   58.82    0.57\n",
      "  9    1200         43.46    132.69   47.22   44.74   50.00    0.47\n",
      " 10    1400         54.33    113.12   52.78   50.00   55.88    0.53\n",
      " 12    1600         87.72    118.70   38.36   35.90   41.18    0.38\n",
      " 13    1800         84.63    105.47   32.88   30.77   35.29    0.33\n",
      " 15    2000        157.67    145.16   48.57   47.22   50.00    0.49\n",
      "[+] Saved pipeline to output directory\n",
      "output_216\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:36:22.888266: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-05-02 15:36:22.888301: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-05-02 15:36:25,478] [INFO] Set up nlp object from config\n",
      "[2022-05-02 15:36:25,485] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-05-02 15:36:25,488] [INFO] Created vocabulary\n",
      "[2022-05-02 15:36:25,489] [INFO] Finished initializing nlp object\n",
      "[2022-05-02 15:36:25,920] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config_216.cfg --output ./output_216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6b82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029683b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de86428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ad7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
